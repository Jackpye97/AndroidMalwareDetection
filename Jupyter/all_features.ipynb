{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permissions + Android Classes Feature Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook different machine learning algorithms will be tested on the Perissions + Android Classes Feature Set and their performance will be ranked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import Ridge, LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset into panda dataframe\n",
    "df = pd.read_csv(\"DATASET PATH HERE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2554, 1091)\n",
      "removed 3740 Features\n"
     ]
    }
   ],
   "source": [
    "#Exploring the first five entries of the dataset to show the features that have been collected\n",
    "df.head()\n",
    "old_shape = df.shape\n",
    "\n",
    "#remove features that are not supported \n",
    "df = df.loc[:, (df.sum(axis=0) != 0)]\n",
    "print(df.shape)\n",
    "new_shape = df.shape\n",
    "print(f'removed {old_shape[1] - new_shape[1]} Features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert \"Malware and Beignin lables into 1 and 0\"\n",
    "df[\"malware\"] = (df[\"malware\"] == 'Malware').astype(int)\n",
    "y = df['malware']\n",
    "X = df.drop('malware', axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomForest(X, y, kfold=10, seed=101):\n",
    "    ## create k-fold \n",
    "    kf = KFold(n_splits=kfold,shuffle=True, random_state=seed)\n",
    "    \n",
    "    #\n",
    "    accuracy_score_avg, f1_score_avg, roc_auc_score_avg, recall_score_avg, precision_score_avg = np.empty(kfold), np.empty(kfold), \\\n",
    "                                                                                    np.empty(kfold), np.empty(kfold), np.empty(kfold)\n",
    "    randomForestMetrics = {'Accuracy': accuracy_score_avg, 'F1 Score': f1_score_avg, 'ROC_AUC_Score': roc_auc_score_avg, \n",
    "                           'Recall': recall_score_avg, 'Precision': precision_score_avg}\n",
    "    \n",
    "    ## create array to hold all confusion matrices \n",
    "    cm_holder = []\n",
    "    count = 0 \n",
    "\n",
    "    ## loop through data set using k-fold split\n",
    "    for train_index, test_index in kf.split(X):\n",
    "\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        clf = RandomForestClassifier()\n",
    "        clf.fit(X_train, y_train.ravel())\n",
    "        pred = clf.predict(X_test)\n",
    "        \n",
    "        accuracy_score_avg[count] = accuracy_score(y_test, pred)\n",
    "        f1_score_avg[count] = f1_score(y_test, pred)\n",
    "        roc_auc_score_avg[count] = roc_auc_score(y_test, pred)\n",
    "        recall_score_avg[count] = recall_score(y_test, pred)\n",
    "        precision_score_avg[count] = precision_score(y_test, pred)\n",
    "        cm_holder.append(confusion_matrix(y_test, pred))\n",
    "\n",
    "        count = count + 1\n",
    "        \n",
    "    #if for any reason a metric in the folds returns 0.0 remove it from the list\n",
    "    # mean all of the k-fold together to get average\n",
    "    for key, values in randomForestMetrics.items():\n",
    "        randomForestMetrics[key] = np.array([value for value in randomForestMetrics[key] if value != 0.0])\n",
    "        randomForestMetrics[key] = randomForestMetrics[key].mean()  \n",
    "    \n",
    "    \n",
    "    true_pos, true_neg, false_pos, false_neg = [], [], [], []\n",
    "    \n",
    "    ## get all confusion matrix values and sum them together for total \n",
    "    for cm in cm_holder:\n",
    "        true_pos.append(cm[0][0])\n",
    "        false_pos.append(cm[0][1])\n",
    "        true_neg.append(cm[1][0])\n",
    "        false_neg.append(cm[1][1])\n",
    "    \n",
    "    avg_cm = np.matrix([[sum(true_pos), sum(false_pos)], [sum(true_neg), sum(false_neg)]])\n",
    "    \n",
    "    return randomForestMetrics, avg_cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.9945220588235294\n",
      "F1 Score:0.9922207166178525\n",
      "ROC_AUC_Score:0.9928157906449616\n",
      "Recall:0.9868400515345381\n",
      "Precision:0.9977647352647352\n",
      "[[1657    2]\n",
      " [  12  883]]\n"
     ]
    }
   ],
   "source": [
    "randomForestMetrics, cm = RandomForest(X, y)\n",
    "\n",
    "Classifiers = {'Random Forest': randomForestMetrics}\n",
    "\n",
    "for metric, score in randomForestMetrics.items():\n",
    "    print(f'{metric}:{score}')\n",
    "    \n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Model Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lmt import LinearModelTree\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statistics import median\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def LogisticModelTree(X, y, kfold=10, seed=101):\n",
    "    \n",
    "    shared_scaler = StandardScaler()\n",
    "    shared_scaler.fit(X)\n",
    "\n",
    "    def fit_linear_model(x, y):\n",
    "        lr = Ridge()\n",
    "        lr.fit(shared_scaler.transform(x), y)\n",
    "        return SharedScalerModel(shared_scaler, lr)\n",
    "\n",
    "    class SharedScalerModel:\n",
    "\n",
    "        def __init__(self, scaler, lm):\n",
    "            self.scaler = scaler\n",
    "            self.lm = lm\n",
    "            self.coef_ = lm.coef_\n",
    "            self.intercept_ = lm.intercept_\n",
    "\n",
    "        def predict(self, X):\n",
    "            return self.lm.predict(self.scaler.transform(X))\n",
    "\n",
    "\n",
    "    MIN_NODE_SIZE = 100\n",
    "    MIN_SPLIT_IMPROVEMENT = 10\n",
    "    lmt = LinearModelTree(MIN_NODE_SIZE, fit_linear_model, min_split_improvement=MIN_SPLIT_IMPROVEMENT)\n",
    "    \n",
    "    def GetThreshold(lmt, X, y, kfold=10, seed=101):\n",
    "        \n",
    "        pred_class = []\n",
    "\n",
    "        kf = KFold(n_splits=kfold,shuffle=True, random_state=seed)\n",
    "        fold = 0\n",
    "        best_thresholds_roc_auc, best_thresholds_f1 = [], []\n",
    "        threshold_list = [0.05,0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5,0.55,0.6,0.65,0.7,0.75,0.8,0.85,0.9,0.95,0.99]\n",
    "        for train_index, test_index in kf.split(X):\n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            lmt.build_tree(X_train.values, X_train, y_train.values)\n",
    "            pred = lmt.predict(X_test.values, X_test)\n",
    "\n",
    "            pred = [round(i, 2) for i in pred]\n",
    "\n",
    "        #     preds.append(pred)\n",
    "\n",
    "\n",
    "            pred_threshold = []\n",
    "\n",
    "            for threshold in threshold_list:\n",
    "                pred_threshold.append([1 if x>threshold else 0 for x in pred])\n",
    "\n",
    "            best_kfold_f1, best_kfold_roc_auc = [0 for i in range(10)], [0 for i in range(10)]\n",
    "\n",
    "            for c, value in enumerate(pred_threshold):\n",
    "                f1 = f1_score(y_test, value)\n",
    "                roc_auc = roc_auc_score(y_test, value)\n",
    "\n",
    "\n",
    "                if c == 0:\n",
    "                    best_kfold_f1[0], best_kfold_roc_auc[0] = f1, roc_auc\n",
    "                    best_kfold_f1[1], best_kfold_roc_auc[1] = threshold_list[c], threshold_list[c]\n",
    "\n",
    "                if best_kfold_f1[0] < f1:\n",
    "                    best_kfold_f1[0] = f1\n",
    "                    best_kfold_f1[1] = threshold_list[c]\n",
    "\n",
    "                if best_kfold_roc_auc[0] < roc_auc:\n",
    "                    best_kfold_roc_auc[0] = roc_auc\n",
    "                    best_kfold_roc_auc[1] = threshold_list[c]\n",
    "\n",
    "                if c == (len(pred_threshold) - 1):\n",
    "                    best_thresholds_roc_auc.append(best_kfold_roc_auc[1])\n",
    "                    best_thresholds_f1.append(best_kfold_f1[1])\n",
    "                    \n",
    "                    \n",
    "\n",
    "            fold = fold + 1\n",
    "\n",
    "        best_threshold_roc_auc = median(best_thresholds_roc_auc)\n",
    "        best_threshold_f1 = median(best_thresholds_roc_auc)\n",
    "        \n",
    "        \n",
    "        \n",
    "        return best_threshold_roc_auc\n",
    "    \n",
    "    def preditions(lmt, X, y, threshold, kfold=10, seed=101):\n",
    "        \n",
    "        accuracy_score_avg, f1_score_avg, roc_auc_score_avg, recall_score_avg, precision_score_avg = np.empty(kfold), np.empty(kfold), \\\n",
    "                                                                                    np.empty(kfold), np.empty(kfold), np.empty(kfold)\n",
    "        LMTMetrics = {'Accuracy': accuracy_score_avg, 'F1 Score': f1_score_avg, 'ROC_AUC_Score': roc_auc_score_avg, \n",
    "                  'Recall': recall_score_avg, 'Precision': precision_score_avg}\n",
    "        \n",
    "        kf = KFold(n_splits=kfold,shuffle=True, random_state=seed)\n",
    "        \n",
    "        cm_holder = []\n",
    "        count = 0             \n",
    "        for train_index, test_index in kf.split(X):\n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            lmt.build_tree(X_train.values, X_train, y_train.values)\n",
    "            pred = lmt.predict(X_test.values, X_test)\n",
    "\n",
    "            pred = [round(i, 2) for i in pred]\n",
    "\n",
    "            #use the threshold that we estabished in the previous run of the algorithm \n",
    "            pred_threshold = [1 if x>threshold else 0 for x in pred]\n",
    "            accuracy_score_avg[count] = accuracy_score(y_test, pred_threshold)\n",
    "            f1_score_avg[count] = f1_score(y_test, pred_threshold)\n",
    "            roc_auc_score_avg[count] = roc_auc_score(y_test, pred_threshold)\n",
    "            recall_score_avg[count] = recall_score(y_test, pred_threshold)\n",
    "            precision_score_avg[count] = precision_score(y_test, pred_threshold)\n",
    "            cm_holder.append(confusion_matrix(y_test, pred_threshold))\n",
    "\n",
    "            count = count + 1\n",
    "\n",
    "\n",
    "        #if for any reason a metric in the folds returns 0.0\n",
    "        #remove it from the list\n",
    "        for key, values in LMTMetrics.items():\n",
    "            LMTMetrics[key] = np.array([value for value in LMTMetrics[key] if value != 0.0])\n",
    "            LMTMetrics[key] = LMTMetrics[key].mean()  \n",
    "\n",
    "        true_pos, true_neg, false_pos, false_neg = [], [], [], []\n",
    "\n",
    "        for cm in cm_holder:\n",
    "            true_pos.append(cm[0][0])\n",
    "            false_pos.append(cm[0][1])\n",
    "            true_neg.append(cm[1][0])\n",
    "            false_neg.append(cm[1][1])\n",
    "\n",
    "        avg_cm = np.matrix([[sum(true_pos), sum(false_pos)], [sum(true_neg), sum(false_neg)]])\n",
    "        \n",
    "        return LMTMetrics, avg_cm\n",
    "    \n",
    "    threshold = GetThreshold(lmt, X, y, kfold)\n",
    "    return preditions(lmt, X, y, threshold, kfold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we know the best threshold to use based off the ROC_auc score, we can use this threshold now with the algorithm again to get the best representation on the performance of our classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.9882536764705883\n",
      "F1 Score:0.9829893887344359\n",
      "ROC_AUC_Score:0.9889400473914189\n",
      "Recall:0.9910343562463803\n",
      "Precision:0.9751616756311197\n",
      "[[1637   22]\n",
      " [   8  887]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "LMTMetrics, cm = LogisticModelTree(X, y)\n",
    "\n",
    "Classifiers['LMT'] = LMTMetrics\n",
    "\n",
    "for metric, score in LMTMetrics.items():\n",
    "    print(f'{metric}:{score}')\n",
    "    \n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will be using the cut off point that has the highest roc_auc score depicting the the usefulness of the test. As the data is imballanced the accuracy cannot be taken as a useful metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logitboost \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from logitboost import LogitBoost\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def LogitBoostClassifier(X, y, kfold=10, seed=101):\n",
    "    accuracy_score_avg, f1_score_avg, roc_auc_score_avg, recall_score_avg, precision_score_avg = np.empty(kfold), np.empty(kfold), \\\n",
    "          np.empty(kfold), np.empty(kfold), np.empty(kfold)\n",
    "\n",
    "    LogitboostMetrics = {'Accuracy': accuracy_score_avg, 'F1 Score': f1_score_avg, 'ROC_AUC_Score': roc_auc_score_avg, \n",
    "                         'Recall': recall_score_avg, 'Precision': precision_score_avg}\n",
    "    \n",
    "    lboost = LogitBoost()\n",
    "    count = 0\n",
    "    cm_holder = []\n",
    "    kf = KFold(n_splits=kfold,shuffle=True, random_state=seed)\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]    \n",
    "\n",
    "        lboost.fit(X_train, y_train)\n",
    "        pred = lboost.predict(X_test)\n",
    "        accuracy_score_avg[count] = accuracy_score(y_test, pred)\n",
    "        f1_score_avg[count] = f1_score(y_test, pred)\n",
    "        roc_auc_score_avg[count] = roc_auc_score(y_test, pred)\n",
    "        recall_score_avg[count] = recall_score(y_test, pred)\n",
    "        precision_score_avg[count] = precision_score(y_test, pred)\n",
    "        cm_holder.append(confusion_matrix(y_test, pred))\n",
    "\n",
    "        count = count + 1\n",
    "    #if for any reason a metric in a fold returns 0.0\n",
    "    #remove it from the list\n",
    "    for key, values in LogitboostMetrics.items():\n",
    "        LogitboostMetrics[key] = np.array([value for value in LogitboostMetrics[key] if value != 0.0])\n",
    "        LogitboostMetrics[key] = LogitboostMetrics[key].mean() \n",
    "\n",
    "    \n",
    "\n",
    "    true_pos, true_neg, false_pos, false_neg = [], [], [], []\n",
    "\n",
    "    for cm in cm_holder:\n",
    "        true_pos.append(cm[0][0])\n",
    "        false_pos.append(cm[0][1])\n",
    "        true_neg.append(cm[1][0])\n",
    "        false_neg.append(cm[1][1])\n",
    "\n",
    "    avg_cm = np.matrix([[sum(true_pos), sum(false_pos)], [sum(true_neg), sum(false_neg)]])\n",
    "    \n",
    "    return LogitboostMetrics, avg_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.9941299019607843\n",
      "F1 Score:0.991595705121993\n",
      "ROC_AUC_Score:0.9938450123969682\n",
      "Recall:0.992455567783009\n",
      "Precision:0.9908024412236103\n",
      "[[1651    8]\n",
      " [   7  888]]\n"
     ]
    }
   ],
   "source": [
    "LogitboostMetrics, cm = LogitBoostClassifier(X, y)\n",
    "\n",
    "Classifiers['Logitboost'] = LogitboostMetrics\n",
    "\n",
    "for metric, score in LogitboostMetrics.items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "        \n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent (SGD) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "def SGD(X, y, kfold=10, seed=101):\n",
    "    kf = KFold(n_splits=kfold,shuffle=True, random_state=seed)\n",
    "    \n",
    "    accuracy_score_avg, f1_score_avg, roc_auc_score_avg, recall_score_avg, precision_score_avg = np.empty(kfold), np.empty(kfold), \\\n",
    "                                                                                    np.empty(kfold), np.empty(kfold), np.empty(kfold)\n",
    "    SGDMetrics = {'Accuracy': accuracy_score_avg, 'F1 Score': f1_score_avg, 'ROC_AUC_Score': roc_auc_score_avg, \n",
    "                           'Recall': recall_score_avg, 'Precision': precision_score_avg}\n",
    "    \n",
    "    ## create array to hold all confusion matrices \n",
    "    cm_holder = []\n",
    "    count = 0 \n",
    "    for train_index, test_index in kf.split(X):\n",
    "\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        clf = SGDClassifier()\n",
    "        clf.fit(X_train, y_train.ravel())\n",
    "        pred = clf.predict(X_test)\n",
    "        \n",
    "        accuracy_score_avg[count] = accuracy_score(y_test, pred)\n",
    "        f1_score_avg[count] = f1_score(y_test, pred)\n",
    "        roc_auc_score_avg[count] = roc_auc_score(y_test, pred)\n",
    "        recall_score_avg[count] = recall_score(y_test, pred)\n",
    "        precision_score_avg[count] = precision_score(y_test, pred)\n",
    "        cm_holder.append(confusion_matrix(y_test, pred))\n",
    "\n",
    "        count = count + 1\n",
    "        \n",
    "    #if for any reason a metric in the folds returns 0.0\n",
    "    #remove it from the list\n",
    "    for key, values in SGDMetrics.items():\n",
    "        SGDMetrics[key] = np.array([value for value in SGDMetrics[key] if value != 0.0])\n",
    "        SGDMetrics[key] = SGDMetrics[key].mean()  \n",
    "    \n",
    "    \n",
    "    true_pos, true_neg, false_pos, false_neg = [], [], [], []\n",
    "\n",
    "    for cm in cm_holder:\n",
    "        true_pos.append(cm[0][0])\n",
    "        false_pos.append(cm[0][1])\n",
    "        true_neg.append(cm[1][0])\n",
    "        false_neg.append(cm[1][1])\n",
    "    \n",
    "    avg_cm = np.matrix([[sum(true_pos), sum(false_pos)], [sum(true_neg), sum(false_neg)]])\n",
    "    \n",
    "    return SGDMetrics, avg_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.9937392769607843\n",
      "F1 Score:0.9906355715792635\n",
      "ROC_AUC_Score:0.9932619582159902\n",
      "Recall:0.9911222344496758\n",
      "Precision:0.9902507215007216\n",
      "[[1651    8]\n",
      " [   8  887]]\n"
     ]
    }
   ],
   "source": [
    "SGDMetrics, cm = SGD(X, y)\n",
    "Classifiers['SGD'] = SGDMetrics\n",
    "\n",
    "for metric, score in SGDMetrics.items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "        \n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "def SVM(X, y, kfold=10, seed=101):\n",
    "    accuracy_score_avg, f1_score_avg, roc_auc_score_avg, recall_score_avg, precision_score_avg  = np.empty(kfold), np.empty(kfold), \\\n",
    "                                                                                    np.empty(kfold), np.empty(kfold), np.empty(kfold)\n",
    "    cm_holder = []\n",
    "    SVCMetrics = {'Accuracy': accuracy_score_avg, 'F1 Score': f1_score_avg, 'ROC_AUC_Score': roc_auc_score_avg, \n",
    "                         'Recall': recall_score_avg, 'Precision': precision_score_avg}\n",
    "    \n",
    "\n",
    "    svc = SVC()\n",
    "    count = 0\n",
    "    kf = KFold(n_splits=kfold,shuffle=True, random_state=seed)\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        svc.fit(X_train, y_train)\n",
    "        pred = svc.predict(X_test)\n",
    "        accuracy_score_avg[count] = accuracy_score(y_test, pred)\n",
    "        f1_score_avg[count] = f1_score(y_test, pred)\n",
    "        roc_auc_score_avg[count] = roc_auc_score(y_test, pred)\n",
    "        recall_score_avg[count] = recall_score(y_test, pred)\n",
    "        precision_score_avg[count] = precision_score(y_test, pred)\n",
    "        cm_holder.append(confusion_matrix(y_test, pred))\n",
    "\n",
    "        count = count + 1\n",
    "\n",
    "    for key, values in SVCMetrics.items():\n",
    "        SVCMetrics[key] = np.array([value for value in SVCMetrics[key] if value != 0.0])\n",
    "        SVCMetrics[key] = SVCMetrics[key].mean()\n",
    "\n",
    "\n",
    "    true_pos, true_neg, false_pos, false_neg = [], [], [], []\n",
    "\n",
    "    for cm in cm_holder:\n",
    "        true_pos.append(cm[0][0])\n",
    "        false_pos.append(cm[0][1])\n",
    "        true_neg.append(cm[1][0])\n",
    "        false_neg.append(cm[1][1])\n",
    "\n",
    "    avg_cm = np.matrix([[sum(true_pos), sum(false_pos)], [sum(true_neg), sum(false_neg)]])\n",
    "    \n",
    "    return SVCMetrics, avg_cm\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.9937392769607843\n",
      "F1 Score:0.9911192159375789\n",
      "ROC_AUC_Score:0.9928445362632801\n",
      "Recall:0.989258041480056\n",
      "Precision:0.9930490101522091\n",
      "[[1653    6]\n",
      " [  10  885]]\n"
     ]
    }
   ],
   "source": [
    "SVCMetrics, cm = SVM(X, y)\n",
    "\n",
    "Classifiers['SVC'] = SVCMetrics\n",
    "\n",
    "for metric, score in SVCMetrics.items():\n",
    "        print(f'{metric}:{score}')\n",
    "        \n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artificial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "\n",
    "def ANN(X, y, kfold=10, seed=101):\n",
    "    accuracy_score_avg, f1_score_avg, roc_auc_score_avg, recall_score_avg, precision_score_avg  = np.empty(kfold), np.empty(kfold), \\\n",
    "                                                                                    np.empty(kfold), np.empty(kfold), np.empty(kfold)\n",
    "    cm_holder = []\n",
    "    ANNMetrics = {'Accuracy': accuracy_score_avg, 'F1 Score': f1_score_avg, 'ROC_AUC_Score': roc_auc_score_avg, \n",
    "                         'Recall': recall_score_avg, 'Precision': precision_score_avg}\n",
    "    \n",
    "\n",
    "\n",
    "    def DL_Model(activation= 'linear', neurons= 5, optimizer='Adam'):\n",
    "        n_cols = X_train.shape[1]\n",
    "        model = Sequential()\n",
    "        model.add(Dense(250, activation='relu', input_shape=(n_cols,)))\n",
    "        model.add(Dense(250, activation='relu'))\n",
    "        model.add(Dropout(0.3))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.compile(loss='binary_crossentropy', optimizer= 'adam', metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    ANN = KerasClassifier(build_fn= DL_Model, epochs= 80, batch_size=100, verbose= 0)\n",
    "    kf = KFold(n_splits=kfold,shuffle=True, random_state=seed)\n",
    "    count = 0\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "\n",
    "        ANN.fit(X_train.values, y_train)\n",
    "        pred = ANN.predict(X_test)\n",
    "        accuracy_score_avg[count] = accuracy_score(y_test, pred)\n",
    "        f1_score_avg[count] = f1_score(y_test, pred)\n",
    "        roc_auc_score_avg[count] = roc_auc_score(y_test, pred)\n",
    "        recall_score_avg[count] = recall_score(y_test, pred)\n",
    "        precision_score_avg[count] = precision_score(y_test, pred)\n",
    "        cm_holder.append(confusion_matrix(y_test, pred))\n",
    "\n",
    "        count = count + 1\n",
    "\n",
    "    for key, values in ANNMetrics.items():\n",
    "        ANNMetrics[key] = np.array([value for value in ANNMetrics[key] if value != 0.0])\n",
    "        ANNMetrics[key] = ANNMetrics[key].mean()\n",
    "\n",
    "    \n",
    "\n",
    "    true_pos, true_neg, false_pos, false_neg = [], [], [], []\n",
    "\n",
    "    for cm in cm_holder:\n",
    "        true_pos.append(cm[0][0])\n",
    "        false_pos.append(cm[0][1])\n",
    "        true_neg.append(cm[1][0])\n",
    "        false_neg.append(cm[1][1])\n",
    "\n",
    "    avg_cm = np.matrix([[sum(true_pos), sum(false_pos)], [sum(true_neg), sum(false_neg)]])\n",
    "    \n",
    "    return ANNMetrics, avg_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.9949126838235294\n",
      "F1 Score:0.9924915135435173\n",
      "ROC_AUC_Score:0.9943166477318333\n",
      "Recall:0.9921531622847274\n",
      "Precision:0.992891710616831\n"
     ]
    }
   ],
   "source": [
    "ANNMetrics, cm = ANN(X, y)\n",
    "\n",
    "Classifiers['ANN'] = ANNMetrics\n",
    "\n",
    "for metric, score in ANNMetrics.items():\n",
    "        print(f'{metric}:{score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "def deepLearn(X, y, kfold=10, seed=101):\n",
    "    accuracy_score_avg, f1_score_avg, roc_auc_score_avg, recall_score_avg, precision_score_avg  = np.empty(kfold), np.empty(kfold), \\\n",
    "                                                                                    np.empty(kfold), np.empty(kfold), np.empty(kfold)\n",
    "    cm_holder = []\n",
    "    DeepLearnMetrics = {'Accuracy': accuracy_score_avg, 'F1 Score': f1_score_avg, 'ROC_AUC_Score': roc_auc_score_avg, \n",
    "                         'Recall': recall_score_avg, 'Precision': precision_score_avg}\n",
    "\n",
    "\n",
    "\n",
    "    def DL_Model():\n",
    "        n_cols = X_train.shape[1]\n",
    "        model = Sequential()\n",
    "        model.add(Dense(250, activation='relu', input_shape=(n_cols,)))\n",
    "        model.add(Dense(250, activation='relu'))\n",
    "        model.add(Dense(250, activation='relu'))\n",
    "        model.add(Dense(2, activation='softmax'))\n",
    "        model.compile(loss='categorical_crossentropy', optimizer= 'adam', metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    deepLearn = KerasClassifier(build_fn= DL_Model, epochs= 80, batch_size=40, verbose= 0)\n",
    "    cm_holder = []\n",
    "    count = 0\n",
    "    kf = KFold(n_splits=kfold,shuffle=True, random_state=seed)\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        train_y_2 = to_categorical(y_train)\n",
    "        deepLearn.fit(X_train, train_y_2)\n",
    "        pred = deepLearn.predict(X_test)\n",
    "        accuracy_score_avg[count] = accuracy_score(y_test, pred)\n",
    "        f1_score_avg[count] = f1_score(y_test, pred)\n",
    "        roc_auc_score_avg[count] = roc_auc_score(y_test, pred)\n",
    "        recall_score_avg[count] = recall_score(y_test, pred)\n",
    "        precision_score_avg[count] = precision_score(y_test, pred)\n",
    "        cm_holder.append(confusion_matrix(y_test, pred))\n",
    "\n",
    "        count = count + 1\n",
    "\n",
    "    for key, values in DeepLearnMetrics.items():\n",
    "        DeepLearnMetrics[key] = np.array([value for value in DeepLearnMetrics[key] if value != 0.0])\n",
    "        DeepLearnMetrics[key] = DeepLearnMetrics[key].mean()\n",
    "\n",
    "    \n",
    "\n",
    "    true_pos, true_neg, false_pos, false_neg = [], [], [], []\n",
    "\n",
    "    for cm in cm_holder:\n",
    "        true_pos.append(cm[0][0])\n",
    "        false_pos.append(cm[0][1])\n",
    "        true_neg.append(cm[1][0])\n",
    "        false_neg.append(cm[1][1])\n",
    "\n",
    "    avg_cm = np.matrix([[sum(true_pos), sum(false_pos)], [sum(true_neg), sum(false_neg)]])\n",
    "    \n",
    "    return DeepLearnMetrics, avg_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.9945220588235294\n",
      "F1 Score:0.9918380919099631\n",
      "ROC_AUC_Score:0.9940404046379104\n",
      "Recall:0.9921531622847274\n",
      "Precision:0.9915934650027959\n",
      "[[1652    7]\n",
      " [   7  888]]\n"
     ]
    }
   ],
   "source": [
    "DeepLearnMetrics, cm = deepLearn(X, y)\n",
    "\n",
    "Classifiers['DeepLearnMetrics'] = DeepLearnMetrics\n",
    "\n",
    "for metric, score in DeepLearnMetrics.items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "        \n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****ANN****\n",
      "Accuracy: 0.9949126838235294\n",
      "F1 Score: 0.9924915135435173\n",
      "ROC_AUC_Score: 0.9943166477318333\n",
      "Recall: 0.9921531622847274\n",
      "Precision: 0.992891710616831\n",
      "\n",
      "****Random Forest****\n",
      "Accuracy: 0.9945220588235294\n",
      "F1 Score: 0.9922844221532741\n",
      "ROC_AUC_Score: 0.9928725378927201\n",
      "Recall: 0.9869535460300553\n",
      "Precision: 0.997777503395481\n",
      "\n",
      "****DeepLearnMetrics****\n",
      "Accuracy: 0.9945220588235294\n",
      "F1 Score: 0.9918380919099631\n",
      "ROC_AUC_Score: 0.9940404046379104\n",
      "Recall: 0.9921531622847274\n",
      "Precision: 0.9915934650027959\n",
      "\n",
      "****Logitboost****\n",
      "Accuracy: 0.9941299019607843\n",
      "F1 Score: 0.991595705121993\n",
      "ROC_AUC_Score: 0.9938450123969682\n",
      "Recall: 0.992455567783009\n",
      "Precision: 0.9908024412236103\n",
      "\n",
      "****SVC****\n",
      "Accuracy: 0.9937392769607843\n",
      "F1 Score: 0.9911192159375789\n",
      "ROC_AUC_Score: 0.9928445362632801\n",
      "Recall: 0.989258041480056\n",
      "Precision: 0.9930490101522091\n",
      "\n",
      "****SGD****\n",
      "Accuracy: 0.9937392769607843\n",
      "F1 Score: 0.9906355715792635\n",
      "ROC_AUC_Score: 0.9932619582159902\n",
      "Recall: 0.9911222344496758\n",
      "Precision: 0.9902507215007216\n",
      "\n",
      "****LMT****\n",
      "Accuracy: 0.9882536764705883\n",
      "F1 Score: 0.9829893887344359\n",
      "ROC_AUC_Score: 0.9889400473914189\n",
      "Recall: 0.9910343562463803\n",
      "Precision: 0.9751616756311197\n"
     ]
    }
   ],
   "source": [
    "sortedClassifiers = sorted(Classifiers.items(), key = lambda x: x[1]['F1 Score'], reverse=True) \n",
    "\n",
    "for classifier in sortedClassifiers:\n",
    "    print(f'\\n****{classifier[0]}****')\n",
    "    for metric, result in classifier[1].items():\n",
    "        print(f'{metric}: {result}')\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old number of features: 1090\n",
      "             New number of features: 485\n",
      "             Number of features removed 605\n",
      "Old number of features: 1090\n",
      "             New number of features: 377\n",
      "             Number of features removed 713\n",
      "Old number of features: 1090\n",
      "             New number of features: 276\n",
      "             Number of features removed 814\n",
      "Old number of features: 1090\n",
      "             New number of features: 172\n",
      "             Number of features removed 918\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "def getVarianceFeatures(X, y, var):\n",
    "    variancefs = VarianceThreshold(threshold=var).fit(X)\n",
    "    cols = variancefs.get_support(indices=True)\n",
    "    new_X = X.iloc[:,cols]\n",
    "    lostFeatures = X.shape[1] - new_X.shape[1]\n",
    "    \n",
    "    print(f'Old number of features: {X.shape[1]}\\n \\\n",
    "            New number of features: {new_X.shape[1]}\\n \\\n",
    "            Number of features removed {lostFeatures}')\n",
    "    \n",
    "    return new_X\n",
    "\n",
    "bestVarFeatures = []\n",
    "variance = [0.05, 0.1, 0.15, 0.2]\n",
    "for i in variance:\n",
    "    bestVarFeatures.append(getVarianceFeatures(X, y, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "RandomForestVar, LogisticModelVar, LogitBoostVar, SGDVar, SVMVar, ANNVar, DeepLearnVar = [], [], [], [], [], [], []\n",
    "\n",
    "for X in bestVarFeatures:\n",
    "    RandomForestVar.append(RandomForest(X, y))\n",
    "    LogisticModelVar.append(LogisticModelTree(X, y))\n",
    "    LogitBoostVar.append(LogitBoostClassifier(X, y))\n",
    "    SGDVar.append(SGD(X, y))\n",
    "    SVMVar.append(SVM(X, y))\n",
    "    ANNVar.append(ANN(X, y))\n",
    "    DeepLearnVar.append(deepLearn(X, y))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*RandomForest Results**\n",
      "\n",
      "**0.05**\n",
      "Accuracy:0.9949142156862745\n",
      "F1 Score:0.992818822179172\n",
      "ROC_AUC_Score:0.9933344449490509\n",
      "Recall:0.9879038813217722\n",
      "Precision:0.9978594322344323\n",
      "\n",
      "**0.1**\n",
      "Accuracy:0.9945220588235294\n",
      "F1 Score:0.9922602705612983\n",
      "ROC_AUC_Score:0.9930332401297737\n",
      "Recall:0.9879038813217722\n",
      "Precision:0.9967230685980686\n",
      "\n",
      "**0.15**\n",
      "Accuracy:0.992953431372549\n",
      "F1 Score:0.9900774915258899\n",
      "ROC_AUC_Score:0.9913605430270718\n",
      "Recall:0.9857701848060533\n",
      "Precision:0.9945258753601923\n",
      "\n",
      "**0.2**\n",
      "Accuracy:0.9929564950980392\n",
      "F1 Score:0.9899523409421876\n",
      "ROC_AUC_Score:0.9913750913399507\n",
      "Recall:0.9857493579811027\n",
      "Precision:0.9943419673142152\n",
      "\n",
      "**LMT Results**\n",
      "\n",
      "**0.05**\n",
      "Accuracy:0.9933486519607844\n",
      "F1 Score:0.990202097703294\n",
      "ROC_AUC_Score:0.9927938189542991\n",
      "Recall:0.9909202414520998\n",
      "Precision:0.9895195212562067\n",
      "\n",
      "**0.1**\n",
      "Accuracy:0.9929564950980392\n",
      "F1 Score:0.9897695916742695\n",
      "ROC_AUC_Score:0.9925479061864694\n",
      "Recall:0.991062468731292\n",
      "Precision:0.9885041232940786\n",
      "\n",
      "**0.15**\n",
      "Accuracy:0.9890456495098039\n",
      "F1 Score:0.9838522518901206\n",
      "ROC_AUC_Score:0.98877708073768\n",
      "Recall:0.9875939582177974\n",
      "Precision:0.9802437150248805\n",
      "\n",
      "**0.2**\n",
      "Accuracy:0.9890395220588235\n",
      "F1 Score:0.9840294342169201\n",
      "ROC_AUC_Score:0.9891638966393554\n",
      "Recall:0.988260424864462\n",
      "Precision:0.9801509610549202\n",
      "\n",
      "**LogitBoost Results**\n",
      "\n",
      "**0.05**\n",
      "Accuracy:0.9941299019607843\n",
      "F1 Score:0.991595705121993\n",
      "ROC_AUC_Score:0.9938450123969682\n",
      "Recall:0.992455567783009\n",
      "Precision:0.9908024412236103\n",
      "\n",
      "**0.1**\n",
      "Accuracy:0.9953033088235295\n",
      "F1 Score:0.9933123424967496\n",
      "ROC_AUC_Score:0.9944723348356979\n",
      "Recall:0.9913319722773911\n",
      "Precision:0.9953589417091117\n",
      "\n",
      "**0.15**\n",
      "Accuracy:0.9913909313725491\n",
      "F1 Score:0.9873027050693421\n",
      "ROC_AUC_Score:0.991069803809847\n",
      "Recall:0.9891012076047232\n",
      "Precision:0.9857538816855408\n",
      "\n",
      "**0.2**\n",
      "Accuracy:0.9890425857843137\n",
      "F1 Score:0.9838955787380268\n",
      "ROC_AUC_Score:0.9887181854790527\n",
      "Recall:0.9867802858161543\n",
      "Precision:0.9813982356296187\n",
      "\n",
      "**SGD Results**\n",
      "**0.05**\n",
      "Accuracy:0.9953048406862746\n",
      "F1 Score:0.9931582183446833\n",
      "ROC_AUC_Score:0.9947572601066419\n",
      "Recall:0.9924226658308266\n",
      "Precision:0.9940332881404311\n",
      "**0.1**\n",
      "Accuracy:0.9941314338235294\n",
      "F1 Score:0.9913219504200186\n",
      "ROC_AUC_Score:0.9934456199468633\n",
      "Recall:0.9910012223484657\n",
      "Precision:0.9917217581478326\n",
      "**0.15**\n",
      "Accuracy:0.9929580269607843\n",
      "F1 Score:0.9893492516652838\n",
      "ROC_AUC_Score:0.9930652449603157\n",
      "Recall:0.9930959799707513\n",
      "Precision:0.9858076114987597\n",
      "**0.2**\n",
      "Accuracy:0.9886550245098039\n",
      "F1 Score:0.9831059700201086\n",
      "ROC_AUC_Score:0.9888692609993894\n",
      "Recall:0.9880852747188438\n",
      "Precision:0.9786014180751023\n",
      "\n",
      "**SVM Results**\n",
      "\n",
      "**0.05**\n",
      "Accuracy:0.9949111519607843\n",
      "F1 Score:0.9929472735977237\n",
      "ROC_AUC_Score:0.9937103202089158\n",
      "Recall:0.989258041480056\n",
      "Precision:0.9967338074296836\n",
      "\n",
      "**0.1**\n",
      "Accuracy:0.9941283700980392\n",
      "F1 Score:0.9918405455664467\n",
      "ROC_AUC_Score:0.992839880480798\n",
      "Recall:0.9881344459744381\n",
      "Precision:0.9956337892569518\n",
      "\n",
      "**0.15**\n",
      "Accuracy:0.9906035539215686\n",
      "F1 Score:0.9865486635081325\n",
      "ROC_AUC_Score:0.9901902714614839\n",
      "Recall:0.9881344459744381\n",
      "Precision:0.9851796578765176\n",
      "\n",
      "**0.2**\n",
      "Accuracy:0.9890395220588235\n",
      "F1 Score:0.9845188124864093\n",
      "ROC_AUC_Score:0.9878275167632868\n",
      "Recall:0.9828636249714118\n",
      "Precision:0.9863763936647919\n",
      "\n",
      "**ANN Results**\n",
      "\n",
      "**0.05**\n",
      "Accuracy:0.9949126838235294\n",
      "F1 Score:0.9923786013688787\n",
      "ROC_AUC_Score:0.9945723195315278\n",
      "Recall:0.9932169920719615\n",
      "Precision:0.9915934650027959\n",
      "\n",
      "**0.1**\n",
      "Accuracy:0.9941314338235294\n",
      "F1 Score:0.9912093151665367\n",
      "ROC_AUC_Score:0.993759505761506\n",
      "Recall:0.9921531622847274\n",
      "Precision:0.9903438707152269\n",
      "\n",
      "**0.15**\n",
      "Accuracy:0.9937377450980392\n",
      "F1 Score:0.9906355739875258\n",
      "ROC_AUC_Score:0.9932355361805019\n",
      "Recall:0.9910749531257987\n",
      "Precision:0.9903232584678318\n",
      "\n",
      "**0.2**\n",
      "Accuracy:0.9898192401960785\n",
      "F1 Score:0.9852009028472107\n",
      "ROC_AUC_Score:0.9891845490033976\n",
      "Recall:0.9859480660461226\n",
      "Precision:0.9846871421192572\n",
      "\n",
      "**DeepLearn Results**\n",
      "\n",
      "**0.05**\n",
      "Accuracy:0.9945235906862745\n",
      "F1 Score:0.9918221987470922\n",
      "ROC_AUC_Score:0.9940482524530789\n",
      "Recall:0.9921531622847274\n",
      "Precision:0.9915789400540603\n",
      "\n",
      "**0.1**\n",
      "Accuracy:0.9949142156862745\n",
      "F1 Score:0.9924670227275731\n",
      "ROC_AUC_Score:0.9943244955470014\n",
      "Recall:0.9921531622847274\n",
      "Precision:0.992843465002796\n",
      "\n",
      "**0.15**\n",
      "Accuracy:0.9941299019607843\n",
      "F1 Score:0.9912831963030143\n",
      "ROC_AUC_Score:0.9933049573322073\n",
      "Recall:0.9900440252907471\n",
      "Precision:0.9926191894871671\n",
      "\n",
      "**0.2**\n",
      "Accuracy:0.991780024509804\n",
      "F1 Score:0.9878695416456905\n",
      "ROC_AUC_Score:0.9911382855309132\n",
      "Recall:0.9880334358734281\n",
      "Precision:0.9879341281081787\n"
     ]
    }
   ],
   "source": [
    "print('*RandomForest Results**')\n",
    "for c, i in enumerate(variance): \n",
    "    print(f'\\n**{i}**')\n",
    "    for metric, score in RandomForestVar[c][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "\n",
    "print('\\n**LMT Results**')\n",
    "for c, i in enumerate(variance): \n",
    "    print(f'\\n**{i}**')\n",
    "    for metric, score in LogisticModelVar[c][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "\n",
    "print('\\n**LogitBoost Results**')\n",
    "for c, i in enumerate(variance): \n",
    "    print(f'\\n**{i}**')\n",
    "    for metric, score in LogitBoostVar[c][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "        \n",
    "print('\\n**SGD Results**')\n",
    "for c, i in enumerate(variance): \n",
    "    print(f'**{i}**')\n",
    "    for metric, score in SGDVar[c][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "\n",
    "print('\\n**SVM Results**')\n",
    "for c, i in enumerate(variance): \n",
    "    print(f'\\n**{i}**')\n",
    "    for metric, score in SVMVar[c][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "        \n",
    "print('\\n**ANN Results**')\n",
    "for c, i in enumerate(variance): \n",
    "    print(f'\\n**{i}**')\n",
    "    for metric, score in ANNVar[c][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "\n",
    "print('\\n**DeepLearn Results**')\n",
    "for c, i in enumerate(variance): \n",
    "    print(f'\\n**{i}**')\n",
    "    for metric, score in DeepLearnVar[c][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi2  Info Gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.feature_selection import chi2, mutual_info_classif\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# fschi2 = SelectKBest(chi2, k='all')\n",
    "# fschi2.fit(X, y)\n",
    "# fschi2.transform(X)\n",
    "# fs_info_gain = SelectKBest(mutual_info_classif, k='all')\n",
    "# fs_info_gain.fit(X, y)\n",
    "# fs_info_gain.transform(X)\n",
    "# bestfeatschi2 = []\n",
    "# bestfeats_info_gain = []\n",
    "# bestFeatsThresholdChi2 = [50, 75, 100, 150]\n",
    "# for treshold in bestFeatsThreshold:\n",
    "#     bestfeatschi2.append([i for i in fschi2.scores_ if i > treshold])\n",
    "#     bestfeats_info_gain.append([i for i in fs_info_gain.scores_ if i > treshold])\n",
    "    \n",
    "# for index,value in enumerate(bestfeatschi2):\n",
    "#     pyplot.bar([i for i in range(len(bestfeatschi2[index]))], bestfeatschi2[index])\n",
    "#     pyplot.show()\n",
    "#     pyplot.bar([i for i in range(len(bestfeats_info_gain[index]))], bestfeats_info_gain[index])\n",
    "#     pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestPercent = [2, 5, 10, 25, 40, 50, 70]\n",
    "bestChiFeatures = []\n",
    "bestInfoGainFeatures = []\n",
    "def getChi2Features(X, y, k):\n",
    "    chi2fs = SelectPercentile(score_func=chi2, percentile=k).fit(X, y)\n",
    "    cols = chi2fs.get_support(indices=True)\n",
    "    new_X = X.iloc[:,cols]\n",
    "    return new_X\n",
    "\n",
    "def getInfoGainFeatures(X, y, k):\n",
    "    InfoGainfs = SelectPercentile(score_func=mutual_info_classif, percentile=k).fit(X, y)\n",
    "    cols = InfoGainfs.get_support(indices=True)\n",
    "    new_X = X.iloc[:,cols]\n",
    "    return new_X\n",
    "\n",
    "for i in bestPercent:\n",
    "    bestChiFeatures.append(getChi2Features(X,y,i))\n",
    "    bestInfoGainFeatures.append(getInfoGainFeatures(X, y, i))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*RandomForest Results**\n",
      "\n",
      "**2**\n",
      "Accuracy:0.9526317401960783\n",
      "F1 Score:0.9354230215471955\n",
      "ROC_AUC_Score:0.9614603165080373\n",
      "Recall:0.9902227364010378\n",
      "Precision:0.887284262431059\n",
      "\n",
      "**5**\n",
      "Accuracy:0.975733762254902\n",
      "F1 Score:0.9656433558152868\n",
      "ROC_AUC_Score:0.979265055692046\n",
      "Recall:0.9902073116648065\n",
      "Precision:0.9429233070205981\n",
      "\n",
      "**10**\n",
      "Accuracy:0.9823912377450981\n",
      "F1 Score:0.9744359298319353\n",
      "ROC_AUC_Score:0.984477756990958\n",
      "Recall:0.9902073116648065\n",
      "Precision:0.9596654110280035\n",
      "\n",
      "**25**\n",
      "Accuracy:0.9878676470588236\n",
      "F1 Score:0.9820799287996806\n",
      "ROC_AUC_Score:0.9884392751469073\n",
      "Recall:0.9898243136231903\n",
      "Precision:0.9746882297650865\n",
      "\n",
      "**40**\n",
      "Accuracy:0.9866911764705882\n",
      "F1 Score:0.9807202253753543\n",
      "ROC_AUC_Score:0.9868083830292285\n",
      "Recall:0.9867065550388212\n",
      "Precision:0.9750949787921698\n",
      "\n",
      "**50**\n",
      "Accuracy:0.9925658700980392\n",
      "F1 Score:0.989275543899564\n",
      "ROC_AUC_Score:0.9908755753277199\n",
      "Recall:0.9846855281938687\n",
      "Precision:0.9941306782219194\n",
      "\n",
      "**70**\n",
      "Accuracy:0.9909957107843137\n",
      "F1 Score:0.9871673394800202\n",
      "ROC_AUC_Score:0.9892238748187369\n",
      "Recall:0.9826255624554829\n",
      "Precision:0.9919577865141438\n",
      "\n",
      "**LMT Results**\n",
      "\n",
      "**2**\n",
      "Accuracy:0.931485906862745\n",
      "F1 Score:0.9082522257389538\n",
      "ROC_AUC_Score:0.9414978493213244\n",
      "Recall:0.9739967428287374\n",
      "Precision:0.8520486444644038\n",
      "\n",
      "**5**\n",
      "Accuracy:0.969857536764706\n",
      "F1 Score:0.9578407831658948\n",
      "ROC_AUC_Score:0.9758379218913381\n",
      "Recall:0.9954666936378626\n",
      "Precision:0.9234809359451841\n",
      "\n",
      "**10**\n",
      "Accuracy:0.9647748161764707\n",
      "F1 Score:0.9509446909493191\n",
      "ROC_AUC_Score:0.9717695436910981\n",
      "Recall:0.994435765802811\n",
      "Precision:0.9117304360455318\n",
      "\n",
      "**25**\n",
      "Accuracy:0.9745572916666667\n",
      "F1 Score:0.963465052073183\n",
      "ROC_AUC_Score:0.9767695667189302\n",
      "Recall:0.9825508667885543\n",
      "Precision:0.9458220949218417\n",
      "\n",
      "**40**\n",
      "Accuracy:0.9780805759803922\n",
      "F1 Score:0.9684984786219111\n",
      "ROC_AUC_Score:0.9800737276304942\n",
      "Recall:0.9856946643143744\n",
      "Precision:0.9523821205274314\n",
      "\n",
      "**50**\n",
      "Accuracy:0.9831678921568627\n",
      "F1 Score:0.9756057668878437\n",
      "ROC_AUC_Score:0.9831572536120559\n",
      "Recall:0.9815932541733602\n",
      "Precision:0.970201672280423\n",
      "\n",
      "**70**\n",
      "Accuracy:0.9874693627450981\n",
      "F1 Score:0.9819044965846426\n",
      "ROC_AUC_Score:0.9855843376817252\n",
      "Recall:0.9782188919948742\n",
      "Precision:0.9858753543271354\n",
      "\n",
      "**LogitBoost Results**\n",
      "\n",
      "**2**\n",
      "Accuracy:0.9498897058823529\n",
      "F1 Score:0.931820788384752\n",
      "ROC_AUC_Score:0.958304154833528\n",
      "Recall:0.9851770476519874\n",
      "Precision:0.8852662022824294\n",
      "\n",
      "**5**\n",
      "Accuracy:0.9737745098039217\n",
      "F1 Score:0.9629032807272047\n",
      "ROC_AUC_Score:0.9779928937656883\n",
      "Recall:0.991238239499858\n",
      "Precision:0.9368196059847606\n",
      "\n",
      "**10**\n",
      "Accuracy:0.9820006127450981\n",
      "F1 Score:0.9736148318864867\n",
      "ROC_AUC_Score:0.9844932406469784\n",
      "Recall:0.991238239499858\n",
      "Precision:0.9573251507668278\n",
      "\n",
      "**25**\n",
      "Accuracy:0.9878676470588236\n",
      "F1 Score:0.9820418518836815\n",
      "ROC_AUC_Score:0.9891638891058954\n",
      "Recall:0.9923020692870921\n",
      "Precision:0.972542962890887\n",
      "\n",
      "**40**\n",
      "Accuracy:0.9866973039215686\n",
      "F1 Score:0.9801739879102899\n",
      "ROC_AUC_Score:0.9882948213664348\n",
      "Recall:0.9922483405099591\n",
      "Precision:0.969031424798169\n",
      "\n",
      "**50**\n",
      "Accuracy:0.9851286764705882\n",
      "F1 Score:0.9782278897570972\n",
      "ROC_AUC_Score:0.9853072163985395\n",
      "Recall:0.9846590736949421\n",
      "Precision:0.9723868653136118\n",
      "\n",
      "**70**\n",
      "Accuracy:0.9890425857843137\n",
      "F1 Score:0.983818079355091\n",
      "ROC_AUC_Score:0.9888109860309366\n",
      "Recall:0.9868937803116713\n",
      "Precision:0.9811454743678386\n",
      "\n",
      "**SGD Results**\n",
      "**2**\n",
      "Accuracy:0.9518428308823529\n",
      "F1 Score:0.9345006153162216\n",
      "ROC_AUC_Score:0.9598429722853785\n",
      "Recall:0.9859791187232615\n",
      "Precision:0.8890465243980769\n",
      "**5**\n",
      "Accuracy:0.9741636029411765\n",
      "F1 Score:0.9634284431338369\n",
      "ROC_AUC_Score:0.9780327024953424\n",
      "Recall:0.990127128388747\n",
      "Precision:0.9387903613306582\n",
      "**10**\n",
      "Accuracy:0.9812147671568627\n",
      "F1 Score:0.9726450167832208\n",
      "ROC_AUC_Score:0.9838303058391581\n",
      "Recall:0.991238239499858\n",
      "Precision:0.955253781735949\n",
      "**25**\n",
      "Accuracy:0.9851332720588235\n",
      "F1 Score:0.9780437768545989\n",
      "ROC_AUC_Score:0.9868193890203789\n",
      "Recall:0.9910285016721427\n",
      "Precision:0.9664264858930665\n",
      "**40**\n",
      "Accuracy:0.9874770220588236\n",
      "F1 Score:0.9821135001151866\n",
      "ROC_AUC_Score:0.9882475112305125\n",
      "Recall:0.9902481404899571\n",
      "Precision:0.9744220711000761\n",
      "**50**\n",
      "Accuracy:0.9909987745098039\n",
      "F1 Score:0.9868040752305459\n",
      "ROC_AUC_Score:0.9907733822037361\n",
      "Recall:0.9891445469845392\n",
      "Precision:0.98475753733164\n",
      "**70**\n",
      "Accuracy:0.9917815563725491\n",
      "F1 Score:0.9879629183894203\n",
      "ROC_AUC_Score:0.9908092697633532\n",
      "Recall:0.9868494393295185\n",
      "Precision:0.9892306403069515\n",
      "\n",
      "**SVM Results**\n",
      "\n",
      "**2**\n",
      "Accuracy:0.9530223651960783\n",
      "F1 Score:0.9359910742624875\n",
      "ROC_AUC_Score:0.9617365596019599\n",
      "Recall:0.9902227364010378\n",
      "Precision:0.8882638862555104\n",
      "\n",
      "**5**\n",
      "Accuracy:0.975733762254902\n",
      "F1 Score:0.9656433558152868\n",
      "ROC_AUC_Score:0.979265055692046\n",
      "Recall:0.9902073116648065\n",
      "Precision:0.9429233070205981\n",
      "\n",
      "**10**\n",
      "Accuracy:0.9812162990196078\n",
      "F1 Score:0.9727595981249136\n",
      "ROC_AUC_Score:0.9838244556792457\n",
      "Recall:0.9912711414520405\n",
      "Precision:0.9555192890181647\n",
      "\n",
      "**25**\n",
      "Accuracy:0.9839537377450981\n",
      "F1 Score:0.9766575509105927\n",
      "ROC_AUC_Score:0.9853908037979517\n",
      "Recall:0.9890837161591886\n",
      "Precision:0.964955096985117\n",
      "\n",
      "**40**\n",
      "Accuracy:0.9870848651960784\n",
      "F1 Score:0.980967694176546\n",
      "ROC_AUC_Score:0.9878262998533845\n",
      "Recall:0.9890837161591886\n",
      "Precision:0.9734107377082889\n",
      "\n",
      "**50**\n",
      "Accuracy:0.9898207720588236\n",
      "F1 Score:0.9855358392280591\n",
      "ROC_AUC_Score:0.9891557177392183\n",
      "Recall:0.986072590304335\n",
      "Precision:0.9853195568642896\n",
      "\n",
      "**70**\n",
      "Accuracy:0.9878630514705883\n",
      "F1 Score:0.982698292708713\n",
      "ROC_AUC_Score:0.9870511891216989\n",
      "Recall:0.983684814978748\n",
      "Precision:0.9819324134705081\n",
      "\n",
      "**ANN Results**\n",
      "\n",
      "**2**\n",
      "Accuracy:0.9530223651960783\n",
      "F1 Score:0.9360389020823361\n",
      "ROC_AUC_Score:0.9619655520352535\n",
      "Recall:0.991298005218242\n",
      "Precision:0.8874403568437457\n",
      "\n",
      "**5**\n",
      "Accuracy:0.9749494485294118\n",
      "F1 Score:0.9646202960940553\n",
      "ROC_AUC_Score:0.9786391755480934\n",
      "Recall:0.9902073116648065\n",
      "Precision:0.9409181681465274\n",
      "\n",
      "**10**\n",
      "Accuracy:0.981999080882353\n",
      "F1 Score:0.973861449553495\n",
      "ROC_AUC_Score:0.9840016468799468\n",
      "Recall:0.9892172126549056\n",
      "Precision:0.9595028023976979\n",
      "\n",
      "**25**\n",
      "Accuracy:0.9886504289215686\n",
      "F1 Score:0.9832983870949226\n",
      "ROC_AUC_Score:0.9893037778179222\n",
      "Recall:0.9909887379539587\n",
      "Precision:0.9758974193646924\n",
      "\n",
      "**40**\n",
      "Accuracy:0.9882552083333334\n",
      "F1 Score:0.9830055250941145\n",
      "ROC_AUC_Score:0.9885322799733187\n",
      "Recall:0.9882471156452045\n",
      "Precision:0.9780864523593393\n",
      "\n",
      "**50**\n",
      "Accuracy:0.9894316789215687\n",
      "F1 Score:0.9848153429226946\n",
      "ROC_AUC_Score:0.9887291527589521\n",
      "Recall:0.9858110136312039\n",
      "Precision:0.9840053694747448\n",
      "\n",
      "**70**\n",
      "Accuracy:0.9906050857843137\n",
      "F1 Score:0.9861692265202402\n",
      "ROC_AUC_Score:0.9899122771201657\n",
      "Recall:0.9868011126411048\n",
      "Precision:0.9857312142421775\n",
      "\n",
      "**DeepLearn Results**\n",
      "\n",
      "**2**\n",
      "Accuracy:0.9510631127450979\n",
      "F1 Score:0.9334064501853095\n",
      "ROC_AUC_Score:0.9594801184882353\n",
      "Recall:0.9862623403614338\n",
      "Precision:0.8870349746817713\n",
      "\n",
      "**5**\n",
      "Accuracy:0.9753416053921569\n",
      "F1 Score:0.9651603333380031\n",
      "ROC_AUC_Score:0.9789403803673707\n",
      "Recall:0.9902073116648065\n",
      "Precision:0.9419804392087985\n",
      "\n",
      "**10**\n",
      "Accuracy:0.981999080882353\n",
      "F1 Score:0.973861449553495\n",
      "ROC_AUC_Score:0.9840016468799468\n",
      "Recall:0.9892172126549056\n",
      "Precision:0.9595028023976979\n",
      "\n",
      "**25**\n",
      "Accuracy:0.9878676470588236\n",
      "F1 Score:0.9821857753866784\n",
      "ROC_AUC_Score:0.9887028593993241\n",
      "Recall:0.9909887379539587\n",
      "Precision:0.9737364342788422\n",
      "\n",
      "**40**\n",
      "Accuracy:0.9894301470588236\n",
      "F1 Score:0.9846587778732229\n",
      "ROC_AUC_Score:0.9903984887942059\n",
      "Recall:0.99258112160726\n",
      "Precision:0.9770494096914761\n",
      "\n",
      "**50**\n",
      "Accuracy:0.9921706495098039\n",
      "F1 Score:0.9886445670924863\n",
      "ROC_AUC_Score:0.9908500460615756\n",
      "Recall:0.9857901868062534\n",
      "Precision:0.9916717807364261\n",
      "\n",
      "**70**\n",
      "Accuracy:0.9921706495098039\n",
      "F1 Score:0.9885807772150743\n",
      "ROC_AUC_Score:0.9910553021013613\n",
      "Recall:0.9868011126411048\n",
      "Precision:0.9905029304296449\n"
     ]
    }
   ],
   "source": [
    "RandomForestChi, LogisticModelChi, LogitBoostChi, SGDChi, SVMChi, ANNChi, DeepLearnChi = [], [], [], [], [], [], []\n",
    "\n",
    "\n",
    "for X in bestChiFeatures:\n",
    "    RandomForestChi.append(RandomForest(X, y))\n",
    "    LogisticModelChi.append(LogisticModelTree(X, y))\n",
    "    LogitBoostChi.append(LogitBoostClassifier(X, y))\n",
    "    SGDChi.append(SGD(X, y))\n",
    "    SVMChi.append(SVM(X, y))\n",
    "    ANNChi.append(ANN(X, y))\n",
    "    DeepLearnChi.append(deepLearn(X, y))\n",
    "\n",
    "    \n",
    "print('*RandomForest Results**')\n",
    "for c, i in enumerate(bestPercent): \n",
    "    print(f'\\n**{i}**')\n",
    "    for metric, score in RandomForestChi[c][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "\n",
    "print('\\n**LMT Results**')\n",
    "for c, i in enumerate(bestPercent): \n",
    "    print(f'\\n**{i}**')\n",
    "    for metric, score in LogisticModelChi[c][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "\n",
    "print('\\n**LogitBoost Results**')\n",
    "for c, i in enumerate(bestPercent): \n",
    "    print(f'\\n**{i}**')\n",
    "    for metric, score in LogitBoostChi[c][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "        \n",
    "print('\\n**SGD Results**')\n",
    "for c, i in enumerate(bestPercent): \n",
    "    print(f'**{i}**')\n",
    "    for metric, score in SGDChi[c][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "\n",
    "print('\\n**SVM Results**')\n",
    "for c, i in enumerate(bestPercent): \n",
    "    print(f'\\n**{i}**')\n",
    "    for metric, score in SVMChi[c][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "        \n",
    "print('\\n**ANN Results**')\n",
    "for c, i in enumerate(bestPercent): \n",
    "    print(f'\\n**{i}**')\n",
    "    for metric, score in ANNChi[c][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "\n",
    "print('\\n**DeepLearn Results**')\n",
    "for c, i in enumerate(bestPercent): \n",
    "    print(f'\\n**{i}**')\n",
    "    for metric, score in DeepLearnChi[c][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*RandomForest Results**\n",
      "\n",
      "**2**\n",
      "Accuracy:0.9252083333333333\n",
      "F1 Score:0.8927535121697823\n",
      "ROC_AUC_Score:0.9196019907634359\n",
      "Recall:0.9026150209478889\n",
      "Precision:0.8847754863837025\n",
      "\n",
      "**5**\n",
      "Accuracy:0.9510661764705881\n",
      "F1 Score:0.9323663352189152\n",
      "ROC_AUC_Score:0.954701889248863\n",
      "Recall:0.9660547089300188\n",
      "Precision:0.9015090400246297\n",
      "\n",
      "**10**\n",
      "Accuracy:0.9823912377450981\n",
      "F1 Score:0.9744672313186971\n",
      "ROC_AUC_Score:0.9842857377890379\n",
      "Recall:0.9892172126549056\n",
      "Precision:0.9606635429207661\n",
      "\n",
      "**25**\n",
      "Accuracy:0.9866942401960784\n",
      "F1 Score:0.9805053391061765\n",
      "ROC_AUC_Score:0.9871271230506269\n",
      "Recall:0.9878032867782377\n",
      "Precision:0.973538342189477\n",
      "\n",
      "**40**\n",
      "Accuracy:0.986688112745098\n",
      "F1 Score:0.9805851022934003\n",
      "ROC_AUC_Score:0.9858173968251258\n",
      "Recall:0.9829785846138993\n",
      "Precision:0.9783793450759534\n",
      "\n",
      "**50**\n",
      "Accuracy:0.991389399509804\n",
      "F1 Score:0.9876698129106882\n",
      "ROC_AUC_Score:0.9899095094199328\n",
      "Recall:0.9846257624754846\n",
      "Precision:0.9909152559452975\n",
      "\n",
      "**70**\n",
      "Accuracy:0.9917784926470589\n",
      "F1 Score:0.9883232479104773\n",
      "ROC_AUC_Score:0.9898206307331723\n",
      "Recall:0.9826255624554829\n",
      "Precision:0.9942661331382799\n",
      "\n",
      "**LMT Results**\n",
      "\n",
      "**2**\n",
      "Accuracy:0.9158118872549019\n",
      "F1 Score:0.883549984107691\n",
      "ROC_AUC_Score:0.9166311956932052\n",
      "Recall:0.9209026651850831\n",
      "Precision:0.8497099064422733\n",
      "\n",
      "**5**\n",
      "Accuracy:0.9287377450980392\n",
      "F1 Score:0.9029359320145496\n",
      "ROC_AUC_Score:0.9343526017364558\n",
      "Recall:0.9531468952224929\n",
      "Precision:0.8583626496281196\n",
      "\n",
      "**10**\n",
      "Accuracy:0.966341911764706\n",
      "F1 Score:0.9528583672948138\n",
      "ROC_AUC_Score:0.9730397241279451\n",
      "Recall:0.994435765802811\n",
      "Precision:0.9153374561731704\n",
      "\n",
      "**25**\n",
      "Accuracy:0.9765134803921569\n",
      "F1 Score:0.966310168291359\n",
      "ROC_AUC_Score:0.9776378261790446\n",
      "Recall:0.9795666046999022\n",
      "Precision:0.9541230050885785\n",
      "\n",
      "**40**\n",
      "Accuracy:0.9808180147058824\n",
      "F1 Score:0.9723567330812033\n",
      "ROC_AUC_Score:0.981227348845857\n",
      "Recall:0.9814397556774432\n",
      "Precision:0.963834596043886\n",
      "\n",
      "**50**\n",
      "Accuracy:0.9816038602941177\n",
      "F1 Score:0.9732728629866163\n",
      "ROC_AUC_Score:0.9821919164418669\n",
      "Recall:0.9826033551834612\n",
      "Precision:0.964664465867231\n",
      "\n",
      "**70**\n",
      "Accuracy:0.9839491421568628\n",
      "F1 Score:0.9766699602734168\n",
      "ROC_AUC_Score:0.9835646695454848\n",
      "Recall:0.9805831531632592\n",
      "Precision:0.9732688995516954\n",
      "\n",
      "**LogitBoost Results**\n",
      "\n",
      "**2**\n",
      "Accuracy:0.9271691176470588\n",
      "F1 Score:0.8960219314650967\n",
      "ROC_AUC_Score:0.9224739741643075\n",
      "Recall:0.9083589877496323\n",
      "Precision:0.8854440733024186\n",
      "\n",
      "**5**\n",
      "Accuracy:0.9432291666666666\n",
      "F1 Score:0.9208661763127491\n",
      "ROC_AUC_Score:0.9439755626057638\n",
      "Recall:0.9458834975008876\n",
      "Precision:0.8978262813740858\n",
      "\n",
      "**10**\n",
      "Accuracy:0.9831740196078431\n",
      "F1 Score:0.9753328577427917\n",
      "ROC_AUC_Score:0.9853469316541007\n",
      "Recall:0.991238239499858\n",
      "Precision:0.9604877050490581\n",
      "\n",
      "**25**\n",
      "Accuracy:0.9839537377450981\n",
      "F1 Score:0.9765432509115808\n",
      "ROC_AUC_Score:0.9857245009058764\n",
      "Recall:0.990228138489757\n",
      "Precision:0.9637512539235147\n",
      "\n",
      "**40**\n",
      "Accuracy:0.9863005514705883\n",
      "F1 Score:0.9798655494771824\n",
      "ROC_AUC_Score:0.9872618291967286\n",
      "Recall:0.9891245449843392\n",
      "Precision:0.9712890320151699\n",
      "\n",
      "**50**\n",
      "Accuracy:0.9862990196078432\n",
      "F1 Score:0.9798481614550951\n",
      "ROC_AUC_Score:0.9862045424949037\n",
      "Recall:0.9846590736949421\n",
      "Precision:0.9755017801746488\n",
      "\n",
      "**70**\n",
      "Accuracy:0.9890441176470588\n",
      "F1 Score:0.9839277785316745\n",
      "ROC_AUC_Score:0.988343523513867\n",
      "Recall:0.984772568190459\n",
      "Precision:0.9835030290141574\n",
      "\n",
      "**SGD Results**\n",
      "\n",
      "**2**\n",
      "Accuracy:0.9236504289215686\n",
      "F1 Score:0.8896873856093006\n",
      "ROC_AUC_Score:0.9161214410644624\n",
      "Recall:0.8926226795500071\n",
      "Precision:0.8883617843798239\n",
      "\n",
      "**5**\n",
      "Accuracy:0.9342279411764706\n",
      "F1 Score:0.9088446392523354\n",
      "ROC_AUC_Score:0.9349601729088028\n",
      "Recall:0.9370343236722679\n",
      "Precision:0.8833915076991052\n",
      "\n",
      "**10**\n",
      "Accuracy:0.9796537990196079\n",
      "F1 Score:0.9702681727434046\n",
      "ROC_AUC_Score:0.982743764997408\n",
      "Recall:0.991238239499858\n",
      "Precision:0.9510361870776916\n",
      "\n",
      "**25**\n",
      "Accuracy:0.9839568014705883\n",
      "F1 Score:0.97637973536822\n",
      "ROC_AUC_Score:0.9858405263407473\n",
      "Recall:0.9910285016721427\n",
      "Precision:0.9625832606621574\n",
      "\n",
      "**40**\n",
      "Accuracy:0.9847426470588235\n",
      "F1 Score:0.9777295989778191\n",
      "ROC_AUC_Score:0.9869273161017127\n",
      "Recall:0.9925611196070598\n",
      "Precision:0.9641301606749485\n",
      "\n",
      "**50**\n",
      "Accuracy:0.9878676470588236\n",
      "F1 Score:0.9822368407000306\n",
      "ROC_AUC_Score:0.9875544453868752\n",
      "Recall:0.9856900015299936\n",
      "Precision:0.9790079725978268\n",
      "\n",
      "**70**\n",
      "Accuracy:0.9886458333333333\n",
      "F1 Score:0.9836314639983739\n",
      "ROC_AUC_Score:0.9880437890830205\n",
      "Recall:0.9849135822918693\n",
      "Precision:0.9826385169133012\n",
      "\n",
      "**SVM Results**\n",
      "\n",
      "**2**\n",
      "Accuracy:0.9271691176470588\n",
      "F1 Score:0.8960219314650967\n",
      "ROC_AUC_Score:0.9224739741643075\n",
      "Recall:0.9083589877496323\n",
      "Precision:0.8854440733024186\n",
      "\n",
      "**5**\n",
      "Accuracy:0.9494990808823529\n",
      "F1 Score:0.9303858694951528\n",
      "ROC_AUC_Score:0.9532280717916659\n",
      "Recall:0.9649794401128144\n",
      "Precision:0.8987686100694153\n",
      "\n",
      "**10**\n",
      "Accuracy:0.9812162990196078\n",
      "F1 Score:0.9727335243485641\n",
      "ROC_AUC_Score:0.9835877232734909\n",
      "Recall:0.9902073116648065\n",
      "Precision:0.9564215660281448\n",
      "\n",
      "**25**\n",
      "Accuracy:0.985125612745098\n",
      "F1 Score:0.9784292303671845\n",
      "ROC_AUC_Score:0.9862408094940683\n",
      "Recall:0.9890837161591886\n",
      "Precision:0.9682666637336668\n",
      "\n",
      "**40**\n",
      "Accuracy:0.9859099264705883\n",
      "F1 Score:0.979527944593546\n",
      "ROC_AUC_Score:0.9868500690061539\n",
      "Recall:0.9890837161591886\n",
      "Precision:0.9704586483094099\n",
      "\n",
      "**50**\n",
      "Accuracy:0.9894286151960785\n",
      "F1 Score:0.9850123674279916\n",
      "ROC_AUC_Score:0.9888470757639098\n",
      "Recall:0.986072590304335\n",
      "Precision:0.9842998200221842\n",
      "\n",
      "**70**\n",
      "Accuracy:0.9882552083333334\n",
      "F1 Score:0.9832346849128163\n",
      "ROC_AUC_Score:0.9879320064169115\n",
      "Recall:0.9860082473219822\n",
      "Precision:0.9807003122384069\n",
      "\n",
      "**ANN Results**\n",
      "\n",
      "**2**\n",
      "Accuracy:0.9248177083333333\n",
      "F1 Score:0.8920469904306518\n",
      "ROC_AUC_Score:0.9189609651224101\n",
      "Recall:0.9013329696658376\n",
      "Precision:0.8845844784495268\n",
      "\n",
      "**5**\n",
      "Accuracy:0.9498927696078431\n",
      "F1 Score:0.9305655618996866\n",
      "ROC_AUC_Score:0.9533511757188837\n",
      "Recall:0.9638558446071965\n",
      "Precision:0.9002369225190542\n",
      "\n",
      "**10**\n",
      "Accuracy:0.9823912377450981\n",
      "F1 Score:0.9744955254646385\n",
      "ROC_AUC_Score:0.9845090107073462\n",
      "Recall:0.9902810424421397\n",
      "Precision:0.9596561858183325\n",
      "\n",
      "**25**\n",
      "Accuracy:0.9874754901960785\n",
      "F1 Score:0.9817589759634812\n",
      "ROC_AUC_Score:0.9881912326011364\n",
      "Recall:0.9899986389440578\n",
      "Precision:0.9738784199635969\n",
      "\n",
      "**40**\n",
      "Accuracy:0.9886488970588235\n",
      "F1 Score:0.9833490267073488\n",
      "ROC_AUC_Score:0.9890182231590359\n",
      "Recall:0.9898651424483408\n",
      "Precision:0.9770608749770174\n",
      "\n",
      "**50**\n",
      "Accuracy:0.9902113970588236\n",
      "F1 Score:0.985916888972576\n",
      "ROC_AUC_Score:0.989133737065022\n",
      "Recall:0.9847800857961524\n",
      "Precision:0.9872177394129131\n",
      "\n",
      "**70**\n",
      "Accuracy:0.9902144607843137\n",
      "F1 Score:0.9856290043139175\n",
      "ROC_AUC_Score:0.9898694711433713\n",
      "Recall:0.9879247081467228\n",
      "Precision:0.9835163038786228\n",
      "\n",
      "**DeepLearn Results**\n",
      "\n",
      "**2**\n",
      "Accuracy:0.9252083333333333\n",
      "F1 Score:0.8927535121697823\n",
      "ROC_AUC_Score:0.9196019907634359\n",
      "Recall:0.9026150209478889\n",
      "Precision:0.8847754863837025\n",
      "\n",
      "**5**\n",
      "Accuracy:0.9494990808823529\n",
      "F1 Score:0.9301262832978336\n",
      "ROC_AUC_Score:0.9525493587613238\n",
      "Recall:0.9617496479549406\n",
      "Precision:0.9011447377604076\n",
      "\n",
      "**10**\n",
      "Accuracy:0.9820021446078432\n",
      "F1 Score:0.9739062690698981\n",
      "ROC_AUC_Score:0.984413351709569\n",
      "Recall:0.9912711414520405\n",
      "Precision:0.9576362929526953\n",
      "\n",
      "**25**\n",
      "Accuracy:0.9894301470588236\n",
      "F1 Score:0.9845900141536316\n",
      "ROC_AUC_Score:0.9898748529345894\n",
      "Recall:0.9910295667791094\n",
      "Precision:0.978407673323742\n",
      "\n",
      "**40**\n",
      "Accuracy:0.986688112745098\n",
      "F1 Score:0.9806152186715396\n",
      "ROC_AUC_Score:0.9871590810386793\n",
      "Recall:0.9878849444285389\n",
      "Precision:0.9737588453019367\n",
      "\n",
      "**50**\n",
      "Accuracy:0.9913909313725491\n",
      "F1 Score:0.9874790464594755\n",
      "ROC_AUC_Score:0.9902625295915343\n",
      "Recall:0.9857901868062534\n",
      "Precision:0.9893335378389725\n",
      "\n",
      "**70**\n",
      "Accuracy:0.991780024509804\n",
      "F1 Score:0.9880076005760017\n",
      "ROC_AUC_Score:0.9905591461850711\n",
      "Recall:0.9857701848060533\n",
      "Precision:0.9903897294543749\n"
     ]
    }
   ],
   "source": [
    "RandomForestInfoGain, LogisticModelInfoGain, LogitBoostInfoGain, SGDInfoGain, SVMInfoGain, ANNInfoGain, DeepLearnInfoGain = [], [], [], [], [], [], []\n",
    "\n",
    "for X in bestInfoGainFeatures:\n",
    "    RandomForestInfoGain.append(RandomForest(X, y))\n",
    "    LogisticModelInfoGain.append(LogisticModelTree(X, y))\n",
    "    LogitBoostInfoGain.append(LogitBoostClassifier(X, y))\n",
    "    SGDInfoGain.append(SGD(X, y))\n",
    "    SVMInfoGain.append(SVM(X, y))\n",
    "    ANNInfoGain.append(ANN(X, y))\n",
    "    DeepLearnInfoGain.append(deepLearn(X, y))\n",
    "\n",
    "\n",
    "print('*RandomForest Results**')\n",
    "for c, i in enumerate(bestPercent): \n",
    "    print(f'\\n**{i}**')\n",
    "    for metric, score in RandomForestInfoGain[c][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "\n",
    "print('\\n**LMT Results**')\n",
    "for c, i in enumerate(bestPercent): \n",
    "    print(f'\\n**{i}**')\n",
    "    for metric, score in LogisticModelInfoGain[c][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "\n",
    "print('\\n**LogitBoost Results**')\n",
    "for c, i in enumerate(bestPercent): \n",
    "    print(f'\\n**{i}**')\n",
    "    for metric, score in LogitBoostInfoGain[c][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "        \n",
    "print('\\n**SGD Results**')\n",
    "for c, i in enumerate(bestPercent): \n",
    "    print(f'\\n**{i}**')\n",
    "    for metric, score in SGDInfoGain[c][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "\n",
    "print('\\n**SVM Results**')\n",
    "for c, i in enumerate(bestPercent): \n",
    "    print(f'\\n**{i}**')\n",
    "    for metric, score in SVMInfoGain[c][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "        \n",
    "print('\\n**ANN Results**')\n",
    "for c, i in enumerate(bestPercent): \n",
    "    print(f'\\n**{i}**')\n",
    "    for metric, score in ANNInfoGain[c][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "\n",
    "print('\\n**DeepLearn Results**')\n",
    "for c, i in enumerate(bestPercent): \n",
    "    print(f'\\n**{i}**')\n",
    "    for metric, score in DeepLearnInfoGain[c][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
