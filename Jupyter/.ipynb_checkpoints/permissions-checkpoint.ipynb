{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permissions Feature Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set __location__ depeneing which operating system user is on \n",
    "\n",
    "if os.name == \"nt\": \n",
    "    __location__ = \"F:\\FinalYearProject\\Machine Learning\\Features\\CIC_dataset\\\\\"\n",
    "else:\n",
    "    __location__ = \"/media/jackp/JACK PYE/FinalYearProject/Machine Learning/Features/CIC_dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset into panda dataframe\n",
    "df = pd.read_csv(os.path.join(__location__,\"permission_dataset.csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1537, 110)\n",
      "removed 215 Features\n"
     ]
    }
   ],
   "source": [
    "#Exploring the first five entries of the dataset to show the features that have been collected\n",
    "df.head()\n",
    "old_shape = df.shape\n",
    "\n",
    "#remove features that are not supported \n",
    "df = df.loc[:, (df.sum(axis=0) != 0)]\n",
    "print(df.shape)\n",
    "new_shape = df.shape\n",
    "print(f'removed {old_shape[1] - new_shape[1]} Features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert \"Malware and Beignin lables into 1 and 0\"\n",
    "\n",
    "df[\"malware\"] = (df[\"malware\"] == 'Malware').astype(int)\n",
    "y = df['malware']\n",
    "X = df.drop('malware', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomForest(X, y, kfold=10, seed=101):\n",
    "    \n",
    "    kf = KFold(n_splits=kfold,shuffle=True, random_state=seed)\n",
    "    \n",
    "    accuracy_score_avg, f1_score_avg, roc_auc_score_avg, recall_score_avg, precision_score_avg = np.empty(kfold), np.empty(kfold), \\\n",
    "                                                                                    np.empty(kfold), np.empty(kfold), np.empty(kfold)\n",
    "    randomForestMetrics = {'Accuracy': accuracy_score_avg, 'F1 Score': f1_score_avg, 'ROC_AUC_Score': roc_auc_score_avg, \n",
    "                           'Recall': recall_score_avg, 'Precision': precision_score_avg}\n",
    "    \n",
    "    ## create array to hold all confusion matrices \n",
    "    cm_holder = []\n",
    "    count = 0 \n",
    "    for train_index, test_index in kf.split(X):\n",
    "\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        clf = RandomForestClassifier()\n",
    "        clf.fit(X_train, y_train.ravel())\n",
    "        pred = clf.predict(X_test)\n",
    "        \n",
    "        accuracy_score_avg[count] = accuracy_score(y_test, pred)\n",
    "        f1_score_avg[count] = f1_score(y_test, pred)\n",
    "        roc_auc_score_avg[count] = roc_auc_score(y_test, pred)\n",
    "        recall_score_avg[count] = recall_score(y_test, pred)\n",
    "        precision_score_avg[count] = precision_score(y_test, pred)\n",
    "        cm_holder.append(confusion_matrix(y_test, pred))\n",
    "\n",
    "        count = count + 1\n",
    "        \n",
    "    #if for any reason a metric in the folds returns 0.0\n",
    "    #remove it from the list\n",
    "    for key, values in randomForestMetrics.items():\n",
    "        randomForestMetrics[key] = np.array([value for value in randomForestMetrics[key] if value != 0.0])\n",
    "        randomForestMetrics[key] = randomForestMetrics[key].mean()  \n",
    "    \n",
    "    \n",
    "    true_pos, true_neg, false_pos, false_neg = [], [], [], []\n",
    "\n",
    "    for cm in cm_holder:\n",
    "        true_pos.append(cm[0][0])\n",
    "        false_pos.append(cm[0][1])\n",
    "        true_neg.append(cm[1][0])\n",
    "        false_neg.append(cm[1][1])\n",
    "    \n",
    "    avg_cm = np.matrix([[sum(true_pos), sum(false_pos)], [sum(true_neg), sum(false_neg)]])\n",
    "    \n",
    "    return randomForestMetrics, avg_cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.8939860792801969\n",
      "F1 Score:0.7938311991410589\n",
      "ROC_AUC_Score:0.8542818233537236\n",
      "Recall:0.7680356168490574\n",
      "Precision:0.8275323097247889\n",
      "[[1059   67]\n",
      " [  96  315]]\n"
     ]
    }
   ],
   "source": [
    "randomForestMetrics, cm = RandomForest(X, y)\n",
    "\n",
    "Classifiers = {'Random Forest': randomForestMetrics}\n",
    "\n",
    "for metric, score in randomForestMetrics.items():\n",
    "    print(f'{metric}:{score}')\n",
    "    \n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Model Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lmt import LinearModelTree\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statistics import median\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def LogisticModelTree(X, y, kfold=10, seed=101):\n",
    "    \n",
    "    shared_scaler = StandardScaler()\n",
    "    shared_scaler.fit(X)\n",
    "\n",
    "    def fit_linear_model(x, y):\n",
    "        lr = Ridge()\n",
    "        lr.fit(shared_scaler.transform(x), y)\n",
    "        return SharedScalerModel(shared_scaler, lr)\n",
    "\n",
    "    class SharedScalerModel:\n",
    "\n",
    "        def __init__(self, scaler, lm):\n",
    "            self.scaler = scaler\n",
    "            self.lm = lm\n",
    "            self.coef_ = lm.coef_\n",
    "            self.intercept_ = lm.intercept_\n",
    "\n",
    "        def predict(self, X):\n",
    "            return self.lm.predict(self.scaler.transform(X))\n",
    "\n",
    "\n",
    "    MIN_NODE_SIZE = 100\n",
    "    MIN_SPLIT_IMPROVEMENT = 10\n",
    "    lmt = LinearModelTree(MIN_NODE_SIZE, fit_linear_model, min_split_improvement=MIN_SPLIT_IMPROVEMENT)\n",
    "    \n",
    "    def GetThreshold(lmt, X, y, kfold=10, seed=101):\n",
    "        \n",
    "        pred_class = []\n",
    "\n",
    "        kf = KFold(n_splits=kfold,shuffle=True, random_state=seed)\n",
    "        fold = 0\n",
    "        best_thresholds_roc_auc, best_thresholds_f1 = [], []\n",
    "        threshold_list = [0.05,0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5,0.55,0.6,0.65,0.7,0.75,0.8,0.85,0.9,0.95,0.99]\n",
    "        for train_index, test_index in kf.split(X):\n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            lmt.build_tree(X_train.values, X_train, y_train.values)\n",
    "            pred = lmt.predict(X_test.values, X_test)\n",
    "\n",
    "            pred = [round(i, 2) for i in pred]\n",
    "\n",
    "        #     preds.append(pred)\n",
    "\n",
    "\n",
    "            pred_threshold = []\n",
    "\n",
    "            for threshold in threshold_list:\n",
    "                pred_threshold.append([1 if x>threshold else 0 for x in pred])\n",
    "\n",
    "            best_kfold_f1, best_kfold_roc_auc = [0 for i in range(10)], [0 for i in range(10)]\n",
    "\n",
    "            for c, value in enumerate(pred_threshold):\n",
    "                f1 = f1_score(y_test, value)\n",
    "                roc_auc = roc_auc_score(y_test, value)\n",
    "\n",
    "\n",
    "                if c == 0:\n",
    "                    best_kfold_f1[0], best_kfold_roc_auc[0] = f1, roc_auc\n",
    "                    best_kfold_f1[1], best_kfold_roc_auc[1] = threshold_list[c], threshold_list[c]\n",
    "\n",
    "                if best_kfold_f1[0] < f1:\n",
    "                    best_kfold_f1[0] = f1\n",
    "                    best_kfold_f1[1] = threshold_list[c]\n",
    "\n",
    "                if best_kfold_roc_auc[0] < roc_auc:\n",
    "                    best_kfold_roc_auc[0] = roc_auc\n",
    "                    best_kfold_roc_auc[1] = threshold_list[c]\n",
    "\n",
    "                if c == (len(pred_threshold) - 1):\n",
    "                    best_thresholds_roc_auc.append(best_kfold_roc_auc[1])\n",
    "                    best_thresholds_f1.append(best_kfold_f1[1])\n",
    "                    \n",
    "                    \n",
    "\n",
    "            fold = fold + 1\n",
    "\n",
    "        best_threshold_roc_auc = median(best_thresholds_roc_auc)\n",
    "        best_threshold_f1 = median(best_thresholds_roc_auc)\n",
    "        \n",
    "        \n",
    "        \n",
    "        return best_threshold_roc_auc\n",
    "    \n",
    "    def preditions(lmt, X, y, threshold, kfold=10, seed=101):\n",
    "        \n",
    "        accuracy_score_avg, f1_score_avg, roc_auc_score_avg, recall_score_avg, precision_score_avg = np.empty(kfold), np.empty(kfold), \\\n",
    "                                                                                    np.empty(kfold), np.empty(kfold), np.empty(kfold)\n",
    "        LMTMetrics = {'Accuracy': accuracy_score_avg, 'F1 Score': f1_score_avg, 'ROC_AUC_Score': roc_auc_score_avg, \n",
    "                  'Recall': recall_score_avg, 'Precision': precision_score_avg}\n",
    "        \n",
    "        kf = KFold(n_splits=kfold,shuffle=True, random_state=seed)\n",
    "        \n",
    "        cm_holder = []\n",
    "        count = 0             \n",
    "        for train_index, test_index in kf.split(X):\n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            lmt.build_tree(X_train.values, X_train, y_train.values)\n",
    "            pred = lmt.predict(X_test.values, X_test)\n",
    "\n",
    "            pred = [round(i, 2) for i in pred]\n",
    "\n",
    "            #use the threshold that we estabished in the previous run of the algorithm \n",
    "            pred_threshold = [1 if x>threshold else 0 for x in pred]\n",
    "            accuracy_score_avg[count] = accuracy_score(y_test, pred_threshold)\n",
    "            f1_score_avg[count] = f1_score(y_test, pred_threshold)\n",
    "            roc_auc_score_avg[count] = roc_auc_score(y_test, pred_threshold)\n",
    "            recall_score_avg[count] = recall_score(y_test, pred_threshold)\n",
    "            precision_score_avg[count] = precision_score(y_test, pred_threshold)\n",
    "            cm_holder.append(confusion_matrix(y_test, pred_threshold))\n",
    "\n",
    "            count = count + 1\n",
    "\n",
    "\n",
    "        #if for any reason a metric in the folds returns 0.0\n",
    "        #remove it from the list\n",
    "        for key, values in LMTMetrics.items():\n",
    "            LMTMetrics[key] = np.array([value for value in LMTMetrics[key] if value != 0.0])\n",
    "            LMTMetrics[key] = LMTMetrics[key].mean()  \n",
    "\n",
    "        true_pos, true_neg, false_pos, false_neg = [], [], [], []\n",
    "\n",
    "        for cm in cm_holder:\n",
    "            true_pos.append(cm[0][0])\n",
    "            false_pos.append(cm[0][1])\n",
    "            true_neg.append(cm[1][0])\n",
    "            false_neg.append(cm[1][1])\n",
    "\n",
    "        avg_cm = np.matrix([[sum(true_pos), sum(false_pos)], [sum(true_neg), sum(false_neg)]])\n",
    "        \n",
    "        return LMTMetrics, avg_cm\n",
    "    \n",
    "    threshold = GetThreshold(lmt, X, y, kfold)\n",
    "    return preditions(lmt, X, y, threshold, kfold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we know the best threshold to use based off the ROC_auc score, we can use this threshold now with the algorithm again to get the best representation on the performance of our classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.8887403446226976\n",
      "F1 Score:0.7847786402143422\n",
      "ROC_AUC_Score:0.8500378870479827\n",
      "Recall:0.7667035087476187\n",
      "Precision:0.8070218679881581\n",
      "[[1051   75]\n",
      " [  96  315]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "LMTMetrics, cm = LogisticModelTree(X, y)\n",
    "\n",
    "Classifiers['LMT'] = LMTMetrics\n",
    "\n",
    "for metric, score in LMTMetrics.items():\n",
    "    print(f'{metric}:{score}')\n",
    "    \n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will be using the cut off point that has the highest roc_auc score depicting the the usefulness of the test. As the data is imballanced the accuracy cannot be taken as a useful metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logitboost \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from logitboost import LogitBoost\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def LogitBoostClassifier(X, y, kfold=10, seed=101):\n",
    "    accuracy_score_avg, f1_score_avg, roc_auc_score_avg, recall_score_avg, precision_score_avg = np.empty(kfold), np.empty(kfold), \\\n",
    "          np.empty(kfold), np.empty(kfold), np.empty(kfold)\n",
    "\n",
    "    LogitboostMetrics = {'Accuracy': accuracy_score_avg, 'F1 Score': f1_score_avg, 'ROC_AUC_Score': roc_auc_score_avg, \n",
    "                         'Recall': recall_score_avg, 'Precision': precision_score_avg}\n",
    "    \n",
    "    lboost = LogitBoost()\n",
    "    count = 0\n",
    "    cm_holder = []\n",
    "    kf = KFold(n_splits=kfold,shuffle=True, random_state=seed)\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]    \n",
    "\n",
    "        lboost.fit(X_train, y_train)\n",
    "        pred = lboost.predict(X_test)\n",
    "        accuracy_score_avg[count] = accuracy_score(y_test, pred)\n",
    "        f1_score_avg[count] = f1_score(y_test, pred)\n",
    "        roc_auc_score_avg[count] = roc_auc_score(y_test, pred)\n",
    "        recall_score_avg[count] = recall_score(y_test, pred)\n",
    "        precision_score_avg[count] = precision_score(y_test, pred)\n",
    "        cm_holder.append(confusion_matrix(y_test, pred))\n",
    "\n",
    "        count = count + 1\n",
    "    #if for any reason a metric in a fold returns 0.0\n",
    "    #remove it from the list\n",
    "    for key, values in LogitboostMetrics.items():\n",
    "        LogitboostMetrics[key] = np.array([value for value in LogitboostMetrics[key] if value != 0.0])\n",
    "        LogitboostMetrics[key] = LogitboostMetrics[key].mean() \n",
    "\n",
    "    \n",
    "\n",
    "    true_pos, true_neg, false_pos, false_neg = [], [], [], []\n",
    "\n",
    "    for cm in cm_holder:\n",
    "        true_pos.append(cm[0][0])\n",
    "        false_pos.append(cm[0][1])\n",
    "        true_neg.append(cm[1][0])\n",
    "        false_neg.append(cm[1][1])\n",
    "\n",
    "    avg_cm = np.matrix([[sum(true_pos), sum(false_pos)], [sum(true_neg), sum(false_neg)]])\n",
    "    \n",
    "    return LogitboostMetrics, avg_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.8919913419913421\n",
      "F1 Score:0.778412364759353\n",
      "ROC_AUC_Score:0.8350427709780955\n",
      "Recall:0.7119905535401123\n",
      "Precision:0.8651271123753421\n",
      "[[1079   47]\n",
      " [ 119  292]]\n"
     ]
    }
   ],
   "source": [
    "LogitboostMetrics, cm = LogitBoostClassifier(X, y)\n",
    "\n",
    "Classifiers['Logitboost'] = LogitboostMetrics\n",
    "\n",
    "for metric, score in LogitboostMetrics.items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "        \n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent (SGD) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "def SGD(X, y, kfold=10, seed=101):\n",
    "    kf = KFold(n_splits=kfold,shuffle=True, random_state=seed)\n",
    "    \n",
    "    accuracy_score_avg, f1_score_avg, roc_auc_score_avg, recall_score_avg, precision_score_avg = np.empty(kfold), np.empty(kfold), \\\n",
    "                                                                                    np.empty(kfold), np.empty(kfold), np.empty(kfold)\n",
    "    SGDMetrics = {'Accuracy': accuracy_score_avg, 'F1 Score': f1_score_avg, 'ROC_AUC_Score': roc_auc_score_avg, \n",
    "                           'Recall': recall_score_avg, 'Precision': precision_score_avg}\n",
    "    \n",
    "    ## create array to hold all confusion matrices \n",
    "    cm_holder = []\n",
    "    count = 0 \n",
    "    for train_index, test_index in kf.split(X):\n",
    "\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        clf = RandomForestClassifier()\n",
    "        clf.fit(X_train, y_train.ravel())\n",
    "        pred = clf.predict(X_test)\n",
    "        \n",
    "        accuracy_score_avg[count] = accuracy_score(y_test, pred)\n",
    "        f1_score_avg[count] = f1_score(y_test, pred)\n",
    "        roc_auc_score_avg[count] = roc_auc_score(y_test, pred)\n",
    "        recall_score_avg[count] = recall_score(y_test, pred)\n",
    "        precision_score_avg[count] = precision_score(y_test, pred)\n",
    "        cm_holder.append(confusion_matrix(y_test, pred))\n",
    "\n",
    "        count = count + 1\n",
    "        \n",
    "    #if for any reason a metric in the folds returns 0.0\n",
    "    #remove it from the list\n",
    "    for key, values in SGDMetrics.items():\n",
    "        SGDMetrics[key] = np.array([value for value in SGDMetrics[key] if value != 0.0])\n",
    "        SGDMetrics[key] = SGDMetrics[key].mean()  \n",
    "    \n",
    "    \n",
    "    true_pos, true_neg, false_pos, false_neg = [], [], [], []\n",
    "\n",
    "    for cm in cm_holder:\n",
    "        true_pos.append(cm[0][0])\n",
    "        false_pos.append(cm[0][1])\n",
    "        true_neg.append(cm[1][0])\n",
    "        false_neg.append(cm[1][1])\n",
    "    \n",
    "    avg_cm = np.matrix([[sum(true_pos), sum(false_pos)], [sum(true_neg), sum(false_neg)]])\n",
    "    \n",
    "    return SGDMetrics, avg_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.8907181054239878\n",
      "F1 Score:0.7893474901439301\n",
      "ROC_AUC_Score:0.8515601717929402\n",
      "Recall:0.7662548772634399\n",
      "Precision:0.8177707652707651\n",
      "[[1055   71]\n",
      " [  97  314]]\n"
     ]
    }
   ],
   "source": [
    "SGDMetrics, cm = SGD(X, y)\n",
    "Classifiers['SGD'] = SGDMetrics\n",
    "\n",
    "for metric, score in SGDMetrics.items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "        \n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "def SVM(X, y, kfold=10, seed=101):\n",
    "    accuracy_score_avg, f1_score_avg, roc_auc_score_avg, recall_score_avg, precision_score_avg  = np.empty(kfold), np.empty(kfold), \\\n",
    "                                                                                    np.empty(kfold), np.empty(kfold), np.empty(kfold)\n",
    "    cm_holder = []\n",
    "    SVCMetrics = {'Accuracy': accuracy_score_avg, 'F1 Score': f1_score_avg, 'ROC_AUC_Score': roc_auc_score_avg, \n",
    "                         'Recall': recall_score_avg, 'Precision': precision_score_avg}\n",
    "    \n",
    "\n",
    "    svc = SVC()\n",
    "    count = 0\n",
    "    kf = KFold(n_splits=kfold,shuffle=True, random_state=seed)\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        svc.fit(X_train, y_train)\n",
    "        pred = svc.predict(X_test)\n",
    "        accuracy_score_avg[count] = accuracy_score(y_test, pred)\n",
    "        f1_score_avg[count] = f1_score(y_test, pred)\n",
    "        roc_auc_score_avg[count] = roc_auc_score(y_test, pred)\n",
    "        recall_score_avg[count] = recall_score(y_test, pred)\n",
    "        precision_score_avg[count] = precision_score(y_test, pred)\n",
    "        cm_holder.append(confusion_matrix(y_test, pred))\n",
    "\n",
    "        count = count + 1\n",
    "\n",
    "    for key, values in SVCMetrics.items():\n",
    "        SVCMetrics[key] = np.array([value for value in SVCMetrics[key] if value != 0.0])\n",
    "        SVCMetrics[key] = SVCMetrics[key].mean()\n",
    "\n",
    "\n",
    "    true_pos, true_neg, false_pos, false_neg = [], [], [], []\n",
    "\n",
    "    for cm in cm_holder:\n",
    "        true_pos.append(cm[0][0])\n",
    "        false_pos.append(cm[0][1])\n",
    "        true_neg.append(cm[1][0])\n",
    "        false_neg.append(cm[1][1])\n",
    "\n",
    "    avg_cm = np.matrix([[sum(true_pos), sum(false_pos)], [sum(true_neg), sum(false_neg)]])\n",
    "    \n",
    "    return SVCMetrics, avg_cm\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.8985018249724132\n",
      "F1 Score:0.7935669428705625\n",
      "ROC_AUC_Score:0.8463335186332708\n",
      "Recall:0.732644565096563\n",
      "Precision:0.8728184936851369\n",
      "[[1081   45]\n",
      " [ 111  300]]\n"
     ]
    }
   ],
   "source": [
    "SVCMetrics, cm = SVM(X, y)\n",
    "\n",
    "Classifiers['SVC'] = SVCMetrics\n",
    "\n",
    "for metric, score in SVCMetrics.items():\n",
    "        print(f'{metric}:{score}')\n",
    "        \n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artificial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jackp/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "\n",
    "def ANN(X, y, kfold=10, seed=101):\n",
    "    accuracy_score_avg, f1_score_avg, roc_auc_score_avg, recall_score_avg, precision_score_avg  = np.empty(kfold), np.empty(kfold), \\\n",
    "                                                                                    np.empty(kfold), np.empty(kfold), np.empty(kfold)\n",
    "    cm_holder = []\n",
    "    ANNMetrics = {'Accuracy': accuracy_score_avg, 'F1 Score': f1_score_avg, 'ROC_AUC_Score': roc_auc_score_avg, \n",
    "                         'Recall': recall_score_avg, 'Precision': precision_score_avg}\n",
    "    \n",
    "\n",
    "\n",
    "    def DL_Model(activation= 'linear', neurons= 5, optimizer='Adam'):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(128, activation='relu'))\n",
    "        model.add(Dense(8, activation='relu'))\n",
    "        model.add(Dropout(0.3))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.compile(loss='binary_crossentropy', optimizer= 'adam', metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    ANN = KerasClassifier(build_fn= DL_Model, epochs= 80, batch_size=40, verbose= 0)\n",
    "    kf = KFold(n_splits=kfold,shuffle=True, random_state=seed)\n",
    "    count = 0\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "\n",
    "        ANN.fit(X_train.values, y_train)\n",
    "        pred = ANN.predict(X_test)\n",
    "        accuracy_score_avg[count] = accuracy_score(y_test, pred)\n",
    "        f1_score_avg[count] = f1_score(y_test, pred)\n",
    "        roc_auc_score_avg[count] = roc_auc_score(y_test, pred)\n",
    "        recall_score_avg[count] = recall_score(y_test, pred)\n",
    "        precision_score_avg[count] = precision_score(y_test, pred)\n",
    "        cm_holder.append(confusion_matrix(y_test, pred))\n",
    "\n",
    "        count = count + 1\n",
    "\n",
    "    for key, values in ANNMetrics.items():\n",
    "        ANNMetrics[key] = np.array([value for value in ANNMetrics[key] if value != 0.0])\n",
    "        ANNMetrics[key] = ANNMetrics[key].mean()\n",
    "\n",
    "    \n",
    "\n",
    "    true_pos, true_neg, false_pos, false_neg = [], [], [], []\n",
    "\n",
    "    for cm in cm_holder:\n",
    "        true_pos.append(cm[0][0])\n",
    "        false_pos.append(cm[0][1])\n",
    "        true_neg.append(cm[1][0])\n",
    "        false_neg.append(cm[1][1])\n",
    "\n",
    "    avg_cm = np.matrix([[sum(true_pos), sum(false_pos)], [sum(true_neg), sum(false_neg)]])\n",
    "    \n",
    "    return ANNMetrics, avg_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.8946269416857652\n",
      "F1 Score:0.792113139360872\n",
      "ROC_AUC_Score:0.8491334428760945\n",
      "Recall:0.7509972457497106\n",
      "Precision:0.8435778712262854\n"
     ]
    }
   ],
   "source": [
    "ANNMetrics, cm = ANN(X, y)\n",
    "\n",
    "Classifiers['ANN'] = ANNMetrics\n",
    "\n",
    "for metric, score in ANNMetrics.items():\n",
    "        print(f'{metric}:{score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "def deepLearn(X, y, kfold=10, seed=101):\n",
    "    accuracy_score_avg, f1_score_avg, roc_auc_score_avg, recall_score_avg, precision_score_avg  = np.empty(kfold), np.empty(kfold), \\\n",
    "                                                                                    np.empty(kfold), np.empty(kfold), np.empty(kfold)\n",
    "    cm_holder = []\n",
    "    DeepLearnMetrics = {'Accuracy': accuracy_score_avg, 'F1 Score': f1_score_avg, 'ROC_AUC_Score': roc_auc_score_avg, \n",
    "                         'Recall': recall_score_avg, 'Precision': precision_score_avg}\n",
    "\n",
    "\n",
    "\n",
    "    def DL_Model():\n",
    "        n_cols = X_train.shape[1]\n",
    "        model = Sequential()\n",
    "        model.add(Dense(250, activation='relu', input_shape=(n_cols,)))\n",
    "        model.add(Dense(250, activation='relu'))\n",
    "        model.add(Dense(250, activation='relu'))\n",
    "        model.add(Dense(2, activation='softmax'))\n",
    "        model.compile(loss='categorical_crossentropy', optimizer= 'adam', metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    deepLearn = KerasClassifier(build_fn= DL_Model, epochs= 80, batch_size=40, verbose= 0)\n",
    "    cm_holder = []\n",
    "    count = 0\n",
    "    kf = KFold(n_splits=kfold,shuffle=True, random_state=seed)\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        train_y_2 = to_categorical(y_train)\n",
    "        deepLearn.fit(X_train, train_y_2)\n",
    "        pred = deepLearn.predict(X_test)\n",
    "        accuracy_score_avg[count] = accuracy_score(y_test, pred)\n",
    "        f1_score_avg[count] = f1_score(y_test, pred)\n",
    "        roc_auc_score_avg[count] = roc_auc_score(y_test, pred)\n",
    "        recall_score_avg[count] = recall_score(y_test, pred)\n",
    "        precision_score_avg[count] = precision_score(y_test, pred)\n",
    "        cm_holder.append(confusion_matrix(y_test, pred))\n",
    "\n",
    "        count = count + 1\n",
    "\n",
    "    for key, values in DeepLearnMetrics.items():\n",
    "        DeepLearnMetrics[key] = np.array([value for value in DeepLearnMetrics[key] if value != 0.0])\n",
    "        DeepLearnMetrics[key] = DeepLearnMetrics[key].mean()\n",
    "\n",
    "    \n",
    "\n",
    "    true_pos, true_neg, false_pos, false_neg = [], [], [], []\n",
    "\n",
    "    for cm in cm_holder:\n",
    "        true_pos.append(cm[0][0])\n",
    "        false_pos.append(cm[0][1])\n",
    "        true_neg.append(cm[1][0])\n",
    "        false_neg.append(cm[1][1])\n",
    "\n",
    "    avg_cm = np.matrix([[sum(true_pos), sum(false_pos)], [sum(true_neg), sum(false_neg)]])\n",
    "    \n",
    "    return DeepLearnMetrics, avg_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.8978609625668449\n",
      "F1 Score:0.8011358151022699\n",
      "ROC_AUC_Score:0.8570867563642757\n",
      "Recall:0.7686569751655377\n",
      "Precision:0.8398795802227756\n",
      "[[1065   61]\n",
      " [  96  315]]\n"
     ]
    }
   ],
   "source": [
    "DeepLearnMetrics, cm = deepLearn(X, y)\n",
    "\n",
    "Classifiers['DeepLearnMetrics'] = DeepLearnMetrics\n",
    "\n",
    "for metric, score in DeepLearnMetrics.items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "        \n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****DeepLearnMetrics****\n",
      "Accuracy: 0.8978609625668449\n",
      "F1 Score: 0.8011358151022699\n",
      "ROC_AUC_Score: 0.8570867563642757\n",
      "Recall: 0.7686569751655377\n",
      "Precision: 0.8398795802227756\n",
      "\n",
      "****Random Forest****\n",
      "Accuracy: 0.8939860792801969\n",
      "F1 Score: 0.7938311991410589\n",
      "ROC_AUC_Score: 0.8542818233537236\n",
      "Recall: 0.7680356168490574\n",
      "Precision: 0.8275323097247889\n",
      "\n",
      "****SVC****\n",
      "Accuracy: 0.8985018249724132\n",
      "F1 Score: 0.7935669428705625\n",
      "ROC_AUC_Score: 0.8463335186332708\n",
      "Recall: 0.732644565096563\n",
      "Precision: 0.8728184936851369\n",
      "\n",
      "****ANN****\n",
      "Accuracy: 0.8946269416857652\n",
      "F1 Score: 0.792113139360872\n",
      "ROC_AUC_Score: 0.8491334428760945\n",
      "Recall: 0.7509972457497106\n",
      "Precision: 0.8435778712262854\n",
      "\n",
      "****SGD****\n",
      "Accuracy: 0.8907181054239878\n",
      "F1 Score: 0.7893474901439301\n",
      "ROC_AUC_Score: 0.8515601717929402\n",
      "Recall: 0.7662548772634399\n",
      "Precision: 0.8177707652707651\n",
      "\n",
      "****LMT****\n",
      "Accuracy: 0.8887403446226976\n",
      "F1 Score: 0.7847786402143422\n",
      "ROC_AUC_Score: 0.8500378870479827\n",
      "Recall: 0.7667035087476187\n",
      "Precision: 0.8070218679881581\n",
      "\n",
      "****Logitboost****\n",
      "Accuracy: 0.8919913419913421\n",
      "F1 Score: 0.778412364759353\n",
      "ROC_AUC_Score: 0.8350427709780955\n",
      "Recall: 0.7119905535401123\n",
      "Precision: 0.8651271123753421\n"
     ]
    }
   ],
   "source": [
    "sortedClassifiers = sorted(Classifiers.items(), key = lambda x: x[1]['F1 Score'], reverse=True) \n",
    "\n",
    "for classifier in sortedClassifiers:\n",
    "    print(f'\\n****{classifier[0]}****')\n",
    "    for metric, result in classifier[1].items():\n",
    "        print(f'{metric}: {result}')\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-8-132844848622>\u001b[0m(5)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m      3 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      4 \u001b[0;31m\u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbestVarFeatures\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m----> 5 \u001b[0;31m    \u001b[0mRandomForestVar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRandomForest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      6 \u001b[0;31m    \u001b[0mLogisticModelVar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLogisticModelTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      7 \u001b[0;31m    \u001b[0mLogitBoostVar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLogitBoostClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> next\n",
      "Old number of features: 109\n",
      "             New number of features: 22\n",
      "             Number of features removed 87\n",
      "Old number of features: 109\n",
      "             New number of features: 10\n",
      "             Number of features removed 99\n",
      "Old number of features: 109\n",
      "             New number of features: 6\n",
      "             Number of features removed 103\n",
      "Old number of features: 109\n",
      "             New number of features: 4\n",
      "             Number of features removed 105\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "def getVarianceFeatures(X, y, var):\n",
    "    variancefs = VarianceThreshold(threshold=var).fit(X)\n",
    "    cols = variancefs.get_support(indices=True)\n",
    "    new_X = X.iloc[:,cols]\n",
    "    lostFeatures = X.shape[1] - new_X.shape[1]\n",
    "    \n",
    "    print(f'Old number of features: {X.shape[1]}\\n \\\n",
    "            New number of features: {new_X.shape[1]}\\n \\\n",
    "            Number of features removed {lostFeatures}')\n",
    "    \n",
    "    return new_X\n",
    "\n",
    "bestVarFeatures = []\n",
    "variance = [0.05, 0.1, 0.15, 0.2]\n",
    "for i in variance:\n",
    "    bestVarFeatures.append(getVarianceFeatures(X, y, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1537, 109)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jackp/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Var Results**\n",
      "\n",
      "\n",
      " Variance Threshold: 0.05\n",
      "*RandomForest Results**\n",
      "Accuracy:0.8777056277056279\n",
      "F1 Score:0.7562122119211876\n",
      "ROC_AUC_Score:0.825067805563463\n",
      "Recall:0.7116652645241124\n",
      "Precision:0.8109279907084785\n",
      "**\n",
      "LMT Results**\n",
      "Accuracy:0.8412443765384943\n",
      "F1 Score:0.7062721504607441\n",
      "ROC_AUC_Score:0.802192435490985\n",
      "Recall:0.7181580765036915\n",
      "Precision:0.7000348815681214\n",
      "**\n",
      "LogitBoost Results**\n",
      "Accuracy:0.8601137424666836\n",
      "F1 Score:0.7119538418411134\n",
      "ROC_AUC_Score:0.7930849808833605\n",
      "Recall:0.6503783002693225\n",
      "Precision:0.7947853100516112\n",
      "**\n",
      "SGD Results**\n",
      "Accuracy:0.880952380952381\n",
      "F1 Score:0.7624959114846973\n",
      "ROC_AUC_Score:0.8285613945883578\n",
      "Recall:0.7150900419001094\n",
      "Precision:0.8208442191067731\n",
      "**\n",
      "SVM Results**\n",
      "Accuracy:0.8822510822510823\n",
      "F1 Score:0.7558819943813699\n",
      "ROC_AUC_Score:0.8189751521561925\n",
      "Recall:0.6815436517483741\n",
      "Precision:0.855611670865286\n",
      "**\n",
      "ANN Results**\n",
      "Accuracy:0.8822383498854087\n",
      "F1 Score:0.7573178862729388\n",
      "ROC_AUC_Score:0.8220953237608478\n",
      "Recall:0.6922268019315242\n",
      "Precision:0.8424289169355902\n",
      "**\n",
      "DeepLearn Results**\n",
      "Accuracy:0.8789873525167643\n",
      "F1 Score:0.7548951741250208\n",
      "ROC_AUC_Score:0.8212426155437301\n",
      "Recall:0.6960556235164435\n",
      "Precision:0.8296960173345871\n",
      "\n",
      " Variance Threshold: 0.1\n",
      "*RandomForest Results**\n",
      "Accuracy:0.8536329683388507\n",
      "F1 Score:0.7002227123161567\n",
      "ROC_AUC_Score:0.7858379507049011\n",
      "Recall:0.6390808450958944\n",
      "Precision:0.7798050356506239\n",
      "**\n",
      "LMT Results**\n",
      "Accuracy:0.8048170783464901\n",
      "F1 Score:0.625513297747198\n",
      "ROC_AUC_Score:0.7442194213683561\n",
      "Recall:0.6147123396176327\n",
      "Precision:0.6396133822203526\n",
      "**\n",
      "LogitBoost Results**\n",
      "Accuracy:0.8308420337832103\n",
      "F1 Score:0.6316112670666045\n",
      "ROC_AUC_Score:0.739597986568094\n",
      "Recall:0.5434021740612296\n",
      "Precision:0.7610563326689087\n",
      "**\n",
      "SGD Results**\n",
      "Accuracy:0.8536244800950683\n",
      "F1 Score:0.7000344760277121\n",
      "ROC_AUC_Score:0.7857098276107509\n",
      "Recall:0.6378243779857687\n",
      "Precision:0.7824551009616931\n",
      "**\n",
      "SVM Results**\n",
      "Accuracy:0.8490662931839402\n",
      "F1 Score:0.6862370939111004\n",
      "ROC_AUC_Score:0.7764458253641495\n",
      "Recall:0.6176131327356028\n",
      "Precision:0.7794290146128382\n",
      "**\n",
      "ANN Results**\n",
      "Accuracy:0.847109752992106\n",
      "F1 Score:0.6825599786977242\n",
      "ROC_AUC_Score:0.7738640113636837\n",
      "Recall:0.6148951297560534\n",
      "Precision:0.7741959845164015\n",
      "**\n",
      "DeepLearn Results**\n",
      "Accuracy:0.8562346150581446\n",
      "F1 Score:0.7040259362362873\n",
      "ROC_AUC_Score:0.7882080243925527\n",
      "Recall:0.640077670792253\n",
      "Precision:0.7891295935247546\n",
      "\n",
      " Variance Threshold: 0.15\n",
      "*RandomForest Results**\n",
      "Accuracy:0.822383498854087\n",
      "F1 Score:0.6380545794108767\n",
      "ROC_AUC_Score:0.7486952231144667\n",
      "Recall:0.5879295053534803\n",
      "Precision:0.7045724318072251\n",
      "**\n",
      "LMT Results**\n",
      "Accuracy:0.8022026992615228\n",
      "F1 Score:0.6145361753404537\n",
      "ROC_AUC_Score:0.7356080649857006\n",
      "Recall:0.594220109369305\n",
      "Precision:0.6397313463050738\n",
      "**\n",
      "LogitBoost Results**\n",
      "Accuracy:0.8197903403785757\n",
      "F1 Score:0.6015853223240324\n",
      "ROC_AUC_Score:0.7220347432828653\n",
      "Recall:0.5127249467830682\n",
      "Precision:0.7367877492877493\n",
      "**\n",
      "SGD Results**\n",
      "Accuracy:0.8210805534334945\n",
      "F1 Score:0.6345188704196365\n",
      "ROC_AUC_Score:0.7455254783215175\n",
      "Recall:0.5816797185549131\n",
      "Precision:0.7049116117052284\n",
      "**\n",
      "SVM Results**\n",
      "Accuracy:0.8119641796112385\n",
      "F1 Score:0.6062750462750464\n",
      "ROC_AUC_Score:0.7269904108931697\n",
      "Recall:0.5437994741668847\n",
      "Precision:0.6916745853568103\n",
      "**\n",
      "ANN Results**\n",
      "Accuracy:0.8171844495373908\n",
      "F1 Score:0.6171624603684016\n",
      "ROC_AUC_Score:0.733597885515204\n",
      "Recall:0.5535012195759471\n",
      "Precision:0.7056803923599118\n",
      "**\n",
      "DeepLearn Results**\n",
      "Accuracy:0.8197776080129021\n",
      "F1 Score:0.6299108616942941\n",
      "ROC_AUC_Score:0.7421764771464293\n",
      "Recall:0.5740515134267079\n",
      "Precision:0.7051088124254992\n",
      "\n",
      " Variance Threshold: 0.2\n",
      "*RandomForest Results**\n",
      "Accuracy:0.7644724556489262\n",
      "F1 Score:0.4425565370302212\n",
      "ROC_AUC_Score:0.6328946130628013\n",
      "Recall:0.34940122861658923\n",
      "Precision:0.6090562649910476\n",
      "**\n",
      "LMT Results**\n",
      "Accuracy:0.7443298531533825\n",
      "F1 Score:0.5561580589665371\n",
      "ROC_AUC_Score:0.6976425349225549\n",
      "Recall:0.5978571214663585\n",
      "Precision:0.5222292962176999\n",
      "**\n",
      "LogitBoost Results**\n",
      "Accuracy:0.7618665648077413\n",
      "F1 Score:0.4247125073855858\n",
      "ROC_AUC_Score:0.6249197215452933\n",
      "Recall:0.3289507875164336\n",
      "Precision:0.6064600858079119\n",
      "**\n",
      "SGD Results**\n",
      "Accuracy:0.7644724556489262\n",
      "F1 Score:0.4425565370302212\n",
      "ROC_AUC_Score:0.6328946130628013\n",
      "Recall:0.34940122861658923\n",
      "Precision:0.6090562649910476\n",
      "**\n",
      "SVM Results**\n",
      "Accuracy:0.7644724556489262\n",
      "F1 Score:0.4425565370302212\n",
      "ROC_AUC_Score:0.6328946130628013\n",
      "Recall:0.34940122861658923\n",
      "Precision:0.6090562649910476\n",
      "**\n",
      "ANN Results**\n",
      "Accuracy:0.7638231049995756\n",
      "F1 Score:0.4493725306638738\n",
      "ROC_AUC_Score:0.623764397580889\n",
      "Recall:0.3544347388249827\n",
      "Precision:0.6208705974648003\n",
      "**\n",
      "DeepLearn Results**\n",
      "Accuracy:0.7644724556489262\n",
      "F1 Score:0.4425565370302212\n",
      "ROC_AUC_Score:0.6328946130628013\n",
      "Recall:0.34940122861658923\n",
      "Precision:0.6090562649910476\n"
     ]
    }
   ],
   "source": [
    "RandomForestVar, LogisticModelVar, LogitBoostVar, SGDVar, SVMVar, ANNVar, DeepLearnVar = [], [], [], [], [], [], []\n",
    "\n",
    "\n",
    "for Xvar in bestVarFeatures:\n",
    "    RandomForestVar.append(RandomForest(Xvar, y))\n",
    "    LogisticModelVar.append(LogisticModelTree(Xvar, y))\n",
    "    LogitBoostVar.append(LogitBoostClassifier(Xvar, y))\n",
    "    SGDVar.append(SGD(Xvar, y))\n",
    "    SVMVar.append(SVM(Xvar, y))\n",
    "    ANNVar.append(ANN(Xvar, y))\n",
    "    DeepLearnVar.append(deepLearn(Xvar, y))\n",
    "\n",
    "\n",
    "print('**Var Results**\\n')\n",
    "for i, k in enumerate(variance):\n",
    "   \n",
    "    print(f'\\n Variance Threshold: {k}')\n",
    "   \n",
    "    \n",
    "    print('*RandomForest Results**')\n",
    "    for metric, score in RandomForestVar[i][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "    \n",
    "    print('**\\nLMT Results**')\n",
    "    for metric, score in LogisticModelVar[i][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "    \n",
    "    print('**\\nLogitBoost Results**')\n",
    "    for metric, score in LogitBoostVar[i][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "    \n",
    "    print('**\\nSGD Results**')\n",
    "    for metric, score in SGDVar[i][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "    \n",
    "    print('**\\nSVM Results**')\n",
    "    for metric, score in SVMVar[i][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "    \n",
    "    print('**\\nANN Results**')\n",
    "    for metric, score in ANNVar[i][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "    \n",
    "    print('**\\nDeepLearn Results**')\n",
    "    for metric, score in DeepLearnVar[i][0].items():\n",
    "        print(f'{metric}:{score.mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi2  Info Gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2, mutual_info_classif\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# fschi2 = SelectKBest(chi2, k='all')\n",
    "# fschi2.fit(X, y)\n",
    "# fschi2.transform(X)\n",
    "# fs_info_gain = SelectKBest(mutual_info_classif, k='all')\n",
    "# fs_info_gain.fit(X, y)\n",
    "# fs_info_gain.transform(X)\n",
    "# bestfeatschi2 = []\n",
    "# bestfeats_info_gain = []\n",
    "# bestFeatsThresholdChi2 = [50, 75, 100, 150]\n",
    "# for treshold in bestFeatsThreshold:\n",
    "#     bestfeatschi2.append([i for i in fschi2.scores_ if i > treshold])\n",
    "#     bestfeats_info_gain.append([i for i in fs_info_gain.scores_ if i > treshold])\n",
    "    \n",
    "# for index,value in enumerate(bestfeatschi2):\n",
    "#     pyplot.bar([i for i in range(len(bestfeatschi2[index]))], bestfeatschi2[index])\n",
    "#     pyplot.show()\n",
    "#     pyplot.bar([i for i in range(len(bestfeats_info_gain[index]))], bestfeats_info_gain[index])\n",
    "#     pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1537, 109)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "bestK = [25, 40, 50, 70, 100]\n",
    "bestChiFeatures = []\n",
    "bestInfoGainFeatures = []\n",
    "def getChi2Features(X, y, k):\n",
    "    chi2fs = SelectKBest(score_func=chi2, k=k).fit(X, y)\n",
    "    cols = chi2fs.get_support(indices=True)\n",
    "    new_X = X.iloc[:,cols]\n",
    "    return new_X\n",
    "\n",
    "def getInfoGainFeatures(X, y, k):\n",
    "    InfoGainfs = SelectKBest(score_func=mutual_info_classif, k=k).fit(X, y)\n",
    "    cols = InfoGainfs.get_support(indices=True)\n",
    "    new_X = X.iloc[:,cols]\n",
    "    return new_X\n",
    "\n",
    "for i in bestK:\n",
    "    bestChiFeatures.append(getChi2Features(X,y,i))\n",
    "    bestInfoGainFeatures.append(getInfoGainFeatures(X, y, i))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Chi2 Results**\n",
      "\n",
      "\n",
      "K number of Features: 25\n",
      "*RandomForest Results**\n",
      "Accuracy:0.8783040488922843\n",
      "F1 Score:0.7527505735980313\n",
      "ROC_AUC_Score:0.8197331310788671\n",
      "Recall:0.6919729162220081\n",
      "Precision:0.8301617570031132\n",
      "**\n",
      "LMT Results**\n",
      "Accuracy:0.8535565741448096\n",
      "F1 Score:0.7333048630791659\n",
      "ROC_AUC_Score:0.8233383077711233\n",
      "Recall:0.75692635906803\n",
      "Precision:0.7152107690941819\n",
      "**\n",
      "LogitBoost Results**\n",
      "Accuracy:0.8731092436974791\n",
      "F1 Score:0.7428681602370986\n",
      "ROC_AUC_Score:0.8149435539779877\n",
      "Recall:0.6885145293655931\n",
      "Precision:0.8140567205652595\n",
      "**\n",
      "SGD Results**\n",
      "Accuracy:0.8770011034716918\n",
      "F1 Score:0.7520009423140807\n",
      "ROC_AUC_Score:0.821450398454594\n",
      "Recall:0.6996813272796666\n",
      "Precision:0.8189455122249442\n",
      "**\n",
      "SVM Results**\n",
      "Accuracy:0.8757024021729904\n",
      "F1 Score:0.744857681017479\n",
      "ROC_AUC_Score:0.8145481073278894\n",
      "Recall:0.6805992223926837\n",
      "Precision:0.832682058162453\n",
      "**\n",
      "ANN Results**\n",
      "Accuracy:0.8796069943128767\n",
      "F1 Score:0.7524313654601649\n",
      "ROC_AUC_Score:0.819990889934525\n",
      "Recall:0.689448643746516\n",
      "Precision:0.8334491360260123\n",
      "**\n",
      "DeepLearn Results**\n",
      "Accuracy:0.8933112638994991\n",
      "F1 Score:0.7946457864603546\n",
      "ROC_AUC_Score:0.8562840938659694\n",
      "Recall:0.7753715668357599\n",
      "Precision:0.8209022686301152\n",
      "\n",
      "K number of Features: 40\n",
      "*RandomForest Results**\n",
      "Accuracy:0.884806043629573\n",
      "F1 Score:0.7677602186406293\n",
      "ROC_AUC_Score:0.8319869637860731\n",
      "Recall:0.7163426068921657\n",
      "Precision:0.8327553948521691\n",
      "**\n",
      "LMT Results**\n",
      "Accuracy:0.8750657838893133\n",
      "F1 Score:0.7614569505370056\n",
      "ROC_AUC_Score:0.8353169561835863\n",
      "Recall:0.748912301053972\n",
      "Precision:0.7786501200895294\n",
      "**\n",
      "LogitBoost Results**\n",
      "Accuracy:0.8789703760291996\n",
      "F1 Score:0.7484307173036788\n",
      "ROC_AUC_Score:0.8149746460559175\n",
      "Recall:0.6763104732590979\n",
      "Precision:0.8479492979247688\n",
      "**\n",
      "SGD Results**\n",
      "Accuracy:0.8835030982089807\n",
      "F1 Score:0.7668705114887164\n",
      "ROC_AUC_Score:0.832757956082129\n",
      "Recall:0.7212876618372206\n",
      "Precision:0.824978237250628\n",
      "**\n",
      "SVM Results**\n",
      "Accuracy:0.8737543502249385\n",
      "F1 Score:0.7436796357022096\n",
      "ROC_AUC_Score:0.8153590693444459\n",
      "Recall:0.6873883032305449\n",
      "Precision:0.8205856662987394\n",
      "**\n",
      "ANN Results**\n",
      "Accuracy:0.8887318563789153\n",
      "F1 Score:0.7735304197811376\n",
      "ROC_AUC_Score:0.8349638166326319\n",
      "Recall:0.7177513282521065\n",
      "Precision:0.8480081795387523\n",
      "**\n",
      "DeepLearn Results**\n",
      "Accuracy:0.8985230455818691\n",
      "F1 Score:0.7996094863350885\n",
      "ROC_AUC_Score:0.8545520292188588\n",
      "Recall:0.7588844520393561\n",
      "Precision:0.8477052954736237\n",
      "\n",
      "K number of Features: 50\n",
      "*RandomForest Results**\n",
      "Accuracy:0.8874204227145404\n",
      "F1 Score:0.7756941776755999\n",
      "ROC_AUC_Score:0.837595790636467\n",
      "Recall:0.7294630079150057\n",
      "Precision:0.8339237581884641\n",
      "**\n",
      "LMT Results**\n",
      "Accuracy:0.8828792122909771\n",
      "F1 Score:0.7674801643882851\n",
      "ROC_AUC_Score:0.8335971138470567\n",
      "Recall:0.726875744114976\n",
      "Precision:0.8192301069648238\n",
      "**\n",
      "LogitBoost Results**\n",
      "Accuracy:0.8835285629403277\n",
      "F1 Score:0.7577815016908012\n",
      "ROC_AUC_Score:0.8204899528793895\n",
      "Recall:0.6837526246036882\n",
      "Precision:0.859448853862966\n",
      "**\n",
      "SGD Results**\n",
      "Accuracy:0.8874161785926493\n",
      "F1 Score:0.7764190733090909\n",
      "ROC_AUC_Score:0.83873065238895\n",
      "Recall:0.732591213043211\n",
      "Precision:0.8315810402459952\n",
      "**\n",
      "SVM Results**\n",
      "Accuracy:0.8822256175197353\n",
      "F1 Score:0.7595957497249988\n",
      "ROC_AUC_Score:0.8242691569248191\n",
      "Recall:0.6981674498145696\n",
      "Precision:0.8438703814170706\n",
      "**\n",
      "ANN Results**\n",
      "Accuracy:0.8939393939393939\n",
      "F1 Score:0.7829098781959378\n",
      "ROC_AUC_Score:0.8409987767193824\n",
      "Recall:0.7262911583407172\n",
      "Precision:0.8558427418903752\n",
      "**\n",
      "DeepLearn Results**\n",
      "Accuracy:0.903076988371106\n",
      "F1 Score:0.8078466147387628\n",
      "ROC_AUC_Score:0.8585936673207725\n",
      "Recall:0.762660291120073\n",
      "Precision:0.8608761264575218\n",
      "\n",
      "K number of Features: 70\n",
      "*RandomForest Results**\n",
      "Accuracy:0.8893812070282658\n",
      "F1 Score:0.7827205607608678\n",
      "ROC_AUC_Score:0.8463071605490112\n",
      "Recall:0.7540058756164101\n",
      "Precision:0.8184642026115825\n",
      "**\n",
      "LMT Results**\n",
      "Accuracy:0.8731092436974791\n",
      "F1 Score:0.7554498433772352\n",
      "ROC_AUC_Score:0.8296940242139857\n",
      "Recall:0.7360377487769807\n",
      "Precision:0.7810716479236155\n",
      "**\n",
      "LogitBoost Results**\n",
      "Accuracy:0.8835328070622189\n",
      "F1 Score:0.7563770134696663\n",
      "ROC_AUC_Score:0.8192044229216648\n",
      "Recall:0.6803797386244195\n",
      "Precision:0.8616514114000345\n",
      "**\n",
      "SGD Results**\n",
      "Accuracy:0.8900348017995077\n",
      "F1 Score:0.7826822669632623\n",
      "ROC_AUC_Score:0.8453132432319375\n",
      "Recall:0.7491974144010989\n",
      "Precision:0.8233267364916982\n",
      "**\n",
      "SVM Results**\n",
      "Accuracy:0.8874204227145404\n",
      "F1 Score:0.7695771745675815\n",
      "ROC_AUC_Score:0.8301688533823803\n",
      "Recall:0.7057286487782075\n",
      "Precision:0.8539705340186726\n",
      "**\n",
      "ANN Results**\n",
      "Accuracy:0.8874416433239963\n",
      "F1 Score:0.7760032990457717\n",
      "ROC_AUC_Score:0.8385847150317532\n",
      "Recall:0.7333165608661197\n",
      "Precision:0.8275293592493081\n",
      "**\n",
      "DeepLearn Results**\n",
      "Accuracy:0.9017740429505136\n",
      "F1 Score:0.8076074335973761\n",
      "ROC_AUC_Score:0.8618370457536724\n",
      "Recall:0.7752791497389317\n",
      "Precision:0.84522325315072\n",
      "\n",
      "K number of Features: 100\n",
      "*RandomForest Results**\n",
      "Accuracy:0.8971988795518208\n",
      "F1 Score:0.8001699160937088\n",
      "ROC_AUC_Score:0.8578477513256976\n",
      "Recall:0.7716378265488281\n",
      "Precision:0.8374393746875188\n",
      "**\n",
      "LMT Results**\n",
      "Accuracy:0.869862490450726\n",
      "F1 Score:0.7620650554642322\n",
      "ROC_AUC_Score:0.8445487896156703\n",
      "Recall:0.7894398647888529\n",
      "Precision:0.7407222481508196\n",
      "**\n",
      "LogitBoost Results**\n",
      "Accuracy:0.8828877005347595\n",
      "F1 Score:0.7578332259601759\n",
      "ROC_AUC_Score:0.8214093791715348\n",
      "Recall:0.6882833704792708\n",
      "Precision:0.8542318501799624\n",
      "**\n",
      "SGD Results**\n",
      "Accuracy:0.8991596638655462\n",
      "F1 Score:0.8023248618431491\n",
      "ROC_AUC_Score:0.857904626281028\n",
      "Recall:0.7682857731967747\n",
      "Precision:0.8439849355061165\n",
      "**\n",
      "SVM Results**\n",
      "Accuracy:0.8978567184449538\n",
      "F1 Score:0.7904374679129775\n",
      "ROC_AUC_Score:0.8430056173821594\n",
      "Recall:0.7233912817944992\n",
      "Precision:0.8778768369400746\n",
      "**\n",
      "ANN Results**\n",
      "Accuracy:0.892649180884475\n",
      "F1 Score:0.7932183331573576\n",
      "ROC_AUC_Score:0.8539617586718762\n",
      "Recall:0.7705422824976536\n",
      "Precision:0.8203003102306239\n",
      "**\n",
      "DeepLearn Results**\n",
      "Accuracy:0.8959129106187931\n",
      "F1 Score:0.7966934225021525\n",
      "ROC_AUC_Score:0.8553761938065605\n",
      "Recall:0.7665764470362291\n",
      "Precision:0.8331306534369002\n"
     ]
    }
   ],
   "source": [
    "RandomForestChi, LogisticModelChi, LogitBoostChi, SGDChi, SVMChi, ANNChi, DeepLearnChi = [], [], [], [], [], [], []\n",
    "\n",
    "\n",
    "for Xchi in bestChiFeatures:\n",
    "    RandomForestChi.append(RandomForest(Xchi, y))\n",
    "    LogisticModelChi.append(LogisticModelTree(Xchi, y))\n",
    "    LogitBoostChi.append(LogitBoostClassifier(Xchi, y))\n",
    "    SGDChi.append(SGD(Xchi, y))\n",
    "    SVMChi.append(SVM(Xchi, y))\n",
    "    ANNChi.append(ANN(Xchi, y))\n",
    "    DeepLearnChi.append(deepLearn(X, y))\n",
    "\n",
    "  \n",
    "print('**Chi2 Results**\\n')\n",
    "for i, k in enumerate(bestK):\n",
    "   \n",
    "    print(f'\\nK number of Features: {k}')\n",
    "   \n",
    "    \n",
    "    print('*RandomForest Results**')\n",
    "    for metric, score in RandomForestChi[i][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "    \n",
    "    print('**\\nLMT Results**')\n",
    "    for metric, score in LogisticModelChi[i][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "    \n",
    "    print('**\\nLogitBoost Results**')\n",
    "    for metric, score in LogitBoostChi[i][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "    \n",
    "    print('**\\nSGD Results**')\n",
    "    for metric, score in SGDChi[i][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "    \n",
    "    print('**\\nSVM Results**')\n",
    "    for metric, score in SVMChi[i][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "    \n",
    "    print('**\\nANN Results**')\n",
    "    for metric, score in ANNChi[i][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "    \n",
    "    print('**\\nDeepLearn Results**')\n",
    "    for metric, score in DeepLearnChi[i][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Infomation Gain Results**\n",
      "\n",
      "\n",
      "K number of Features: 25\n",
      "\n",
      "**RandomForest Results**\n",
      "Accuracy:0.8770180799592564\n",
      "F1 Score:0.750724375543164\n",
      "ROC_AUC_Score:0.8204160327775449\n",
      "Recall:0.6967823230314149\n",
      "Precision:0.8232004204945381\n",
      "\n",
      "**LMT Results**\n",
      "Accuracy:0.8542356336473984\n",
      "F1 Score:0.7333456976718846\n",
      "ROC_AUC_Score:0.8229172188492123\n",
      "Recall:0.7543073114489823\n",
      "Precision:0.7180409360161681\n",
      "\n",
      "**LogitBoost Results**\n",
      "Accuracy:0.8718190306425602\n",
      "F1 Score:0.7409380964847696\n",
      "ROC_AUC_Score:0.8139141574989829\n",
      "Recall:0.6864343672942531\n",
      "Precision:0.81518494975316\n",
      "\n",
      "**SGD Results**\n",
      "Accuracy:0.878321025379849\n",
      "F1 Score:0.7543854280648137\n",
      "ROC_AUC_Score:0.823451370259316\n",
      "Recall:0.7037213474216587\n",
      "Precision:0.8215959703606762\n",
      "\n",
      "**SVM Results**\n",
      "Accuracy:0.8757278669043375\n",
      "F1 Score:0.7511378675836998\n",
      "ROC_AUC_Score:0.8212159734693689\n",
      "Recall:0.7020120117566926\n",
      "Precision:0.8165134442288517\n",
      "\n",
      "**ANN Results**\n",
      "Accuracy:0.8776759188523895\n",
      "F1 Score:0.7533239916860077\n",
      "ROC_AUC_Score:0.821953207269757\n",
      "Recall:0.7008663904691408\n",
      "Precision:0.8218432083649475\n",
      "\n",
      "**DeepLearn Results**\n",
      "Accuracy:0.8809184279772516\n",
      "F1 Score:0.7561219793047456\n",
      "ROC_AUC_Score:0.8227654158708197\n",
      "Recall:0.6961871523918747\n",
      "Precision:0.8342915711424288\n",
      "\n",
      "K number of Features: 40\n",
      "\n",
      "**RandomForest Results**\n",
      "Accuracy:0.8815677786266022\n",
      "F1 Score:0.7647620290373413\n",
      "ROC_AUC_Score:0.8314476304320951\n",
      "Recall:0.7226129514673884\n",
      "Precision:0.818742969304739\n",
      "\n",
      "**LMT Results**\n",
      "Accuracy:0.878321025379849\n",
      "F1 Score:0.769338053981067\n",
      "ROC_AUC_Score:0.8402895824354302\n",
      "Recall:0.7572463358392263\n",
      "Precision:0.7871884677754698\n",
      "\n",
      "**LogitBoost Results**\n",
      "Accuracy:0.8828707240471946\n",
      "F1 Score:0.7554857359189034\n",
      "ROC_AUC_Score:0.8197107005696731\n",
      "Recall:0.682943841188522\n",
      "Precision:0.8559316575146887\n",
      "\n",
      "**SGD Results**\n",
      "Accuracy:0.8848187759952466\n",
      "F1 Score:0.771476431891461\n",
      "ROC_AUC_Score:0.8349403055210463\n",
      "Recall:0.7271770540314909\n",
      "Precision:0.8268248879021375\n",
      "\n",
      "**SVM Results**\n",
      "Accuracy:0.8848187759952466\n",
      "F1 Score:0.766584814846828\n",
      "ROC_AUC_Score:0.8285488040337367\n",
      "Recall:0.7062151268134662\n",
      "Precision:0.8462261724430418\n",
      "\n",
      "**ANN Results**\n",
      "Accuracy:0.8932688226805874\n",
      "F1 Score:0.7840321767348508\n",
      "ROC_AUC_Score:0.8422789965655803\n",
      "Recall:0.7328755291679526\n",
      "Precision:0.8547317682317683\n",
      "\n",
      "**DeepLearn Results**\n",
      "Accuracy:0.8848187759952466\n",
      "F1 Score:0.7647029064905653\n",
      "ROC_AUC_Score:0.8277286645571371\n",
      "Recall:0.7045732675740459\n",
      "Precision:0.8435046194723613\n",
      "\n",
      "K number of Features: 50\n",
      "\n",
      "**RandomForest Results**\n",
      "Accuracy:0.8835285629403277\n",
      "F1 Score:0.7674439435723686\n",
      "ROC_AUC_Score:0.8337389808396753\n",
      "Recall:0.7249467724031813\n",
      "Precision:0.8222225097225098\n",
      "\n",
      "**LMT Results**\n",
      "Accuracy:0.8724811136575843\n",
      "F1 Score:0.756590591319737\n",
      "ROC_AUC_Score:0.8320946132823378\n",
      "Recall:0.7452297437738538\n",
      "Precision:0.7724719735049883\n",
      "\n",
      "**LogitBoost Results**\n",
      "Accuracy:0.8822256175197353\n",
      "F1 Score:0.7557576446892327\n",
      "ROC_AUC_Score:0.819887109605105\n",
      "Recall:0.6853187630146633\n",
      "Precision:0.8510491855451289\n",
      "\n",
      "**SGD Results**\n",
      "Accuracy:0.8861259655377303\n",
      "F1 Score:0.7726307094473271\n",
      "ROC_AUC_Score:0.8369861375016079\n",
      "Recall:0.729723782627\n",
      "Precision:0.8264407217367745\n",
      "\n",
      "**SVM Results**\n",
      "Accuracy:0.884827264239029\n",
      "F1 Score:0.7642925699978627\n",
      "ROC_AUC_Score:0.8268247442004826\n",
      "Recall:0.7007391759350763\n",
      "Precision:0.8490724554667883\n",
      "\n",
      "**ANN Results**\n",
      "Accuracy:0.8848484848484848\n",
      "F1 Score:0.7690282577054699\n",
      "ROC_AUC_Score:0.8338662238865086\n",
      "Recall:0.7235444511472016\n",
      "Precision:0.82951633091053\n",
      "\n",
      "**DeepLearn Results**\n",
      "Accuracy:0.8874289109583227\n",
      "F1 Score:0.7708634187520953\n",
      "ROC_AUC_Score:0.8342211462487426\n",
      "Recall:0.7188123038618627\n",
      "Precision:0.8382285652239346\n",
      "\n",
      "K number of Features: 70\n",
      "\n",
      "**RandomForest Results**\n",
      "Accuracy:0.8919998302351244\n",
      "F1 Score:0.7912806185220271\n",
      "ROC_AUC_Score:0.8524111315152106\n",
      "Recall:0.7663450258535883\n",
      "Precision:0.8240684436336612\n",
      "\n",
      "**LMT Results**\n",
      "Accuracy:0.8822553263729734\n",
      "F1 Score:0.7781288526335302\n",
      "ROC_AUC_Score:0.8491161215241908\n",
      "Recall:0.7771759631225121\n",
      "Precision:0.7836536193678534\n",
      "\n",
      "**LogitBoost Results**\n",
      "Accuracy:0.8900475341651812\n",
      "F1 Score:0.7770418382706519\n",
      "ROC_AUC_Score:0.8355312536089059\n",
      "Recall:0.7173660209199907\n",
      "Precision:0.8552002098649469\n",
      "\n",
      "**SGD Results**\n",
      "Accuracy:0.8900475341651812\n",
      "F1 Score:0.7885047033364461\n",
      "ROC_AUC_Score:0.850746663697892\n",
      "Recall:0.7647951229544379\n",
      "Precision:0.820590033520201\n",
      "\n",
      "**SVM Results**\n",
      "Accuracy:0.8939563704269586\n",
      "F1 Score:0.7862019770784435\n",
      "ROC_AUC_Score:0.8438550282046233\n",
      "Recall:0.734644565096563\n",
      "Precision:0.8534770908964457\n",
      "\n",
      "**ANN Results**\n",
      "Accuracy:0.88874883286648\n",
      "F1 Score:0.7822386252696932\n",
      "ROC_AUC_Score:0.8470341876478544\n",
      "Recall:0.7569168981693631\n",
      "Precision:0.8171617551793918\n",
      "\n",
      "**DeepLearn Results**\n",
      "Accuracy:0.8894024276377218\n",
      "F1 Score:0.7777326662703977\n",
      "ROC_AUC_Score:0.8390493223456433\n",
      "Recall:0.7315191208647358\n",
      "Precision:0.8362247852347791\n",
      "\n",
      "K number of Features: 100\n",
      "\n",
      "**RandomForest Results**\n",
      "Accuracy:0.8946184534419828\n",
      "F1 Score:0.7958578527223017\n",
      "ROC_AUC_Score:0.8542276308154217\n",
      "Recall:0.7663129492727314\n",
      "Precision:0.8331933286811335\n",
      "\n",
      "**LMT Results**\n",
      "Accuracy:0.8867838044308632\n",
      "F1 Score:0.7811610081435166\n",
      "ROC_AUC_Score:0.8470933842220905\n",
      "Recall:0.7618254599671309\n",
      "Precision:0.8050428943869724\n",
      "\n",
      "**LogitBoost Results**\n",
      "Accuracy:0.8926406926406927\n",
      "F1 Score:0.7791430651245302\n",
      "ROC_AUC_Score:0.8355264214318417\n",
      "Recall:0.7119905535401123\n",
      "Precision:0.8654634504988558\n",
      "\n",
      "**SGD Results**\n",
      "Accuracy:0.8952678040913336\n",
      "F1 Score:0.7975471717490029\n",
      "ROC_AUC_Score:0.8569008551614017\n",
      "Recall:0.7733937007559218\n",
      "Precision:0.8278755731552996\n",
      "\n",
      "**SVM Results**\n",
      "Accuracy:0.8978524743230626\n",
      "F1 Score:0.7924634050581639\n",
      "ROC_AUC_Score:0.8459061682059204\n",
      "Recall:0.732644565096563\n",
      "Precision:0.8708440453692251\n",
      "\n",
      "**ANN Results**\n",
      "Accuracy:0.888774297597827\n",
      "F1 Score:0.7834041959770547\n",
      "ROC_AUC_Score:0.8462273591535159\n",
      "Recall:0.7548983435532476\n",
      "Precision:0.8181565653329581\n",
      "\n",
      "**DeepLearn Results**\n",
      "Accuracy:0.8913632119514473\n",
      "F1 Score:0.7876920630831827\n",
      "ROC_AUC_Score:0.8470924269096652\n",
      "Recall:0.751317222520907\n",
      "Precision:0.8306949033166013\n"
     ]
    }
   ],
   "source": [
    "RandomForestInfoGain, LogisticModelInfoGain, LogitBoostInfoGain, SGDInfoGain, SVMInfoGain, ANNInfoGain, DeepLearnInfoGain = [], [], [], [], [], [], []\n",
    "\n",
    "for XInfo in bestInfoGainFeatures:\n",
    "    RandomForestInfoGain.append(RandomForest(XInfo, y))\n",
    "    LogisticModelInfoGain.append(LogisticModelTree(XInfo, y))\n",
    "    LogitBoostInfoGain.append(LogitBoostClassifier(XInfo, y))\n",
    "    SGDInfoGain.append(SGD(XInfo, y))\n",
    "    SVMInfoGain.append(SVM(XInfo, y))\n",
    "    ANNInfoGain.append(ANN(XInfo, y))\n",
    "    DeepLearnInfoGain.append(deepLearn(XInfo, y))\n",
    "\n",
    "\n",
    "print('**Infomation Gain Results**\\n')\n",
    "for i, k in enumerate(bestK):\n",
    "   \n",
    "    \n",
    "    print(f'\\nK number of Features: {k}')\n",
    "    \n",
    "    print('\\n**RandomForest Results**')\n",
    "    for metric, score in RandomForestInfoGain[i][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "    \n",
    "    print('\\n**LMT Results**')\n",
    "    for metric, score in LogisticModelInfoGain[i][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "    \n",
    "    print('\\n**LogitBoost Results**')\n",
    "    for metric, score in LogitBoostInfoGain[i][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "    \n",
    "    print('\\n**SGD Results**')\n",
    "    for metric, score in SGDInfoGain[i][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "    \n",
    "    print('\\n**SVM Results**')\n",
    "    for metric, score in SVMInfoGain[i][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "    \n",
    "    print('\\n**ANN Results**')\n",
    "    for metric, score in ANNInfoGain[i][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "    \n",
    "    print('\\n**DeepLearn Results**')\n",
    "    for metric, score in DeepLearnInfoGain[i][0].items():\n",
    "        print(f'{metric}:{score.mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
