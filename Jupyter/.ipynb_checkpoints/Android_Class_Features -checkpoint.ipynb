{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Android Classes Feature Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set __location__ depeneing which operating system user is on \n",
    "\n",
    "if os.name == \"nt\": \n",
    "    __location__ = \"F:\\FinalYearProject\\Machine Learning\\Features\\CIC_dataset\\\\\"\n",
    "else:\n",
    "    __location__ = \"/media/jackp/JACK PYE/FinalYearProject/Machine Learning/Features/CIC_dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset into panda dataframe\n",
    "df = pd.read_csv(os.path.join(__location__,\"api_dataset.csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1582, 1154)\n",
      "removed 3353 Features\n"
     ]
    }
   ],
   "source": [
    "#Exploring the first five entries of the dataset to show the features that have been collected\n",
    "df.head()\n",
    "old_shape = df.shape\n",
    "\n",
    "#remove features that are not supported \n",
    "df = df.loc[:, (df.sum(axis=0) != 0)]\n",
    "print(df.shape)\n",
    "new_shape = df.shape\n",
    "print(f'removed {old_shape[1] - new_shape[1]} Features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert \"Malware and Beignin lables into 1 and 0\"\n",
    "df[\"malware\"] = (df[\"malware\"] == 'Malware').astype(int)\n",
    "y = df['malware']\n",
    "X = df.drop('malware', axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomForest(X, y, kfold=10, seed=101):\n",
    "    \n",
    "    kf = KFold(n_splits=kfold,shuffle=True, random_state=seed)\n",
    "    \n",
    "    accuracy_score_avg, f1_score_avg, roc_auc_score_avg, recall_score_avg, precision_score_avg = np.empty(kfold), np.empty(kfold), \\\n",
    "                                                                                    np.empty(kfold), np.empty(kfold), np.empty(kfold)\n",
    "    randomForestMetrics = {'Accuracy': accuracy_score_avg, 'F1 Score': f1_score_avg, 'ROC_AUC_Score': roc_auc_score_avg, \n",
    "                           'Recall': recall_score_avg, 'Precision': precision_score_avg}\n",
    "    \n",
    "    ## create array to hold all confusion matrices \n",
    "    cm_holder = []\n",
    "    count = 0 \n",
    "    for train_index, test_index in kf.split(X):\n",
    "\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        clf = RandomForestClassifier()\n",
    "        clf.fit(X_train, y_train.ravel())\n",
    "        pred = clf.predict(X_test)\n",
    "        \n",
    "        accuracy_score_avg[count] = accuracy_score(y_test, pred)\n",
    "        f1_score_avg[count] = f1_score(y_test, pred)\n",
    "        roc_auc_score_avg[count] = roc_auc_score(y_test, pred)\n",
    "        recall_score_avg[count] = recall_score(y_test, pred)\n",
    "        precision_score_avg[count] = precision_score(y_test, pred)\n",
    "        cm_holder.append(confusion_matrix(y_test, pred))\n",
    "\n",
    "        count = count + 1\n",
    "        \n",
    "    #if for any reason a metric in the folds returns 0.0\n",
    "    #remove it from the list\n",
    "    for key, values in randomForestMetrics.items():\n",
    "        randomForestMetrics[key] = np.array([value for value in randomForestMetrics[key] if value != 0.0])\n",
    "        randomForestMetrics[key] = randomForestMetrics[key].mean()  \n",
    "    \n",
    "    \n",
    "    true_pos, true_neg, false_pos, false_neg = [], [], [], []\n",
    "\n",
    "    for cm in cm_holder:\n",
    "        true_pos.append(cm[0][0])\n",
    "        false_pos.append(cm[0][1])\n",
    "        true_neg.append(cm[1][0])\n",
    "        false_neg.append(cm[1][1])\n",
    "    \n",
    "    avg_cm = np.matrix([[sum(true_pos), sum(false_pos)], [sum(true_neg), sum(false_neg)]])\n",
    "    \n",
    "    return randomForestMetrics, avg_cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.939355942998169\n",
      "F1 Score:0.8827410678385549\n",
      "ROC_AUC_Score:0.9134641476313574\n",
      "Recall:0.8580343198169598\n",
      "Precision:0.9100298275980669\n",
      "[[1122   36]\n",
      " [  60  364]]\n"
     ]
    }
   ],
   "source": [
    "randomForestMetrics, cm = RandomForest(X, y)\n",
    "\n",
    "Classifiers = {'Random Forest': randomForestMetrics}\n",
    "\n",
    "for metric, score in randomForestMetrics.items():\n",
    "    print(f'{metric}:{score}')\n",
    "    \n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Model Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lmt import LinearModelTree\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statistics import median\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def LogisticModelTree(X, y, kfold=10, seed=101):\n",
    "    \n",
    "    shared_scaler = StandardScaler()\n",
    "    shared_scaler.fit(X)\n",
    "\n",
    "    def fit_linear_model(x, y):\n",
    "        lr = Ridge()\n",
    "        lr.fit(shared_scaler.transform(x), y)\n",
    "        return SharedScalerModel(shared_scaler, lr)\n",
    "\n",
    "    class SharedScalerModel:\n",
    "\n",
    "        def __init__(self, scaler, lm):\n",
    "            self.scaler = scaler\n",
    "            self.lm = lm\n",
    "            self.coef_ = lm.coef_\n",
    "            self.intercept_ = lm.intercept_\n",
    "\n",
    "        def predict(self, X):\n",
    "            return self.lm.predict(self.scaler.transform(X))\n",
    "\n",
    "\n",
    "    MIN_NODE_SIZE = 100\n",
    "    MIN_SPLIT_IMPROVEMENT = 10\n",
    "    lmt = LinearModelTree(MIN_NODE_SIZE, fit_linear_model, min_split_improvement=MIN_SPLIT_IMPROVEMENT)\n",
    "    \n",
    "    def GetThreshold(lmt, X, y, kfold=10, seed=101):\n",
    "        \n",
    "        pred_class = []\n",
    "\n",
    "        kf = KFold(n_splits=kfold,shuffle=True, random_state=seed)\n",
    "        fold = 0\n",
    "        best_thresholds_roc_auc, best_thresholds_f1 = [], []\n",
    "        threshold_list = [0.05,0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5,0.55,0.6,0.65,0.7,0.75,0.8,0.85,0.9,0.95,0.99]\n",
    "        for train_index, test_index in kf.split(X):\n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            lmt.build_tree(X_train.values, X_train, y_train.values)\n",
    "            pred = lmt.predict(X_test.values, X_test)\n",
    "\n",
    "            pred = [round(i, 2) for i in pred]\n",
    "\n",
    "        #     preds.append(pred)\n",
    "\n",
    "\n",
    "            pred_threshold = []\n",
    "\n",
    "            for threshold in threshold_list:\n",
    "                pred_threshold.append([1 if x>threshold else 0 for x in pred])\n",
    "\n",
    "            best_kfold_f1, best_kfold_roc_auc = [0 for i in range(10)], [0 for i in range(10)]\n",
    "\n",
    "            for c, value in enumerate(pred_threshold):\n",
    "                f1 = f1_score(y_test, value)\n",
    "                roc_auc = roc_auc_score(y_test, value)\n",
    "\n",
    "\n",
    "                if c == 0:\n",
    "                    best_kfold_f1[0], best_kfold_roc_auc[0] = f1, roc_auc\n",
    "                    best_kfold_f1[1], best_kfold_roc_auc[1] = threshold_list[c], threshold_list[c]\n",
    "\n",
    "                if best_kfold_f1[0] < f1:\n",
    "                    best_kfold_f1[0] = f1\n",
    "                    best_kfold_f1[1] = threshold_list[c]\n",
    "\n",
    "                if best_kfold_roc_auc[0] < roc_auc:\n",
    "                    best_kfold_roc_auc[0] = roc_auc\n",
    "                    best_kfold_roc_auc[1] = threshold_list[c]\n",
    "\n",
    "                if c == (len(pred_threshold) - 1):\n",
    "                    best_thresholds_roc_auc.append(best_kfold_roc_auc[1])\n",
    "                    best_thresholds_f1.append(best_kfold_f1[1])\n",
    "                    \n",
    "                    \n",
    "\n",
    "            fold = fold + 1\n",
    "\n",
    "        best_threshold_roc_auc = median(best_thresholds_roc_auc)\n",
    "        best_threshold_f1 = median(best_thresholds_roc_auc)\n",
    "        \n",
    "        \n",
    "        \n",
    "        return best_threshold_roc_auc\n",
    "    \n",
    "    def preditions(lmt, X, y, threshold, kfold=10, seed=101):\n",
    "        \n",
    "        accuracy_score_avg, f1_score_avg, roc_auc_score_avg, recall_score_avg, precision_score_avg = np.empty(kfold), np.empty(kfold), \\\n",
    "                                                                                    np.empty(kfold), np.empty(kfold), np.empty(kfold)\n",
    "        LMTMetrics = {'Accuracy': accuracy_score_avg, 'F1 Score': f1_score_avg, 'ROC_AUC_Score': roc_auc_score_avg, \n",
    "                  'Recall': recall_score_avg, 'Precision': precision_score_avg}\n",
    "        \n",
    "        kf = KFold(n_splits=kfold,shuffle=True, random_state=seed)\n",
    "        \n",
    "        cm_holder = []\n",
    "        count = 0             \n",
    "        for train_index, test_index in kf.split(X):\n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            lmt.build_tree(X_train.values, X_train, y_train.values)\n",
    "            pred = lmt.predict(X_test.values, X_test)\n",
    "\n",
    "            pred = [round(i, 2) for i in pred]\n",
    "\n",
    "            #use the threshold that we estabished in the previous run of the algorithm \n",
    "            pred_threshold = [1 if x>threshold else 0 for x in pred]\n",
    "            accuracy_score_avg[count] = accuracy_score(y_test, pred_threshold)\n",
    "            f1_score_avg[count] = f1_score(y_test, pred_threshold)\n",
    "            roc_auc_score_avg[count] = roc_auc_score(y_test, pred_threshold)\n",
    "            recall_score_avg[count] = recall_score(y_test, pred_threshold)\n",
    "            precision_score_avg[count] = precision_score(y_test, pred_threshold)\n",
    "            cm_holder.append(confusion_matrix(y_test, pred_threshold))\n",
    "\n",
    "            count = count + 1\n",
    "\n",
    "\n",
    "        #if for any reason a metric in the folds returns 0.0\n",
    "        #remove it from the list\n",
    "        for key, values in LMTMetrics.items():\n",
    "            LMTMetrics[key] = np.array([value for value in LMTMetrics[key] if value != 0.0])\n",
    "            LMTMetrics[key] = LMTMetrics[key].mean()  \n",
    "\n",
    "        true_pos, true_neg, false_pos, false_neg = [], [], [], []\n",
    "\n",
    "        for cm in cm_holder:\n",
    "            true_pos.append(cm[0][0])\n",
    "            false_pos.append(cm[0][1])\n",
    "            true_neg.append(cm[1][0])\n",
    "            false_neg.append(cm[1][1])\n",
    "\n",
    "        avg_cm = np.matrix([[sum(true_pos), sum(false_pos)], [sum(true_neg), sum(false_neg)]])\n",
    "        \n",
    "        return LMTMetrics, avg_cm\n",
    "    \n",
    "    threshold = GetThreshold(lmt, X, y, kfold)\n",
    "    return preditions(lmt, X, y, threshold, kfold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we know the best threshold to use based off the ROC_auc score, we can use this threshold now with the algorithm again to get the best representation on the performance of our classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.8451556404744845\n",
      "F1 Score:0.7451711473018012\n",
      "ROC_AUC_Score:0.8485998060596304\n",
      "Recall:0.853250685571858\n",
      "Precision:0.6667491854399596\n",
      "[[976 182]\n",
      " [ 63 361]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "LMTMetrics, cm = LogisticModelTree(X, y)\n",
    "\n",
    "Classifiers['LMT'] = LMTMetrics\n",
    "\n",
    "for metric, score in LMTMetrics.items():\n",
    "    print(f'{metric}:{score}')\n",
    "    \n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will be using the cut off point that has the highest roc_auc score depicting the the usefulness of the test. As the data is imballanced the accuracy cannot be taken as a useful metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logitboost \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from logitboost import LogitBoost\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def LogitBoostClassifier(X, y, kfold=10, seed=101):\n",
    "    accuracy_score_avg, f1_score_avg, roc_auc_score_avg, recall_score_avg, precision_score_avg = np.empty(kfold), np.empty(kfold), \\\n",
    "          np.empty(kfold), np.empty(kfold), np.empty(kfold)\n",
    "\n",
    "    LogitboostMetrics = {'Accuracy': accuracy_score_avg, 'F1 Score': f1_score_avg, 'ROC_AUC_Score': roc_auc_score_avg, \n",
    "                         'Recall': recall_score_avg, 'Precision': precision_score_avg}\n",
    "    \n",
    "    lboost = LogitBoost()\n",
    "    count = 0\n",
    "    cm_holder = []\n",
    "    kf = KFold(n_splits=kfold,shuffle=True, random_state=seed)\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]    \n",
    "\n",
    "        lboost.fit(X_train, y_train)\n",
    "        pred = lboost.predict(X_test)\n",
    "        accuracy_score_avg[count] = accuracy_score(y_test, pred)\n",
    "        f1_score_avg[count] = f1_score(y_test, pred)\n",
    "        roc_auc_score_avg[count] = roc_auc_score(y_test, pred)\n",
    "        recall_score_avg[count] = recall_score(y_test, pred)\n",
    "        precision_score_avg[count] = precision_score(y_test, pred)\n",
    "        cm_holder.append(confusion_matrix(y_test, pred))\n",
    "\n",
    "        count = count + 1\n",
    "    #if for any reason a metric in a fold returns 0.0\n",
    "    #remove it from the list\n",
    "    for key, values in LogitboostMetrics.items():\n",
    "        LogitboostMetrics[key] = np.array([value for value in LogitboostMetrics[key] if value != 0.0])\n",
    "        LogitboostMetrics[key] = LogitboostMetrics[key].mean() \n",
    "\n",
    "    \n",
    "\n",
    "    true_pos, true_neg, false_pos, false_neg = [], [], [], []\n",
    "\n",
    "    for cm in cm_holder:\n",
    "        true_pos.append(cm[0][0])\n",
    "        false_pos.append(cm[0][1])\n",
    "        true_neg.append(cm[1][0])\n",
    "        false_neg.append(cm[1][1])\n",
    "\n",
    "    avg_cm = np.matrix([[sum(true_pos), sum(false_pos)], [sum(true_neg), sum(false_neg)]])\n",
    "    \n",
    "    return LogitboostMetrics, avg_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.940577979460234\n",
      "F1 Score:0.8855431282920427\n",
      "ROC_AUC_Score:0.9186963340406237\n",
      "Recall:0.8727478797249756\n",
      "Precision:0.899968512767426\n",
      "[[1117   41]\n",
      " [  53  371]]\n"
     ]
    }
   ],
   "source": [
    "LogitboostMetrics, cm = LogitBoostClassifier(X, y)\n",
    "\n",
    "Classifiers['Logitboost'] = LogitboostMetrics\n",
    "\n",
    "for metric, score in LogitboostMetrics.items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "        \n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent (SGD) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "def SGD(X, y, kfold=10, seed=101):\n",
    "    kf = KFold(n_splits=kfold,shuffle=True, random_state=seed)\n",
    "    \n",
    "    accuracy_score_avg, f1_score_avg, roc_auc_score_avg, recall_score_avg, precision_score_avg = np.empty(kfold), np.empty(kfold), \\\n",
    "                                                                                    np.empty(kfold), np.empty(kfold), np.empty(kfold)\n",
    "    SGDMetrics = {'Accuracy': accuracy_score_avg, 'F1 Score': f1_score_avg, 'ROC_AUC_Score': roc_auc_score_avg, \n",
    "                           'Recall': recall_score_avg, 'Precision': precision_score_avg}\n",
    "    \n",
    "    ## create array to hold all confusion matrices \n",
    "    cm_holder = []\n",
    "    count = 0 \n",
    "    for train_index, test_index in kf.split(X):\n",
    "\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        clf = RandomForestClassifier()\n",
    "        clf.fit(X_train, y_train.ravel())\n",
    "        pred = clf.predict(X_test)\n",
    "        \n",
    "        accuracy_score_avg[count] = accuracy_score(y_test, pred)\n",
    "        f1_score_avg[count] = f1_score(y_test, pred)\n",
    "        roc_auc_score_avg[count] = roc_auc_score(y_test, pred)\n",
    "        recall_score_avg[count] = recall_score(y_test, pred)\n",
    "        precision_score_avg[count] = precision_score(y_test, pred)\n",
    "        cm_holder.append(confusion_matrix(y_test, pred))\n",
    "\n",
    "        count = count + 1\n",
    "        \n",
    "    #if for any reason a metric in the folds returns 0.0\n",
    "    #remove it from the list\n",
    "    for key, values in SGDMetrics.items():\n",
    "        SGDMetrics[key] = np.array([value for value in SGDMetrics[key] if value != 0.0])\n",
    "        SGDMetrics[key] = SGDMetrics[key].mean()  \n",
    "    \n",
    "    \n",
    "    true_pos, true_neg, false_pos, false_neg = [], [], [], []\n",
    "\n",
    "    for cm in cm_holder:\n",
    "        true_pos.append(cm[0][0])\n",
    "        false_pos.append(cm[0][1])\n",
    "        true_neg.append(cm[1][0])\n",
    "        false_neg.append(cm[1][1])\n",
    "    \n",
    "    avg_cm = np.matrix([[sum(true_pos), sum(false_pos)], [sum(true_neg), sum(false_neg)]])\n",
    "    \n",
    "    return SGDMetrics, avg_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.939347981848579\n",
      "F1 Score:0.8829314605925835\n",
      "ROC_AUC_Score:0.9145627026350652\n",
      "Recall:0.8599097904554966\n",
      "Precision:0.9089559798668626\n",
      "[[1122   36]\n",
      " [  60  364]]\n"
     ]
    }
   ],
   "source": [
    "SGDMetrics, cm = SGD(X, y)\n",
    "Classifiers['SGD'] = SGDMetrics\n",
    "\n",
    "for metric, score in SGDMetrics.items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "        \n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "def SVM(X, y, kfold=10, seed=101):\n",
    "    accuracy_score_avg, f1_score_avg, roc_auc_score_avg, recall_score_avg, precision_score_avg  = np.empty(kfold), np.empty(kfold), \\\n",
    "                                                                                    np.empty(kfold), np.empty(kfold), np.empty(kfold)\n",
    "    cm_holder = []\n",
    "    SVCMetrics = {'Accuracy': accuracy_score_avg, 'F1 Score': f1_score_avg, 'ROC_AUC_Score': roc_auc_score_avg, \n",
    "                         'Recall': recall_score_avg, 'Precision': precision_score_avg}\n",
    "    \n",
    "\n",
    "    svc = SVC()\n",
    "    count = 0\n",
    "    kf = KFold(n_splits=kfold,shuffle=True, random_state=seed)\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        svc.fit(X_train, y_train)\n",
    "        pred = svc.predict(X_test)\n",
    "        accuracy_score_avg[count] = accuracy_score(y_test, pred)\n",
    "        f1_score_avg[count] = f1_score(y_test, pred)\n",
    "        roc_auc_score_avg[count] = roc_auc_score(y_test, pred)\n",
    "        recall_score_avg[count] = recall_score(y_test, pred)\n",
    "        precision_score_avg[count] = precision_score(y_test, pred)\n",
    "        cm_holder.append(confusion_matrix(y_test, pred))\n",
    "\n",
    "        count = count + 1\n",
    "\n",
    "    for key, values in SVCMetrics.items():\n",
    "        SVCMetrics[key] = np.array([value for value in SVCMetrics[key] if value != 0.0])\n",
    "        SVCMetrics[key] = SVCMetrics[key].mean()\n",
    "\n",
    "\n",
    "    true_pos, true_neg, false_pos, false_neg = [], [], [], []\n",
    "\n",
    "    for cm in cm_holder:\n",
    "        true_pos.append(cm[0][0])\n",
    "        false_pos.append(cm[0][1])\n",
    "        true_neg.append(cm[1][0])\n",
    "        false_neg.append(cm[1][1])\n",
    "\n",
    "    avg_cm = np.matrix([[sum(true_pos), sum(false_pos)], [sum(true_neg), sum(false_neg)]])\n",
    "    \n",
    "    return SVCMetrics, avg_cm\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.9380702173393839\n",
      "F1 Score:0.8774186844675068\n",
      "ROC_AUC_Score:0.9057581843514801\n",
      "Recall:0.836611401510971\n",
      "Precision:0.9241130302820212\n",
      "[[1129   29]\n",
      " [  69  355]]\n"
     ]
    }
   ],
   "source": [
    "SVCMetrics, cm = SVM(X, y)\n",
    "\n",
    "Classifiers['SVC'] = SVCMetrics\n",
    "\n",
    "for metric, score in SVCMetrics.items():\n",
    "        print(f'{metric}:{score}')\n",
    "        \n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artificial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jackp/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "\n",
    "def ANN(X, y, kfold=10, seed=101):\n",
    "    accuracy_score_avg, f1_score_avg, roc_auc_score_avg, recall_score_avg, precision_score_avg  = np.empty(kfold), np.empty(kfold), \\\n",
    "                                                                                    np.empty(kfold), np.empty(kfold), np.empty(kfold)\n",
    "    cm_holder = []\n",
    "    ANNMetrics = {'Accuracy': accuracy_score_avg, 'F1 Score': f1_score_avg, 'ROC_AUC_Score': roc_auc_score_avg, \n",
    "                         'Recall': recall_score_avg, 'Precision': precision_score_avg}\n",
    "    \n",
    "\n",
    "\n",
    "    def DL_Model(activation= 'linear', neurons= 5, optimizer='Adam'):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(128, activation='relu'))\n",
    "        model.add(Dense(8, activation='relu'))\n",
    "        model.add(Dropout(0.3))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.compile(loss='binary_crossentropy', optimizer= 'adam', metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    ANN = KerasClassifier(build_fn= DL_Model, epochs= 80, batch_size=40, verbose= 0)\n",
    "    kf = KFold(n_splits=kfold,shuffle=True, random_state=seed)\n",
    "    count = 0\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "\n",
    "        ANN.fit(X_train.values, y_train)\n",
    "        pred = ANN.predict(X_test)\n",
    "        accuracy_score_avg[count] = accuracy_score(y_test, pred)\n",
    "        f1_score_avg[count] = f1_score(y_test, pred)\n",
    "        roc_auc_score_avg[count] = roc_auc_score(y_test, pred)\n",
    "        recall_score_avg[count] = recall_score(y_test, pred)\n",
    "        precision_score_avg[count] = precision_score(y_test, pred)\n",
    "        cm_holder.append(confusion_matrix(y_test, pred))\n",
    "\n",
    "        count = count + 1\n",
    "\n",
    "    for key, values in ANNMetrics.items():\n",
    "        ANNMetrics[key] = np.array([value for value in ANNMetrics[key] if value != 0.0])\n",
    "        ANNMetrics[key] = ANNMetrics[key].mean()\n",
    "\n",
    "    \n",
    "\n",
    "    true_pos, true_neg, false_pos, false_neg = [], [], [], []\n",
    "\n",
    "    for cm in cm_holder:\n",
    "        true_pos.append(cm[0][0])\n",
    "        false_pos.append(cm[0][1])\n",
    "        true_neg.append(cm[1][0])\n",
    "        false_neg.append(cm[1][1])\n",
    "\n",
    "    avg_cm = np.matrix([[sum(true_pos), sum(false_pos)], [sum(true_neg), sum(false_neg)]])\n",
    "    \n",
    "    return ANNMetrics, avg_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.949430777804315\n",
      "F1 Score:0.9055527122640544\n",
      "ROC_AUC_Score:0.936445679329883\n",
      "Recall:0.9080321750907425\n",
      "Precision:0.9062586396605574\n"
     ]
    }
   ],
   "source": [
    "ANNMetrics, cm = ANN(X, y)\n",
    "\n",
    "Classifiers['ANN'] = ANNMetrics\n",
    "\n",
    "for metric, score in ANNMetrics.items():\n",
    "        print(f'{metric}:{score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "def deepLearn(X, y, kfold=10, seed=101):\n",
    "    accuracy_score_avg, f1_score_avg, roc_auc_score_avg, recall_score_avg, precision_score_avg  = np.empty(kfold), np.empty(kfold), \\\n",
    "                                                                                    np.empty(kfold), np.empty(kfold), np.empty(kfold)\n",
    "    cm_holder = []\n",
    "    DeepLearnMetrics = {'Accuracy': accuracy_score_avg, 'F1 Score': f1_score_avg, 'ROC_AUC_Score': roc_auc_score_avg, \n",
    "                         'Recall': recall_score_avg, 'Precision': precision_score_avg}\n",
    "\n",
    "\n",
    "\n",
    "    def DL_Model():\n",
    "        n_cols = X_train.shape[1]\n",
    "        model = Sequential()\n",
    "        model.add(Dense(250, activation='relu', input_shape=(n_cols,)))\n",
    "        model.add(Dense(250, activation='relu'))\n",
    "        model.add(Dense(250, activation='relu'))\n",
    "        model.add(Dense(2, activation='softmax'))\n",
    "        model.compile(loss='categorical_crossentropy', optimizer= 'adam', metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    deepLearn = KerasClassifier(build_fn= DL_Model, epochs= 80, batch_size=40, verbose= 0)\n",
    "    cm_holder = []\n",
    "    count = 0\n",
    "    kf = KFold(n_splits=kfold,shuffle=True, random_state=seed)\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        train_y_2 = to_categorical(y_train)\n",
    "        deepLearn.fit(X_train, train_y_2)\n",
    "        pred = deepLearn.predict(X_test)\n",
    "        accuracy_score_avg[count] = accuracy_score(y_test, pred)\n",
    "        f1_score_avg[count] = f1_score(y_test, pred)\n",
    "        roc_auc_score_avg[count] = roc_auc_score(y_test, pred)\n",
    "        recall_score_avg[count] = recall_score(y_test, pred)\n",
    "        precision_score_avg[count] = precision_score(y_test, pred)\n",
    "        cm_holder.append(confusion_matrix(y_test, pred))\n",
    "\n",
    "        count = count + 1\n",
    "\n",
    "    for key, values in DeepLearnMetrics.items():\n",
    "        DeepLearnMetrics[key] = np.array([value for value in DeepLearnMetrics[key] if value != 0.0])\n",
    "        DeepLearnMetrics[key] = DeepLearnMetrics[key].mean()\n",
    "\n",
    "    \n",
    "\n",
    "    true_pos, true_neg, false_pos, false_neg = [], [], [], []\n",
    "\n",
    "    for cm in cm_holder:\n",
    "        true_pos.append(cm[0][0])\n",
    "        false_pos.append(cm[0][1])\n",
    "        true_neg.append(cm[1][0])\n",
    "        false_neg.append(cm[1][1])\n",
    "\n",
    "    avg_cm = np.matrix([[sum(true_pos), sum(false_pos)], [sum(true_neg), sum(false_neg)]])\n",
    "    \n",
    "    return DeepLearnMetrics, avg_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.9557559111535706\n",
      "F1 Score:0.9203101934134665\n",
      "ROC_AUC_Score:0.9479616410257113\n",
      "Recall:0.9317796877406941\n",
      "Precision:0.9119404186025253\n",
      "[[1117   41]\n",
      " [  29  395]]\n"
     ]
    }
   ],
   "source": [
    "DeepLearnMetrics, cm = deepLearn(X, y)\n",
    "\n",
    "Classifiers['DeepLearnMetrics'] = DeepLearnMetrics\n",
    "\n",
    "for metric, score in DeepLearnMetrics.items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "        \n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****DeepLearnMetrics****\n",
      "Accuracy: 0.9557559111535706\n",
      "F1 Score: 0.9203101934134665\n",
      "ROC_AUC_Score: 0.9479616410257113\n",
      "Recall: 0.9317796877406941\n",
      "Precision: 0.9119404186025253\n",
      "\n",
      "****ANN****\n",
      "Accuracy: 0.949430777804315\n",
      "F1 Score: 0.9055527122640544\n",
      "ROC_AUC_Score: 0.936445679329883\n",
      "Recall: 0.9080321750907425\n",
      "Precision: 0.9062586396605574\n",
      "\n",
      "****Logitboost****\n",
      "Accuracy: 0.940577979460234\n",
      "F1 Score: 0.8855431282920427\n",
      "ROC_AUC_Score: 0.9186963340406237\n",
      "Recall: 0.8727478797249756\n",
      "Precision: 0.899968512767426\n",
      "\n",
      "****SGD****\n",
      "Accuracy: 0.939347981848579\n",
      "F1 Score: 0.8829314605925835\n",
      "ROC_AUC_Score: 0.9145627026350652\n",
      "Recall: 0.8599097904554966\n",
      "Precision: 0.9089559798668626\n",
      "\n",
      "****Random Forest****\n",
      "Accuracy: 0.939355942998169\n",
      "F1 Score: 0.8827410678385549\n",
      "ROC_AUC_Score: 0.9134641476313574\n",
      "Recall: 0.8580343198169598\n",
      "Precision: 0.9100298275980669\n",
      "\n",
      "****SVC****\n",
      "Accuracy: 0.9380702173393839\n",
      "F1 Score: 0.8774186844675068\n",
      "ROC_AUC_Score: 0.9057581843514801\n",
      "Recall: 0.836611401510971\n",
      "Precision: 0.9241130302820212\n",
      "\n",
      "****LMT****\n",
      "Accuracy: 0.8451556404744845\n",
      "F1 Score: 0.7451711473018012\n",
      "ROC_AUC_Score: 0.8485998060596304\n",
      "Recall: 0.853250685571858\n",
      "Precision: 0.6667491854399596\n"
     ]
    }
   ],
   "source": [
    "sortedClassifiers = sorted(Classifiers.items(), key = lambda x: x[1]['F1 Score'], reverse=True) \n",
    "\n",
    "for classifier in sortedClassifiers:\n",
    "    print(f'\\n****{classifier[0]}****')\n",
    "    for metric, result in classifier[1].items():\n",
    "        print(f'{metric}: {result}')\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/media/jackp/JACK PYE/FinalYearProject/Machine Learning/Results/Scikit learn/pandas/_libs/parsers.pyx\u001b[0m(673)\u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\n",
      "ipdb> n\n",
      "Old number of features: 1153\n",
      "             New number of features: 594\n",
      "             Number of features removed 559\n",
      "Old number of features: 1153\n",
      "             New number of features: 493\n",
      "             Number of features removed 660\n",
      "Old number of features: 1153\n",
      "             New number of features: 375\n",
      "             Number of features removed 778\n",
      "Old number of features: 1153\n",
      "             New number of features: 256\n",
      "             Number of features removed 897\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "def getVarianceFeatures(X, y, var):\n",
    "    variancefs = VarianceThreshold(threshold=var).fit(X)\n",
    "    cols = variancefs.get_support(indices=True)\n",
    "    new_X = X.iloc[:,cols]\n",
    "    lostFeatures = X.shape[1] - new_X.shape[1]\n",
    "    \n",
    "    print(f'Old number of features: {X.shape[1]}\\n \\\n",
    "            New number of features: {new_X.shape[1]}\\n \\\n",
    "            Number of features removed {lostFeatures}')\n",
    "    \n",
    "    return new_X\n",
    "\n",
    "bestVarFeatures = []\n",
    "variance = [0.05, 0.1, 0.15, 0.2]\n",
    "for i in variance:\n",
    "    bestVarFeatures.append(getVarianceFeatures(X, y, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Var Results**\n",
      "\n",
      "\n",
      " Variance Threshold: 0.05\n",
      "*RandomForest Results**\n",
      "Accuracy:0.9437624392962343\n",
      "F1 Score:0.8917679908810083\n",
      "ROC_AUC_Score:0.9191823787363635\n",
      "Recall:0.8660733046416589\n",
      "Precision:0.9200264804712093\n",
      "**\n",
      "LMT Results**\n",
      "Accuracy:0.9191027784412069\n",
      "F1 Score:0.8532117067235774\n",
      "ROC_AUC_Score:0.90916245369082\n",
      "Recall:0.8873358374562514\n",
      "Precision:0.822929824778706\n",
      "**\n",
      "LogitBoost Results**\n",
      "Accuracy:0.9374134224982088\n",
      "F1 Score:0.8798681449529727\n",
      "ROC_AUC_Score:0.9116686059981272\n",
      "Recall:0.8562196707098326\n",
      "Precision:0.9062514514752854\n",
      "**\n",
      "SGD Results**\n",
      "Accuracy:0.9437504975718494\n",
      "F1 Score:0.8918517789340061\n",
      "ROC_AUC_Score:0.9202390747775588\n",
      "Recall:0.8690800249828738\n",
      "Precision:0.9182200123711752\n",
      "**\n",
      "SVM Results**\n",
      "Accuracy:0.940597882334209\n",
      "F1 Score:0.8834261724125161\n",
      "ROC_AUC_Score:0.9120190972518504\n",
      "Recall:0.8497678385698471\n",
      "Precision:0.921899612587391\n",
      "**\n",
      "ANN Results**\n",
      "Accuracy:0.9595573600827961\n",
      "F1 Score:0.9234409552990359\n",
      "ROC_AUC_Score:0.9482830599744778\n",
      "Recall:0.9241423149508823\n",
      "Precision:0.9236154910937217\n",
      "**\n",
      "DeepLearn Results**\n",
      "Accuracy:0.9557678528779556\n",
      "F1 Score:0.9174501783546505\n",
      "ROC_AUC_Score:0.9473749832586952\n",
      "Recall:0.9281207421566615\n",
      "Precision:0.9103280259382496\n",
      "\n",
      " Variance Threshold: 0.1\n",
      "*RandomForest Results**\n",
      "Accuracy:0.9406018629090042\n",
      "F1 Score:0.8818590822730134\n",
      "ROC_AUC_Score:0.9116699150223997\n",
      "Recall:0.8498538243542344\n",
      "Precision:0.9186608433061434\n",
      "**\n",
      "LMT Results**\n",
      "Accuracy:0.9190948172916169\n",
      "F1 Score:0.852959797434319\n",
      "ROC_AUC_Score:0.9060659216998795\n",
      "Recall:0.8781275947185969\n",
      "Precision:0.830344646851103\n",
      "**\n",
      "LogitBoost Results**\n",
      "Accuracy:0.9273067430937028\n",
      "F1 Score:0.8604746398062547\n",
      "ROC_AUC_Score:0.9004161802773828\n",
      "Recall:0.8421093414339982\n",
      "Precision:0.881231813773813\n",
      "**\n",
      "SGD Results**\n",
      "Accuracy:0.9355505134941484\n",
      "F1 Score:0.8738003044341831\n",
      "ROC_AUC_Score:0.9074096049185586\n",
      "Recall:0.8475904677920972\n",
      "Precision:0.9040216997821056\n",
      "**\n",
      "SVM Results**\n",
      "Accuracy:0.9361794443117585\n",
      "F1 Score:0.8747775286937911\n",
      "ROC_AUC_Score:0.9073724988241876\n",
      "Recall:0.8457325039857322\n",
      "Precision:0.9069734160391432\n",
      "**\n",
      "ANN Results**\n",
      "Accuracy:0.9576586259055807\n",
      "F1 Score:0.9189009202664762\n",
      "ROC_AUC_Score:0.9468006756753443\n",
      "Recall:0.9236263674837153\n",
      "Precision:0.915330466458286\n",
      "**\n",
      "DeepLearn Results**\n",
      "Accuracy:0.9538770798503304\n",
      "F1 Score:0.9129002312687897\n",
      "ROC_AUC_Score:0.9391617840775792\n",
      "Recall:0.9077026131960544\n",
      "Precision:0.9193365626659892\n",
      "\n",
      " Variance Threshold: 0.15\n",
      "*RandomForest Results**\n",
      "Accuracy:0.9330029456253485\n",
      "F1 Score:0.8679009107198599\n",
      "ROC_AUC_Score:0.9023132390782094\n",
      "Recall:0.8363828307205535\n",
      "Precision:0.9044285807898955\n",
      "**\n",
      "LMT Results**\n",
      "Accuracy:0.9033038770798504\n",
      "F1 Score:0.8279554768148957\n",
      "ROC_AUC_Score:0.894677317048785\n",
      "Recall:0.8767703700105318\n",
      "Precision:0.7852711386103555\n",
      "**\n",
      "LogitBoost Results**\n",
      "Accuracy:0.9121487142743412\n",
      "F1 Score:0.8318091253908186\n",
      "ROC_AUC_Score:0.8828055206635168\n",
      "Recall:0.820912208905394\n",
      "Precision:0.8431825079464439\n",
      "**\n",
      "SGD Results**\n",
      "Accuracy:0.9368004139797786\n",
      "F1 Score:0.8757614996111649\n",
      "ROC_AUC_Score:0.9086851564111695\n",
      "Recall:0.8482679798851146\n",
      "Precision:0.9064200913425235\n",
      "**\n",
      "SVM Results**\n",
      "Accuracy:0.9247950003980574\n",
      "F1 Score:0.8521503323053372\n",
      "ROC_AUC_Score:0.8910641372529767\n",
      "Recall:0.8193205129570164\n",
      "Precision:0.8893012723083824\n",
      "**\n",
      "ANN Results**\n",
      "Accuracy:0.9443993312634344\n",
      "F1 Score:0.8950084631494404\n",
      "ROC_AUC_Score:0.9289362790729655\n",
      "Recall:0.8969469054891273\n",
      "Precision:0.8941578730388992\n",
      "**\n",
      "DeepLearn Results**\n",
      "Accuracy:0.9488137887110899\n",
      "F1 Score:0.9028814896999432\n",
      "ROC_AUC_Score:0.9327096222578442\n",
      "Recall:0.8993659295544928\n",
      "Precision:0.9084635692167973\n",
      "\n",
      " Variance Threshold: 0.2\n",
      "*RandomForest Results**\n",
      "Accuracy:0.9374412865217737\n",
      "F1 Score:0.8762983576391928\n",
      "ROC_AUC_Score:0.90957837502865\n",
      "Recall:0.8500414793241193\n",
      "Precision:0.9065683254496859\n",
      "**\n",
      "LMT Results**\n",
      "Accuracy:0.8830865376960434\n",
      "F1 Score:0.8053045721033575\n",
      "ROC_AUC_Score:0.8938427579946918\n",
      "Recall:0.9170615284319424\n",
      "Precision:0.7199135787682647\n",
      "**\n",
      "LogitBoost Results**\n",
      "Accuracy:0.9096170687047209\n",
      "F1 Score:0.8208564095185752\n",
      "ROC_AUC_Score:0.8716166571787973\n",
      "Recall:0.7912980034244638\n",
      "Precision:0.8550620766882279\n",
      "**\n",
      "SGD Results**\n",
      "Accuracy:0.9374333253721838\n",
      "F1 Score:0.8775173141118369\n",
      "ROC_AUC_Score:0.9102803960203854\n",
      "Recall:0.8523890617137184\n",
      "Precision:0.9057355300296676\n",
      "**\n",
      "SVM Results**\n",
      "Accuracy:0.9152973489371865\n",
      "F1 Score:0.8357778145548671\n",
      "ROC_AUC_Score:0.8841375484681626\n",
      "Recall:0.8164084250449285\n",
      "Precision:0.8592151258747004\n",
      "**\n",
      "ANN Results**\n",
      "Accuracy:0.9374293447973887\n",
      "F1 Score:0.8793806263848133\n",
      "ROC_AUC_Score:0.9156962841754673\n",
      "Recall:0.8704386764939646\n",
      "Precision:0.8915561092078175\n",
      "**\n",
      "DeepLearn Results**\n",
      "Accuracy:0.940585940609824\n",
      "F1 Score:0.888423211688175\n",
      "ROC_AUC_Score:0.9236677963044709\n",
      "Recall:0.8892595333374693\n",
      "Precision:0.8900915156601904\n"
     ]
    }
   ],
   "source": [
    "RandomForestVar, LogisticModelVar, LogitBoostVar, SGDVar, SVMVar, ANNVar, DeepLearnVar = [], [], [], [], [], [], []\n",
    "\n",
    "\n",
    "for X in bestVarFeatures:\n",
    "    RandomForestVar.append(RandomForest(X, y))\n",
    "    LogisticModelVar.append(LogisticModelTree(X, y))\n",
    "    LogitBoostVar.append(LogitBoostClassifier(X, y))\n",
    "    SGDVar.append(SGD(X, y))\n",
    "    SVMVar.append(SVM(X, y))\n",
    "    ANNVar.append(ANN(X, y))\n",
    "    DeepLearnVar.append(deepLearn(X, y))\n",
    "\n",
    "    \n",
    "RandomForestVar.append(RandomForest(X, y))\n",
    "LogisticModelVar.append(LogisticModelTree(X, y))\n",
    "LogitBoostVar.append(LogitBoostClassifier(X, y))\n",
    "SGDVar.append(SGD(X, y))\n",
    "SVMVar.append(SVM(X, y))\n",
    "ANNVar.append(ANN(X, y))\n",
    "DeepLearnVar.append(deepLearn(X, y))  \n",
    "\n",
    "print('**Var Results**\\n')\n",
    "for i, k in enumerate(variance):\n",
    "   \n",
    "    print(f'\\n Variance Threshold: {k}')\n",
    "   \n",
    "    \n",
    "    print('*RandomForest Results**')\n",
    "    for metric, score in RandomForestVar[i][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "    \n",
    "    print('**\\nLMT Results**')\n",
    "    for metric, score in LogisticModelVar[i][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "    \n",
    "    print('**\\nLogitBoost Results**')\n",
    "    for metric, score in LogitBoostVar[i][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "    \n",
    "    print('**\\nSGD Results**')\n",
    "    for metric, score in SGDVar[i][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "    \n",
    "    print('**\\nSVM Results**')\n",
    "    for metric, score in SVMVar[i][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "    \n",
    "    print('**\\nANN Results**')\n",
    "    for metric, score in ANNVar[i][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "    \n",
    "    print('**\\nDeepLearn Results**')\n",
    "    for metric, score in DeepLearnVar[i][0].items():\n",
    "        print(f'{metric}:{score.mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi2  Info Gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2, mutual_info_classif\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# fschi2 = SelectKBest(chi2, k='all')\n",
    "# fschi2.fit(X, y)\n",
    "# fschi2.transform(X)\n",
    "# fs_info_gain = SelectKBest(mutual_info_classif, k='all')\n",
    "# fs_info_gain.fit(X, y)\n",
    "# fs_info_gain.transform(X)\n",
    "# bestfeatschi2 = []\n",
    "# bestfeats_info_gain = []\n",
    "# bestFeatsThresholdChi2 = [50, 75, 100, 150]\n",
    "# for treshold in bestFeatsThreshold:\n",
    "#     bestfeatschi2.append([i for i in fschi2.scores_ if i > treshold])\n",
    "#     bestfeats_info_gain.append([i for i in fs_info_gain.scores_ if i > treshold])\n",
    "    \n",
    "# for index,value in enumerate(bestfeatschi2):\n",
    "#     pyplot.bar([i for i in range(len(bestfeatschi2[index]))], bestfeatschi2[index])\n",
    "#     pyplot.show()\n",
    "#     pyplot.bar([i for i in range(len(bestfeats_info_gain[index]))], bestfeats_info_gain[index])\n",
    "#     pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestK = [25, 40, 50, 70, 100, 150, 200]\n",
    "bestChiFeatures = []\n",
    "bestInfoGainFeatures = []\n",
    "def getChi2Features(X, y, k):\n",
    "    chi2fs = SelectKBest(score_func=chi2, k=k).fit(X, y)\n",
    "    cols = chi2fs.get_support(indices=True)\n",
    "    new_X = X.iloc[:,cols]\n",
    "    return new_X\n",
    "\n",
    "def getInfoGainFeatures(X, y, k):\n",
    "    InfoGainfs = SelectKBest(score_func=mutual_info_classif, k=k).fit(X, y)\n",
    "    cols = InfoGainfs.get_support(indices=True)\n",
    "    new_X = X.iloc[:,cols]\n",
    "    return new_X\n",
    "\n",
    "for i in bestK:\n",
    "    bestChiFeatures.append(getChi2Features(X,y,i))\n",
    "    bestInfoGainFeatures.append(getInfoGainFeatures(X, y, i))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Chi2 Results**\n",
      "\n",
      "\n",
      "K number of Features: 25\n",
      "*RandomForest Results**\n",
      "Accuracy:0.8779794602340578\n",
      "F1 Score:0.7640900349327578\n",
      "ROC_AUC_Score:0.8376397557467298\n",
      "Recall:0.7489823465630496\n",
      "Precision:0.784873563129377\n",
      "**\n",
      "LMT Results**\n",
      "Accuracy:0.8539885359445905\n",
      "F1 Score:0.7535070897785633\n",
      "ROC_AUC_Score:0.8502438841627276\n",
      "Recall:0.8426844740966487\n",
      "Precision:0.6831257702700552\n",
      "**\n",
      "LogitBoost Results**\n",
      "Accuracy:0.8754716981132076\n",
      "F1 Score:0.7586015340370416\n",
      "ROC_AUC_Score:0.8339846208456401\n",
      "Recall:0.7431519168301809\n",
      "Precision:0.7823711200639578\n",
      "**\n",
      "SGD Results**\n",
      "Accuracy:0.8773425682668577\n",
      "F1 Score:0.7627245442074144\n",
      "ROC_AUC_Score:0.8367673489965359\n",
      "Recall:0.7482255438419612\n",
      "Precision:0.7825271181504017\n",
      "**\n",
      "SVM Results**\n",
      "Accuracy:0.8754677175384126\n",
      "F1 Score:0.7577962354029597\n",
      "ROC_AUC_Score:0.8320032844191955\n",
      "Recall:0.7368039442452745\n",
      "Precision:0.7858914921414921\n",
      "**\n",
      "ANN Results**\n",
      "Accuracy:0.8773505294164478\n",
      "F1 Score:0.7634966113049078\n",
      "ROC_AUC_Score:0.8383716433949475\n",
      "Recall:0.7530836024500196\n",
      "Precision:0.7811648337982128\n",
      "**\n",
      "DeepLearn Results**\n",
      "Accuracy:0.880507125228883\n",
      "F1 Score:0.7695440845463413\n",
      "ROC_AUC_Score:0.8418300515690145\n",
      "Recall:0.7564869253176284\n",
      "Precision:0.7885040892967722\n",
      "\n",
      "K number of Features: 40\n",
      "*RandomForest Results**\n",
      "Accuracy:0.8957169015205796\n",
      "F1 Score:0.8007697760764488\n",
      "ROC_AUC_Score:0.8636914279255266\n",
      "Recall:0.7951394839020376\n",
      "Precision:0.809475391571232\n",
      "**\n",
      "LMT Results**\n",
      "Accuracy:0.8539845553697953\n",
      "F1 Score:0.751100712297996\n",
      "ROC_AUC_Score:0.8459777241388977\n",
      "Recall:0.8280000513765117\n",
      "Precision:0.690526503297752\n",
      "**\n",
      "LogitBoost Results**\n",
      "Accuracy:0.8761085900804076\n",
      "F1 Score:0.7612174973345441\n",
      "ROC_AUC_Score:0.8361183001929586\n",
      "Recall:0.7476368228512623\n",
      "Precision:0.7814317335112351\n",
      "**\n",
      "SGD Results**\n",
      "Accuracy:0.8931852559509593\n",
      "F1 Score:0.7957495790686152\n",
      "ROC_AUC_Score:0.8604531659073607\n",
      "Recall:0.7894297769423309\n",
      "Precision:0.8065126828456582\n",
      "**\n",
      "SVM Results**\n",
      "Accuracy:0.8830666348220684\n",
      "F1 Score:0.7699501600216055\n",
      "ROC_AUC_Score:0.839004498732803\n",
      "Recall:0.7438551874783685\n",
      "Precision:0.8021031084506676\n",
      "**\n",
      "ANN Results**\n",
      "Accuracy:0.8868322585781387\n",
      "F1 Score:0.7845561772389527\n",
      "ROC_AUC_Score:0.8537019578855286\n",
      "Recall:0.7812372305224324\n",
      "Precision:0.7941436943113719\n",
      "**\n",
      "DeepLearn Results**\n",
      "Accuracy:0.8944351564365893\n",
      "F1 Score:0.7999773159832846\n",
      "ROC_AUC_Score:0.865608937636163\n",
      "Recall:0.8023188524940934\n",
      "Precision:0.802034798202456\n",
      "\n",
      "K number of Features: 50\n",
      "*RandomForest Results**\n",
      "Accuracy:0.8969628214314145\n",
      "F1 Score:0.8022547624600916\n",
      "ROC_AUC_Score:0.8646566282579764\n",
      "Recall:0.7945982009552925\n",
      "Precision:0.8145342305681977\n",
      "**\n",
      "LMT Results**\n",
      "Accuracy:0.8691664676379268\n",
      "F1 Score:0.761008127407159\n",
      "ROC_AUC_Score:0.842382900689208\n",
      "Recall:0.7834876383608192\n",
      "Precision:0.7439531700698712\n",
      "**\n",
      "LogitBoost Results**\n",
      "Accuracy:0.8811679006448532\n",
      "F1 Score:0.7748344565901955\n",
      "ROC_AUC_Score:0.8465664986181611\n",
      "Recall:0.7704640159833335\n",
      "Precision:0.7819537845140074\n",
      "**\n",
      "SGD Results**\n",
      "Accuracy:0.8988575750338349\n",
      "F1 Score:0.803349842954163\n",
      "ROC_AUC_Score:0.8644945501680505\n",
      "Recall:0.7907201394117258\n",
      "Precision:0.8214217079376803\n",
      "**\n",
      "SVM Results**\n",
      "Accuracy:0.8862152694849137\n",
      "F1 Score:0.7730943789333142\n",
      "ROC_AUC_Score:0.8396993053770458\n",
      "Recall:0.7392246046465661\n",
      "Precision:0.8145684497747396\n",
      "**\n",
      "ANN Results**\n",
      "Accuracy:0.8956969986466043\n",
      "F1 Score:0.8001413551389776\n",
      "ROC_AUC_Score:0.8642764024516705\n",
      "Recall:0.7962245403022201\n",
      "Precision:0.8071570593149542\n",
      "**\n",
      "DeepLearn Results**\n",
      "Accuracy:0.8969588408566196\n",
      "F1 Score:0.8039605595391002\n",
      "ROC_AUC_Score:0.8684922682997863\n",
      "Recall:0.8073665080905293\n",
      "Precision:0.8034277214611715\n",
      "\n",
      "K number of Features: 70\n",
      "*RandomForest Results**\n",
      "Accuracy:0.89950640872542\n",
      "F1 Score:0.8082186010473593\n",
      "ROC_AUC_Score:0.868988655689841\n",
      "Recall:0.8022535812892443\n",
      "Precision:0.8192737297148076\n",
      "**\n",
      "LMT Results**\n",
      "Accuracy:0.8558832895470105\n",
      "F1 Score:0.7495493284933541\n",
      "ROC_AUC_Score:0.8429550193304752\n",
      "Recall:0.8150463772409868\n",
      "Precision:0.6963951320191861\n",
      "**\n",
      "LogitBoost Results**\n",
      "Accuracy:0.8767494626224026\n",
      "F1 Score:0.7590525737854465\n",
      "ROC_AUC_Score:0.8317105425276479\n",
      "Recall:0.7347616271478744\n",
      "Precision:0.7874627171322397\n",
      "**\n",
      "SGD Results**\n",
      "Accuracy:0.9026630045378552\n",
      "F1 Score:0.8130226580501162\n",
      "ROC_AUC_Score:0.8722167068571626\n",
      "Recall:0.8068693226907001\n",
      "Precision:0.8225771047165222\n",
      "**\n",
      "SVM Results**\n",
      "Accuracy:0.8849613884244885\n",
      "F1 Score:0.7690251080934052\n",
      "ROC_AUC_Score:0.83460778790835\n",
      "Recall:0.7247562300547031\n",
      "Precision:0.8244069629261148\n",
      "**\n",
      "ANN Results**\n",
      "Accuracy:0.8995024281506249\n",
      "F1 Score:0.8096300314179814\n",
      "ROC_AUC_Score:0.8701764358393496\n",
      "Recall:0.8055503791999488\n",
      "Precision:0.8190480424507497\n",
      "**\n",
      "DeepLearn Results**\n",
      "Accuracy:0.898873497333015\n",
      "F1 Score:0.8091167402124227\n",
      "ROC_AUC_Score:0.8722619735596784\n",
      "Recall:0.8129448441494966\n",
      "Precision:0.8124563226680384\n",
      "\n",
      "K number of Features: 100\n",
      "*RandomForest Results**\n",
      "Accuracy:0.9045577581402755\n",
      "F1 Score:0.8178782540867152\n",
      "ROC_AUC_Score:0.873897128697433\n",
      "Recall:0.8070841673698304\n",
      "Precision:0.8315341848856488\n",
      "**\n",
      "LMT Results**\n",
      "Accuracy:0.8514409680757901\n",
      "F1 Score:0.7522588380154163\n",
      "ROC_AUC_Score:0.8523786575147708\n",
      "Recall:0.8538627705900712\n",
      "Precision:0.6748108510479065\n",
      "**\n",
      "LogitBoost Results**\n",
      "Accuracy:0.8818008120372582\n",
      "F1 Score:0.7667795910158517\n",
      "ROC_AUC_Score:0.8358670644954536\n",
      "Recall:0.7370324762175039\n",
      "Precision:0.8020835655735017\n",
      "**\n",
      "SGD Results**\n",
      "Accuracy:0.9077183345275058\n",
      "F1 Score:0.8220849765076244\n",
      "ROC_AUC_Score:0.8770478005707133\n",
      "Recall:0.8107489306485002\n",
      "Precision:0.8368422748187585\n",
      "**\n",
      "SVM Results**\n",
      "Accuracy:0.8906496298065439\n",
      "F1 Score:0.7783901911604416\n",
      "ROC_AUC_Score:0.8390225695719018\n",
      "Recall:0.7268795585776524\n",
      "Precision:0.8421071187086184\n",
      "**\n",
      "ANN Results**\n",
      "Accuracy:0.9052225141310405\n",
      "F1 Score:0.824294648185101\n",
      "ROC_AUC_Score:0.8852015308509612\n",
      "Recall:0.8398423578880638\n",
      "Precision:0.8131371406371406\n",
      "**\n",
      "DeepLearn Results**\n",
      "Accuracy:0.9083552264947057\n",
      "F1 Score:0.8296309741543043\n",
      "ROC_AUC_Score:0.8889949883751317\n",
      "Recall:0.8456412160634338\n",
      "Precision:0.819560902808505\n",
      "\n",
      "K number of Features: 150\n",
      "*RandomForest Results**\n",
      "Accuracy:0.9222752965528223\n",
      "F1 Score:0.8472601693484393\n",
      "ROC_AUC_Score:0.8901137225561137\n",
      "Recall:0.8204713021145691\n",
      "Precision:0.879714147923025\n",
      "**\n",
      "LMT Results**\n",
      "Accuracy:0.8495860202213199\n",
      "F1 Score:0.7577702298847943\n",
      "ROC_AUC_Score:0.8624454547901206\n",
      "Recall:0.8895061566328731\n",
      "Precision:0.6629857560567561\n",
      "**\n",
      "LogitBoost Results**\n",
      "Accuracy:0.8855743969429186\n",
      "F1 Score:0.7693482292775283\n",
      "ROC_AUC_Score:0.8360873591032834\n",
      "Recall:0.7316465319711374\n",
      "Precision:0.8144515540950069\n",
      "**\n",
      "SGD Results**\n",
      "Accuracy:0.9216463657352122\n",
      "F1 Score:0.8459640117240991\n",
      "ROC_AUC_Score:0.889756809563832\n",
      "Recall:0.820509537688519\n",
      "Precision:0.8763950016283033\n",
      "**\n",
      "SVM Results**\n",
      "Accuracy:0.891278560624154\n",
      "F1 Score:0.7799980134611272\n",
      "ROC_AUC_Score:0.839838676762179\n",
      "Recall:0.7286848960972757\n",
      "Precision:0.8415636674399793\n",
      "**\n",
      "ANN Results**\n",
      "Accuracy:0.9254159700660776\n",
      "F1 Score:0.8586271643874979\n",
      "ROC_AUC_Score:0.9021847001023435\n",
      "Recall:0.8529144045474236\n",
      "Precision:0.8671565031087607\n",
      "**\n",
      "DeepLearn Results**\n",
      "Accuracy:0.9216025794124671\n",
      "F1 Score:0.8498796194331056\n",
      "ROC_AUC_Score:0.896618967854177\n",
      "Recall:0.8411920795949286\n",
      "Precision:0.8617431910940179\n",
      "\n",
      "K number of Features: 200\n",
      "*RandomForest Results**\n",
      "Accuracy:0.9222673354032322\n",
      "F1 Score:0.8460007383139457\n",
      "ROC_AUC_Score:0.8878409239197053\n",
      "Recall:0.8143372224380115\n",
      "Precision:0.8819813977294796\n",
      "**\n",
      "LMT Results**\n",
      "Accuracy:0.8729599554175623\n",
      "F1 Score:0.7873431322365895\n",
      "ROC_AUC_Score:0.8784500877768242\n",
      "Recall:0.8896558040749986\n",
      "Precision:0.7094753092239482\n",
      "**\n",
      "LogitBoost Results**\n",
      "Accuracy:0.8956930180718095\n",
      "F1 Score:0.7933222386205999\n",
      "ROC_AUC_Score:0.85207649353956\n",
      "Recall:0.7594674711945157\n",
      "Precision:0.8319260947081254\n",
      "**\n",
      "SGD Results**\n",
      "Accuracy:0.9247989809728525\n",
      "F1 Score:0.8515724154865033\n",
      "ROC_AUC_Score:0.8907598085802523\n",
      "Recall:0.8176460564611313\n",
      "Precision:0.8903205061731709\n",
      "**\n",
      "SVM Results**\n",
      "Accuracy:0.8950601066794045\n",
      "F1 Score:0.7899999439126005\n",
      "ROC_AUC_Score:0.8485388988394542\n",
      "Recall:0.7478001960634161\n",
      "Precision:0.8401565127867443\n",
      "**\n",
      "ANN Results**\n",
      "Accuracy:0.9203526789268371\n",
      "F1 Score:0.8483371786529549\n",
      "ROC_AUC_Score:0.897456142903971\n",
      "Recall:0.8481212357021949\n",
      "Precision:0.8501693853296188\n",
      "**\n",
      "DeepLearn Results**\n",
      "Accuracy:0.9298344080885279\n",
      "F1 Score:0.8639190752068899\n",
      "ROC_AUC_Score:0.9010639900228107\n",
      "Recall:0.8402469323052435\n",
      "Precision:0.8902436790238273\n"
     ]
    }
   ],
   "source": [
    "RandomForestChi, LogisticModelChi, LogitBoostChi, SGDChi, SVMChi, ANNChi, DeepLearnChi = [], [], [], [], [], [], []\n",
    "\n",
    "\n",
    "for X in bestChiFeatures:\n",
    "    RandomForestChi.append(RandomForest(X, y))\n",
    "    LogisticModelChi.append(LogisticModelTree(X, y))\n",
    "    LogitBoostChi.append(LogitBoostClassifier(X, y))\n",
    "    SGDChi.append(SGD(X, y))\n",
    "    SVMChi.append(SVM(X, y))\n",
    "    ANNChi.append(ANN(X, y))\n",
    "    DeepLearnChi.append(deepLearn(X, y))\n",
    "\n",
    "    \n",
    "RandomForestChi.append(RandomForest(X, y))\n",
    "LogisticModelChi.append(LogisticModelTree(X, y))\n",
    "LogitBoostChi.append(LogitBoostClassifier(X, y))\n",
    "SGDChi.append(SGD(X, y))\n",
    "SVMChi.append(SVM(X, y))\n",
    "ANNChi.append(ANN(X, y))\n",
    "DeepLearnChi.append(deepLearn(X, y))    \n",
    "print('**Chi2 Results**\\n')\n",
    "for i, k in enumerate(bestK):\n",
    "   \n",
    "    print(f'\\nK number of Features: {k}')\n",
    "   \n",
    "    \n",
    "    print('*RandomForest Results**')\n",
    "    for metric, score in RandomForestChi[i][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "    \n",
    "    print('**\\nLMT Results**')\n",
    "    for metric, score in LogisticModelChi[i][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "    \n",
    "    print('**\\nLogitBoost Results**')\n",
    "    for metric, score in LogitBoostChi[i][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "    \n",
    "    print('**\\nSGD Results**')\n",
    "    for metric, score in SGDChi[i][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "    \n",
    "    print('**\\nSVM Results**')\n",
    "    for metric, score in SVMChi[i][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "    \n",
    "    print('**\\nANN Results**')\n",
    "    for metric, score in ANNChi[i][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "    \n",
    "    print('**\\nDeepLearn Results**')\n",
    "    for metric, score in DeepLearnChi[i][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'InfoGainSGDInfoGain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-fdcee7749fa6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mLogisticModelInfoGain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLogisticModelTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mLogitBoostInfoGain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLogitBoostClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mInfoGainSGDInfoGain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mInfoGainSVMInfoGain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSVM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mInfoGainANNInfoGain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mANN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'InfoGainSGDInfoGain' is not defined"
     ]
    }
   ],
   "source": [
    "RandomForestInfoGain, LogisticModelInfoGain, LogitBoostInfoGain, SGDInfoGain, SVMInfoGain, ANNInfoGain, DeepLearnInfoGain = [], [], [], [], [], [], []\n",
    "\n",
    "for X in bestInfoGainFeatures:\n",
    "    RandomForestInfoGain.append(RandomForest(X, y))\n",
    "    LogisticModelInfoGain.append(LogisticModelTree(X, y))\n",
    "    LogitBoostInfoGain.append(LogitBoostClassifier(X, y))\n",
    "   *Chi2 Results**\n",
    "\n",
    " SGDInfoGain.append(SGD(X, y))\n",
    "    SVMInfoGain.append(SVM(X, y))\n",
    "    ANNInfoGain.append(ANN(X, y))\n",
    "    DeepLearnInfoGain.append(deepLearn(X, y))\n",
    "\n",
    "\n",
    "RandomForestInfoGain.append(RandomForest(X, y))\n",
    "LogisticModelInfoGain.append(LogisticModelTree(X, y))\n",
    "LogitBoostInfoGain.append(LogitBoostClassifier(X, y))\n",
    "InfoGainSGDInfoGain.append(SGD(X, y))\n",
    "InfoGainSVMInfoGain.append(SVM(X, y))\n",
    "InfoGainANNInfoGain.append(ANN(X, y))\n",
    "InfoGainDeepLearnInfoGain.append(deepLearn(X, y))\n",
    "print('**Infomation Gain Results**\\n')\n",
    "for i, k in enumerate(bestK):\n",
    "   \n",
    "    \n",
    "    print(f'\\nK number of Features: {k}')\n",
    "    \n",
    "    print('\\n**RandomForest Results**')\n",
    "    for metric, score in RandomForestInfoGain[i][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "    \n",
    "    print('\\n**LMT Results**')\n",
    "    for metric, score in LogisticModelInfoGain[i][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "    \n",
    "    print('\\n**LogitBoost Results**')\n",
    "    for metric, score in LogitBoostInfoGain[i][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "    \n",
    "    print('\\n**SGD Results**')\n",
    "    for metric, score in SGDInfoGain[i][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "    \n",
    "    print('\\n**SVM Results**')\n",
    "    for metric, score in SVMInfoGain[i][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "    \n",
    "    print('\\n**ANN Results**')\n",
    "    for metric, score in ANNInfoGain[i][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "    \n",
    "    print('\\n**DeepLearn Results**')\n",
    "    for metric, score in DeepLearnInfoGain[i][0].items():\n",
    "        print(f'{metric}:{score.mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
