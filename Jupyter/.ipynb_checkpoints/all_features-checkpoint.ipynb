{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permissions + Android Classes Feature Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook different machine learning algorithms will be tested on the Perissions + Android Classes Feature Set and their performance will be ranked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import Ridge, LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set __location__ depeneing which operating system user is on \n",
    "\n",
    "if os.name == \"nt\": \n",
    "    __location__ = \"F:\\FinalYearProject\\Machine Learning\\Features\\CIC_dataset\\\\\"\n",
    "else:\n",
    "    __location__ = \"/media/jackp/JACK PYE/FinalYearProject/Machine Learning/Features/CIC_dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset into panda dataframe\n",
    "df = pd.read_csv(os.path.join(__location__,\"all_features.csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1537, 1263)\n",
      "removed 3568 Features\n"
     ]
    }
   ],
   "source": [
    "#Exploring the first five entries of the dataset to show the features that have been collected\n",
    "df.head()\n",
    "old_shape = df.shape\n",
    "\n",
    "#remove features that are not supported \n",
    "df = df.loc[:, (df.sum(axis=0) != 0)]\n",
    "print(df.shape)\n",
    "new_shape = df.shape\n",
    "print(f'removed {old_shape[1] - new_shape[1]} Features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert \"Malware and Beignin lables into 1 and 0\"\n",
    "df[\"malware\"] = (df[\"malware\"] == 'Malware').astype(int)\n",
    "y = df['malware']\n",
    "X = df.drop('malware', axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomForest(X, y, kfold=10, seed=101):\n",
    "    ## create k-fold \n",
    "    kf = KFold(n_splits=kfold,shuffle=True, random_state=seed)\n",
    "    \n",
    "    #\n",
    "    accuracy_score_avg, f1_score_avg, roc_auc_score_avg, recall_score_avg, precision_score_avg = np.empty(kfold), np.empty(kfold), \\\n",
    "                                                                                    np.empty(kfold), np.empty(kfold), np.empty(kfold)\n",
    "    randomForestMetrics = {'Accuracy': accuracy_score_avg, 'F1 Score': f1_score_avg, 'ROC_AUC_Score': roc_auc_score_avg, \n",
    "                           'Recall': recall_score_avg, 'Precision': precision_score_avg}\n",
    "    \n",
    "    ## create array to hold all confusion matrices \n",
    "    cm_holder = []\n",
    "    count = 0 \n",
    "\n",
    "    ## loop through data set using k-fold split\n",
    "    for train_index, test_index in kf.split(X):\n",
    "\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        clf = RandomForestClassifier()\n",
    "        clf.fit(X_train, y_train.ravel())\n",
    "        pred = clf.predict(X_test)\n",
    "        \n",
    "        accuracy_score_avg[count] = accuracy_score(y_test, pred)\n",
    "        f1_score_avg[count] = f1_score(y_test, pred)\n",
    "        roc_auc_score_avg[count] = roc_auc_score(y_test, pred)\n",
    "        recall_score_avg[count] = recall_score(y_test, pred)\n",
    "        precision_score_avg[count] = precision_score(y_test, pred)\n",
    "        cm_holder.append(confusion_matrix(y_test, pred))\n",
    "\n",
    "        count = count + 1\n",
    "        \n",
    "    #if for any reason a metric in the folds returns 0.0 remove it from the list\n",
    "    # mean all of the k-fold together to get average\n",
    "    for key, values in randomForestMetrics.items():\n",
    "        randomForestMetrics[key] = np.array([value for value in randomForestMetrics[key] if value != 0.0])\n",
    "        randomForestMetrics[key] = randomForestMetrics[key].mean()  \n",
    "    \n",
    "    \n",
    "    true_pos, true_neg, false_pos, false_neg = [], [], [], []\n",
    "    \n",
    "    ## get all confusion matrix values and sum them together for total \n",
    "    for cm in cm_holder:\n",
    "        true_pos.append(cm[0][0])\n",
    "        false_pos.append(cm[0][1])\n",
    "        true_neg.append(cm[1][0])\n",
    "        false_neg.append(cm[1][1])\n",
    "    \n",
    "    avg_cm = np.matrix([[sum(true_pos), sum(false_pos)], [sum(true_neg), sum(false_neg)]])\n",
    "    \n",
    "    return randomForestMetrics, avg_cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.9382140735081912\n",
      "F1 Score:0.8803080358230682\n",
      "ROC_AUC_Score:0.9098586235527527\n",
      "Recall:0.8480386677843865\n",
      "Precision:0.9194598776209816\n",
      "[[1094   32]\n",
      " [  63  348]]\n"
     ]
    }
   ],
   "source": [
    "randomForestMetrics, cm = RandomForest(X, y)\n",
    "\n",
    "Classifiers = {'Random Forest': randomForestMetrics}\n",
    "\n",
    "for metric, score in randomForestMetrics.items():\n",
    "    print(f'{metric}:{score}')\n",
    "    \n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Model Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lmt import LinearModelTree\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statistics import median\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def LogisticModelTree(X, y, kfold=10, seed=101):\n",
    "    \n",
    "    shared_scaler = StandardScaler()\n",
    "    shared_scaler.fit(X)\n",
    "\n",
    "    def fit_linear_model(x, y):\n",
    "        lr = Ridge()\n",
    "        lr.fit(shared_scaler.transform(x), y)\n",
    "        return SharedScalerModel(shared_scaler, lr)\n",
    "\n",
    "    class SharedScalerModel:\n",
    "\n",
    "        def __init__(self, scaler, lm):\n",
    "            self.scaler = scaler\n",
    "            self.lm = lm\n",
    "            self.coef_ = lm.coef_\n",
    "            self.intercept_ = lm.intercept_\n",
    "\n",
    "        def predict(self, X):\n",
    "            return self.lm.predict(self.scaler.transform(X))\n",
    "\n",
    "\n",
    "    MIN_NODE_SIZE = 100\n",
    "    MIN_SPLIT_IMPROVEMENT = 10\n",
    "    lmt = LinearModelTree(MIN_NODE_SIZE, fit_linear_model, min_split_improvement=MIN_SPLIT_IMPROVEMENT)\n",
    "    \n",
    "    def GetThreshold(lmt, X, y, kfold=10, seed=101):\n",
    "        \n",
    "        pred_class = []\n",
    "\n",
    "        kf = KFold(n_splits=kfold,shuffle=True, random_state=seed)\n",
    "        fold = 0\n",
    "        best_thresholds_roc_auc, best_thresholds_f1 = [], []\n",
    "        threshold_list = [0.05,0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5,0.55,0.6,0.65,0.7,0.75,0.8,0.85,0.9,0.95,0.99]\n",
    "        for train_index, test_index in kf.split(X):\n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            lmt.build_tree(X_train.values, X_train, y_train.values)\n",
    "            pred = lmt.predict(X_test.values, X_test)\n",
    "\n",
    "            pred = [round(i, 2) for i in pred]\n",
    "\n",
    "        #     preds.append(pred)\n",
    "\n",
    "\n",
    "            pred_threshold = []\n",
    "\n",
    "            for threshold in threshold_list:\n",
    "                pred_threshold.append([1 if x>threshold else 0 for x in pred])\n",
    "\n",
    "            best_kfold_f1, best_kfold_roc_auc = [0 for i in range(10)], [0 for i in range(10)]\n",
    "\n",
    "            for c, value in enumerate(pred_threshold):\n",
    "                f1 = f1_score(y_test, value)\n",
    "                roc_auc = roc_auc_score(y_test, value)\n",
    "\n",
    "\n",
    "                if c == 0:\n",
    "                    best_kfold_f1[0], best_kfold_roc_auc[0] = f1, roc_auc\n",
    "                    best_kfold_f1[1], best_kfold_roc_auc[1] = threshold_list[c], threshold_list[c]\n",
    "\n",
    "                if best_kfold_f1[0] < f1:\n",
    "                    best_kfold_f1[0] = f1\n",
    "                    best_kfold_f1[1] = threshold_list[c]\n",
    "\n",
    "                if best_kfold_roc_auc[0] < roc_auc:\n",
    "                    best_kfold_roc_auc[0] = roc_auc\n",
    "                    best_kfold_roc_auc[1] = threshold_list[c]\n",
    "\n",
    "                if c == (len(pred_threshold) - 1):\n",
    "                    best_thresholds_roc_auc.append(best_kfold_roc_auc[1])\n",
    "                    best_thresholds_f1.append(best_kfold_f1[1])\n",
    "                    \n",
    "                    \n",
    "\n",
    "            fold = fold + 1\n",
    "\n",
    "        best_threshold_roc_auc = median(best_thresholds_roc_auc)\n",
    "        best_threshold_f1 = median(best_thresholds_roc_auc)\n",
    "        \n",
    "        \n",
    "        \n",
    "        return best_threshold_roc_auc\n",
    "    \n",
    "    def preditions(lmt, X, y, threshold, kfold=10, seed=101):\n",
    "        \n",
    "        accuracy_score_avg, f1_score_avg, roc_auc_score_avg, recall_score_avg, precision_score_avg = np.empty(kfold), np.empty(kfold), \\\n",
    "                                                                                    np.empty(kfold), np.empty(kfold), np.empty(kfold)\n",
    "        LMTMetrics = {'Accuracy': accuracy_score_avg, 'F1 Score': f1_score_avg, 'ROC_AUC_Score': roc_auc_score_avg, \n",
    "                  'Recall': recall_score_avg, 'Precision': precision_score_avg}\n",
    "        \n",
    "        kf = KFold(n_splits=kfold,shuffle=True, random_state=seed)\n",
    "        \n",
    "        cm_holder = []\n",
    "        count = 0             \n",
    "        for train_index, test_index in kf.split(X):\n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            lmt.build_tree(X_train.values, X_train, y_train.values)\n",
    "            pred = lmt.predict(X_test.values, X_test)\n",
    "\n",
    "            pred = [round(i, 2) for i in pred]\n",
    "\n",
    "            #use the threshold that we estabished in the previous run of the algorithm \n",
    "            pred_threshold = [1 if x>threshold else 0 for x in pred]\n",
    "            accuracy_score_avg[count] = accuracy_score(y_test, pred_threshold)\n",
    "            f1_score_avg[count] = f1_score(y_test, pred_threshold)\n",
    "            roc_auc_score_avg[count] = roc_auc_score(y_test, pred_threshold)\n",
    "            recall_score_avg[count] = recall_score(y_test, pred_threshold)\n",
    "            precision_score_avg[count] = precision_score(y_test, pred_threshold)\n",
    "            cm_holder.append(confusion_matrix(y_test, pred_threshold))\n",
    "\n",
    "            count = count + 1\n",
    "\n",
    "\n",
    "        #if for any reason a metric in the folds returns 0.0\n",
    "        #remove it from the list\n",
    "        for key, values in LMTMetrics.items():\n",
    "            LMTMetrics[key] = np.array([value for value in LMTMetrics[key] if value != 0.0])\n",
    "            LMTMetrics[key] = LMTMetrics[key].mean()  \n",
    "\n",
    "        true_pos, true_neg, false_pos, false_neg = [], [], [], []\n",
    "\n",
    "        for cm in cm_holder:\n",
    "            true_pos.append(cm[0][0])\n",
    "            false_pos.append(cm[0][1])\n",
    "            true_neg.append(cm[1][0])\n",
    "            false_neg.append(cm[1][1])\n",
    "\n",
    "        avg_cm = np.matrix([[sum(true_pos), sum(false_pos)], [sum(true_neg), sum(false_neg)]])\n",
    "        \n",
    "        return LMTMetrics, avg_cm\n",
    "    \n",
    "    threshold = GetThreshold(lmt, X, y, kfold)\n",
    "    return preditions(lmt, X, y, threshold, kfold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we know the best threshold to use based off the ROC_auc score, we can use this threshold now with the algorithm again to get the best representation on the performance of our classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.86991341991342\n",
      "F1 Score:0.7800413404850743\n",
      "ROC_AUC_Score:0.8670968902221194\n",
      "Recall:0.8602243803593053\n",
      "Precision:0.718986546242008\n",
      "[[984 142]\n",
      " [ 58 353]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "LMTMetrics, cm = LogisticModelTree(X, y)\n",
    "\n",
    "Classifiers['LMT'] = LMTMetrics\n",
    "\n",
    "for metric, score in LMTMetrics.items():\n",
    "    print(f'{metric}:{score}')\n",
    "    \n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will be using the cut off point that has the highest roc_auc score depicting the the usefulness of the test. As the data is imballanced the accuracy cannot be taken as a useful metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logitboost \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from logitboost import LogitBoost\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def LogitBoostClassifier(X, y, kfold=10, seed=101):\n",
    "    accuracy_score_avg, f1_score_avg, roc_auc_score_avg, recall_score_avg, precision_score_avg = np.empty(kfold), np.empty(kfold), \\\n",
    "          np.empty(kfold), np.empty(kfold), np.empty(kfold)\n",
    "\n",
    "    LogitboostMetrics = {'Accuracy': accuracy_score_avg, 'F1 Score': f1_score_avg, 'ROC_AUC_Score': roc_auc_score_avg, \n",
    "                         'Recall': recall_score_avg, 'Precision': precision_score_avg}\n",
    "    \n",
    "    lboost = LogitBoost()\n",
    "    count = 0\n",
    "    cm_holder = []\n",
    "    kf = KFold(n_splits=kfold,shuffle=True, random_state=seed)\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]    \n",
    "\n",
    "        lboost.fit(X_train, y_train)\n",
    "        pred = lboost.predict(X_test)\n",
    "        accuracy_score_avg[count] = accuracy_score(y_test, pred)\n",
    "        f1_score_avg[count] = f1_score(y_test, pred)\n",
    "        roc_auc_score_avg[count] = roc_auc_score(y_test, pred)\n",
    "        recall_score_avg[count] = recall_score(y_test, pred)\n",
    "        precision_score_avg[count] = precision_score(y_test, pred)\n",
    "        cm_holder.append(confusion_matrix(y_test, pred))\n",
    "\n",
    "        count = count + 1\n",
    "    #if for any reason a metric in a fold returns 0.0\n",
    "    #remove it from the list\n",
    "    for key, values in LogitboostMetrics.items():\n",
    "        LogitboostMetrics[key] = np.array([value for value in LogitboostMetrics[key] if value != 0.0])\n",
    "        LogitboostMetrics[key] = LogitboostMetrics[key].mean() \n",
    "\n",
    "    \n",
    "\n",
    "    true_pos, true_neg, false_pos, false_neg = [], [], [], []\n",
    "\n",
    "    for cm in cm_holder:\n",
    "        true_pos.append(cm[0][0])\n",
    "        false_pos.append(cm[0][1])\n",
    "        true_neg.append(cm[1][0])\n",
    "        false_neg.append(cm[1][1])\n",
    "\n",
    "    avg_cm = np.matrix([[sum(true_pos), sum(false_pos)], [sum(true_neg), sum(false_neg)]])\n",
    "    \n",
    "    return LogitboostMetrics, avg_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.938867668279433\n",
      "F1 Score:0.8836854664739725\n",
      "ROC_AUC_Score:0.9156159890369826\n",
      "Recall:0.8661159805425503\n",
      "Precision:0.9041595152953061\n",
      "[[1087   39]\n",
      " [  55  356]]\n"
     ]
    }
   ],
   "source": [
    "LogitboostMetrics, cm = LogitBoostClassifier(X, y)\n",
    "\n",
    "Classifiers['Logitboost'] = LogitboostMetrics\n",
    "\n",
    "for metric, score in LogitboostMetrics.items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "        \n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent (SGD) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "def SGD(X, y, kfold=10, seed=101):\n",
    "    kf = KFold(n_splits=kfold,shuffle=True, random_state=seed)\n",
    "    \n",
    "    accuracy_score_avg, f1_score_avg, roc_auc_score_avg, recall_score_avg, precision_score_avg = np.empty(kfold), np.empty(kfold), \\\n",
    "                                                                                    np.empty(kfold), np.empty(kfold), np.empty(kfold)\n",
    "    SGDMetrics = {'Accuracy': accuracy_score_avg, 'F1 Score': f1_score_avg, 'ROC_AUC_Score': roc_auc_score_avg, \n",
    "                           'Recall': recall_score_avg, 'Precision': precision_score_avg}\n",
    "    \n",
    "    ## create array to hold all confusion matrices \n",
    "    cm_holder = []\n",
    "    count = 0 \n",
    "    for train_index, test_index in kf.split(X):\n",
    "\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        clf = SGDClassifier()\n",
    "        clf.fit(X_train, y_train.ravel())\n",
    "        pred = clf.predict(X_test)\n",
    "        \n",
    "        accuracy_score_avg[count] = accuracy_score(y_test, pred)\n",
    "        f1_score_avg[count] = f1_score(y_test, pred)\n",
    "        roc_auc_score_avg[count] = roc_auc_score(y_test, pred)\n",
    "        recall_score_avg[count] = recall_score(y_test, pred)\n",
    "        precision_score_avg[count] = precision_score(y_test, pred)\n",
    "        cm_holder.append(confusion_matrix(y_test, pred))\n",
    "\n",
    "        count = count + 1\n",
    "        \n",
    "    #if for any reason a metric in the folds returns 0.0\n",
    "    #remove it from the list\n",
    "    for key, values in SGDMetrics.items():\n",
    "        SGDMetrics[key] = np.array([value for value in SGDMetrics[key] if value != 0.0])\n",
    "        SGDMetrics[key] = SGDMetrics[key].mean()  \n",
    "    \n",
    "    \n",
    "    true_pos, true_neg, false_pos, false_neg = [], [], [], []\n",
    "\n",
    "    for cm in cm_holder:\n",
    "        true_pos.append(cm[0][0])\n",
    "        false_pos.append(cm[0][1])\n",
    "        true_neg.append(cm[1][0])\n",
    "        false_neg.append(cm[1][1])\n",
    "    \n",
    "    avg_cm = np.matrix([[sum(true_pos), sum(false_pos)], [sum(true_neg), sum(false_neg)]])\n",
    "    \n",
    "    return SGDMetrics, avg_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.944037008742891\n",
      "F1 Score:0.890314001900577\n",
      "ROC_AUC_Score:0.920012135480991\n",
      "Recall:0.8683745159873858\n",
      "Precision:0.9213159954013612\n",
      "[[1094   32]\n",
      " [  54  357]]\n"
     ]
    }
   ],
   "source": [
    "SGDMetrics, cm = SGD(X, y)\n",
    "Classifiers['SGD'] = SGDMetrics\n",
    "\n",
    "for metric, score in SGDMetrics.items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "        \n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "def SVM(X, y, kfold=10, seed=101):\n",
    "    accuracy_score_avg, f1_score_avg, roc_auc_score_avg, recall_score_avg, precision_score_avg  = np.empty(kfold), np.empty(kfold), \\\n",
    "                                                                                    np.empty(kfold), np.empty(kfold), np.empty(kfold)\n",
    "    cm_holder = []\n",
    "    SVCMetrics = {'Accuracy': accuracy_score_avg, 'F1 Score': f1_score_avg, 'ROC_AUC_Score': roc_auc_score_avg, \n",
    "                         'Recall': recall_score_avg, 'Precision': precision_score_avg}\n",
    "    \n",
    "\n",
    "    svc = SVC()\n",
    "    count = 0\n",
    "    kf = KFold(n_splits=kfold,shuffle=True, random_state=seed)\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        svc.fit(X_train, y_train)\n",
    "        pred = svc.predict(X_test)\n",
    "        accuracy_score_avg[count] = accuracy_score(y_test, pred)\n",
    "        f1_score_avg[count] = f1_score(y_test, pred)\n",
    "        roc_auc_score_avg[count] = roc_auc_score(y_test, pred)\n",
    "        recall_score_avg[count] = recall_score(y_test, pred)\n",
    "        precision_score_avg[count] = precision_score(y_test, pred)\n",
    "        cm_holder.append(confusion_matrix(y_test, pred))\n",
    "\n",
    "        count = count + 1\n",
    "\n",
    "    for key, values in SVCMetrics.items():\n",
    "        SVCMetrics[key] = np.array([value for value in SVCMetrics[key] if value != 0.0])\n",
    "        SVCMetrics[key] = SVCMetrics[key].mean()\n",
    "\n",
    "\n",
    "    true_pos, true_neg, false_pos, false_neg = [], [], [], []\n",
    "\n",
    "    for cm in cm_holder:\n",
    "        true_pos.append(cm[0][0])\n",
    "        false_pos.append(cm[0][1])\n",
    "        true_neg.append(cm[1][0])\n",
    "        false_neg.append(cm[1][1])\n",
    "\n",
    "    avg_cm = np.matrix([[sum(true_pos), sum(false_pos)], [sum(true_neg), sum(false_neg)]])\n",
    "    \n",
    "    return SVCMetrics, avg_cm\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.938867668279433\n",
      "F1 Score:0.8807255639696852\n",
      "ROC_AUC_Score:0.9112648380532254\n",
      "Recall:0.8517905377791213\n",
      "Precision:0.9153996332092307\n",
      "[[1093   33]\n",
      " [  61  350]]\n"
     ]
    }
   ],
   "source": [
    "SVCMetrics, cm = SVM(X, y)\n",
    "\n",
    "Classifiers['SVC'] = SVCMetrics\n",
    "\n",
    "for metric, score in SVCMetrics.items():\n",
    "        print(f'{metric}:{score}')\n",
    "        \n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artificial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "\n",
    "def ANN(X, y, kfold=10, seed=101):\n",
    "    accuracy_score_avg, f1_score_avg, roc_auc_score_avg, recall_score_avg, precision_score_avg  = np.empty(kfold), np.empty(kfold), \\\n",
    "                                                                                    np.empty(kfold), np.empty(kfold), np.empty(kfold)\n",
    "    cm_holder = []\n",
    "    ANNMetrics = {'Accuracy': accuracy_score_avg, 'F1 Score': f1_score_avg, 'ROC_AUC_Score': roc_auc_score_avg, \n",
    "                         'Recall': recall_score_avg, 'Precision': precision_score_avg}\n",
    "    \n",
    "\n",
    "\n",
    "    def DL_Model(activation= 'linear', neurons= 5, optimizer='Adam'):\n",
    "        n_cols = X_train.shape[1]\n",
    "        model = Sequential()\n",
    "        model.add(Dense(250, activation='relu', input_shape=(n_cols,)))\n",
    "        model.add(Dense(250, activation='relu'))\n",
    "        model.add(Dropout(0.3))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.compile(loss='binary_crossentropy', optimizer= 'adam', metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    ANN = KerasClassifier(build_fn= DL_Model, epochs= 80, batch_size=100, verbose= 0)\n",
    "    kf = KFold(n_splits=kfold,shuffle=True, random_state=seed)\n",
    "    count = 0\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "\n",
    "        ANN.fit(X_train.values, y_train)\n",
    "        pred = ANN.predict(X_test)\n",
    "        accuracy_score_avg[count] = accuracy_score(y_test, pred)\n",
    "        f1_score_avg[count] = f1_score(y_test, pred)\n",
    "        roc_auc_score_avg[count] = roc_auc_score(y_test, pred)\n",
    "        recall_score_avg[count] = recall_score(y_test, pred)\n",
    "        precision_score_avg[count] = precision_score(y_test, pred)\n",
    "        cm_holder.append(confusion_matrix(y_test, pred))\n",
    "\n",
    "        count = count + 1\n",
    "\n",
    "    for key, values in ANNMetrics.items():\n",
    "        ANNMetrics[key] = np.array([value for value in ANNMetrics[key] if value != 0.0])\n",
    "        ANNMetrics[key] = ANNMetrics[key].mean()\n",
    "\n",
    "    \n",
    "\n",
    "    true_pos, true_neg, false_pos, false_neg = [], [], [], []\n",
    "\n",
    "    for cm in cm_holder:\n",
    "        true_pos.append(cm[0][0])\n",
    "        false_pos.append(cm[0][1])\n",
    "        true_neg.append(cm[1][0])\n",
    "        false_neg.append(cm[1][1])\n",
    "\n",
    "    avg_cm = np.matrix([[sum(true_pos), sum(false_pos)], [sum(true_neg), sum(false_neg)]])\n",
    "    \n",
    "    return ANNMetrics, avg_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.9616458704693999\n",
      "F1 Score:0.9269225746109967\n",
      "ROC_AUC_Score:0.9475228433308025\n",
      "Recall:0.9172367418086154\n",
      "Precision:0.9406416203754798\n"
     ]
    }
   ],
   "source": [
    "ANNMetrics, cm = ANN(X, y)\n",
    "\n",
    "Classifiers['ANN'] = ANNMetrics\n",
    "\n",
    "for metric, score in ANNMetrics.items():\n",
    "        print(f'{metric}:{score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "def deepLearn(X, y, kfold=10, seed=101):\n",
    "    accuracy_score_avg, f1_score_avg, roc_auc_score_avg, recall_score_avg, precision_score_avg  = np.empty(kfold), np.empty(kfold), \\\n",
    "                                                                                    np.empty(kfold), np.empty(kfold), np.empty(kfold)\n",
    "    cm_holder = []\n",
    "    DeepLearnMetrics = {'Accuracy': accuracy_score_avg, 'F1 Score': f1_score_avg, 'ROC_AUC_Score': roc_auc_score_avg, \n",
    "                         'Recall': recall_score_avg, 'Precision': precision_score_avg}\n",
    "\n",
    "\n",
    "\n",
    "    def DL_Model():\n",
    "        n_cols = X_train.shape[1]\n",
    "        model = Sequential()\n",
    "        model.add(Dense(250, activation='relu', input_shape=(n_cols,)))\n",
    "        model.add(Dense(250, activation='relu'))\n",
    "        model.add(Dense(250, activation='relu'))\n",
    "        model.add(Dense(2, activation='softmax'))\n",
    "        model.compile(loss='categorical_crossentropy', optimizer= 'adam', metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    deepLearn = KerasClassifier(build_fn= DL_Model, epochs= 80, batch_size=40, verbose= 0)\n",
    "    cm_holder = []\n",
    "    count = 0\n",
    "    kf = KFold(n_splits=kfold,shuffle=True, random_state=seed)\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        train_y_2 = to_categorical(y_train)\n",
    "        deepLearn.fit(X_train, train_y_2)\n",
    "        pred = deepLearn.predict(X_test)\n",
    "        accuracy_score_avg[count] = accuracy_score(y_test, pred)\n",
    "        f1_score_avg[count] = f1_score(y_test, pred)\n",
    "        roc_auc_score_avg[count] = roc_auc_score(y_test, pred)\n",
    "        recall_score_avg[count] = recall_score(y_test, pred)\n",
    "        precision_score_avg[count] = precision_score(y_test, pred)\n",
    "        cm_holder.append(confusion_matrix(y_test, pred))\n",
    "\n",
    "        count = count + 1\n",
    "\n",
    "    for key, values in DeepLearnMetrics.items():\n",
    "        DeepLearnMetrics[key] = np.array([value for value in DeepLearnMetrics[key] if value != 0.0])\n",
    "        DeepLearnMetrics[key] = DeepLearnMetrics[key].mean()\n",
    "\n",
    "    \n",
    "\n",
    "    true_pos, true_neg, false_pos, false_neg = [], [], [], []\n",
    "\n",
    "    for cm in cm_holder:\n",
    "        true_pos.append(cm[0][0])\n",
    "        false_pos.append(cm[0][1])\n",
    "        true_neg.append(cm[1][0])\n",
    "        false_neg.append(cm[1][1])\n",
    "\n",
    "    avg_cm = np.matrix([[sum(true_pos), sum(false_pos)], [sum(true_neg), sum(false_neg)]])\n",
    "    \n",
    "    return DeepLearnMetrics, avg_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.9570749511925983\n",
      "F1 Score:0.9177894011413595\n",
      "ROC_AUC_Score:0.9432839808983852\n",
      "Recall:0.9140378389989184\n",
      "Precision:0.9272602857382737\n",
      "[[1095   31]\n",
      " [  35  376]]\n"
     ]
    }
   ],
   "source": [
    "DeepLearnMetrics, cm = deepLearn(X, y)\n",
    "\n",
    "Classifiers['DeepLearnMetrics'] = DeepLearnMetrics\n",
    "\n",
    "for metric, score in DeepLearnMetrics.items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "        \n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****ANN****\n",
      "Accuracy: 0.9616458704693999\n",
      "F1 Score: 0.9269225746109967\n",
      "ROC_AUC_Score: 0.9475228433308025\n",
      "Recall: 0.9172367418086154\n",
      "Precision: 0.9406416203754798\n",
      "\n",
      "****DeepLearnMetrics****\n",
      "Accuracy: 0.9570749511925983\n",
      "F1 Score: 0.9177894011413595\n",
      "ROC_AUC_Score: 0.9432839808983852\n",
      "Recall: 0.9140378389989184\n",
      "Precision: 0.9272602857382737\n",
      "\n",
      "****SGD****\n",
      "Accuracy: 0.944037008742891\n",
      "F1 Score: 0.890314001900577\n",
      "ROC_AUC_Score: 0.920012135480991\n",
      "Recall: 0.8683745159873858\n",
      "Precision: 0.9213159954013612\n",
      "\n",
      "****Logitboost****\n",
      "Accuracy: 0.938867668279433\n",
      "F1 Score: 0.8836854664739725\n",
      "ROC_AUC_Score: 0.9156159890369826\n",
      "Recall: 0.8661159805425503\n",
      "Precision: 0.9041595152953061\n",
      "\n",
      "****SVC****\n",
      "Accuracy: 0.938867668279433\n",
      "F1 Score: 0.8807255639696852\n",
      "ROC_AUC_Score: 0.9112648380532254\n",
      "Recall: 0.8517905377791213\n",
      "Precision: 0.9153996332092307\n",
      "\n",
      "****Random Forest****\n",
      "Accuracy: 0.9382140735081912\n",
      "F1 Score: 0.8803080358230682\n",
      "ROC_AUC_Score: 0.9098586235527527\n",
      "Recall: 0.8480386677843865\n",
      "Precision: 0.9194598776209816\n",
      "\n",
      "****LMT****\n",
      "Accuracy: 0.86991341991342\n",
      "F1 Score: 0.7800413404850743\n",
      "ROC_AUC_Score: 0.8670968902221194\n",
      "Recall: 0.8602243803593053\n",
      "Precision: 0.718986546242008\n"
     ]
    }
   ],
   "source": [
    "sortedClassifiers = sorted(Classifiers.items(), key = lambda x: x[1]['F1 Score'], reverse=True) \n",
    "\n",
    "for classifier in sortedClassifiers:\n",
    "    print(f'\\n****{classifier[0]}****')\n",
    "    for metric, result in classifier[1].items():\n",
    "        print(f'{metric}: {result}')\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old number of features: 1262\n",
      "             New number of features: 615\n",
      "             Number of features removed 647\n",
      "Old number of features: 1262\n",
      "             New number of features: 498\n",
      "             Number of features removed 764\n",
      "Old number of features: 1262\n",
      "             New number of features: 377\n",
      "             Number of features removed 885\n",
      "Old number of features: 1262\n",
      "             New number of features: 249\n",
      "             Number of features removed 1013\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "def getVarianceFeatures(X, y, var):\n",
    "    variancefs = VarianceThreshold(threshold=var).fit(X)\n",
    "    cols = variancefs.get_support(indices=True)\n",
    "    new_X = X.iloc[:,cols]\n",
    "    lostFeatures = X.shape[1] - new_X.shape[1]\n",
    "    \n",
    "    print(f'Old number of features: {X.shape[1]}\\n \\\n",
    "            New number of features: {new_X.shape[1]}\\n \\\n",
    "            Number of features removed {lostFeatures}')\n",
    "    \n",
    "    return new_X\n",
    "\n",
    "bestVarFeatures = []\n",
    "variance = [0.05, 0.1, 0.15, 0.2]\n",
    "for i in variance:\n",
    "    bestVarFeatures.append(getVarianceFeatures(X, y, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "RandomForestVar, LogisticModelVar, LogitBoostVar, SGDVar, SVMVar, ANNVar, DeepLearnVar = [], [], [], [], [], [], []\n",
    "\n",
    "for X in bestVarFeatures:\n",
    "    RandomForestVar.append(RandomForest(X, y))\n",
    "    LogisticModelVar.append(LogisticModelTree(X, y))\n",
    "    LogitBoostVar.append(LogitBoostClassifier(X, y))\n",
    "    SGDVar.append(SGD(X, y))\n",
    "    SVMVar.append(SVM(X, y))\n",
    "    ANNVar.append(ANN(X, y))\n",
    "    DeepLearnVar.append(deepLearn(X, y))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*RandomForest Results**\n",
      "\n",
      "**0.05**\n",
      "Accuracy:0.9356166709107885\n",
      "F1 Score:0.8764128006850015\n",
      "ROC_AUC_Score:0.9098151074519503\n",
      "Recall:0.8542384963246408\n",
      "Precision:0.9035200480540395\n",
      "\n",
      "**0.1**\n",
      "Accuracy:0.9434131228248874\n",
      "F1 Score:0.8886010227759338\n",
      "ROC_AUC_Score:0.9149516423946713\n",
      "Recall:0.8536769751611475\n",
      "Precision:0.9315125619051765\n",
      "\n",
      "**0.15**\n",
      "Accuracy:0.9349715643833291\n",
      "F1 Score:0.8734175911156559\n",
      "ROC_AUC_Score:0.9058151978358611\n",
      "Recall:0.8426022342991726\n",
      "Precision:0.9109428400546822\n",
      "\n",
      "**0.2**\n",
      "Accuracy:0.9362660215601393\n",
      "F1 Score:0.8771592108412418\n",
      "ROC_AUC_Score:0.9092163062158505\n",
      "Recall:0.8502945419914804\n",
      "Precision:0.9094625392361012\n",
      "\n",
      "**LMT Results**\n",
      "\n",
      "**0.05**\n",
      "Accuracy:0.9394957983193277\n",
      "F1 Score:0.8890737678084386\n",
      "ROC_AUC_Score:0.9300905294609256\n",
      "Recall:0.9099656700331324\n",
      "Precision:0.8706635192798485\n",
      "\n",
      "**0.1**\n",
      "Accuracy:0.9291146761734996\n",
      "F1 Score:0.8724267300783091\n",
      "ROC_AUC_Score:0.9223905697259319\n",
      "Recall:0.9077830749081398\n",
      "Precision:0.8420032468765661\n",
      "\n",
      "**0.15**\n",
      "Accuracy:0.9271538918597741\n",
      "F1 Score:0.8663765283166409\n",
      "ROC_AUC_Score:0.9152220446314759\n",
      "Recall:0.8887627335473729\n",
      "Precision:0.8476230453531295\n",
      "\n",
      "**0.2**\n",
      "Accuracy:0.9102622867328749\n",
      "F1 Score:0.8432011739077522\n",
      "ROC_AUC_Score:0.9085432448703152\n",
      "Recall:0.9049656795375529\n",
      "Precision:0.7905059891671095\n",
      "\n",
      "**LogitBoost Results**\n",
      "\n",
      "**0.05**\n",
      "Accuracy:0.926517273576097\n",
      "F1 Score:0.8589485422305578\n",
      "ROC_AUC_Score:0.9013247204451345\n",
      "Recall:0.8480453208787407\n",
      "Precision:0.872638480804875\n",
      "\n",
      "**0.1**\n",
      "Accuracy:0.9284610814022578\n",
      "F1 Score:0.8608747110752706\n",
      "ROC_AUC_Score:0.8994057537190361\n",
      "Recall:0.8380971389793392\n",
      "Precision:0.8878918155770078\n",
      "\n",
      "**0.15**\n",
      "Accuracy:0.9265300059417706\n",
      "F1 Score:0.8580662856281844\n",
      "ROC_AUC_Score:0.8982883606201255\n",
      "Recall:0.8374530244016493\n",
      "Precision:0.8835523953090398\n",
      "\n",
      "**0.2**\n",
      "Accuracy:0.9109243697478993\n",
      "F1 Score:0.8298723741145094\n",
      "ROC_AUC_Score:0.8790928387148004\n",
      "Recall:0.8116958547420404\n",
      "Precision:0.8505453008186687\n",
      "\n",
      "**GD Results**\n",
      "**0.05**\n",
      "Accuracy:0.9453484424072659\n",
      "F1 Score:0.8971417744078112\n",
      "ROC_AUC_Score:0.9281903929032174\n",
      "Recall:0.8900689260575094\n",
      "Precision:0.9097848405162535\n",
      "**0.1**\n",
      "Accuracy:0.9440879382055852\n",
      "F1 Score:0.8971467568117208\n",
      "ROC_AUC_Score:0.9294761822442889\n",
      "Recall:0.8992178812365632\n",
      "Precision:0.8996679632716784\n",
      "**0.15**\n",
      "Accuracy:0.9245649775061541\n",
      "F1 Score:0.861476321269046\n",
      "ROC_AUC_Score:0.9093902007978981\n",
      "Recall:0.8764948077350777\n",
      "Precision:0.8519757716843749\n",
      "**0.2**\n",
      "Accuracy:0.8972837619896443\n",
      "F1 Score:0.8278845407125217\n",
      "ROC_AUC_Score:0.8874448345239421\n",
      "Recall:0.8663540662762251\n",
      "Precision:0.8139227340232852\n",
      "\n",
      "**SVM Results**\n",
      "\n",
      "**0.05**\n",
      "Accuracy:0.9414735591206179\n",
      "F1 Score:0.8866278388932776\n",
      "ROC_AUC_Score:0.9147063379149198\n",
      "Recall:0.8569187429073262\n",
      "Precision:0.9219644808059442\n",
      "\n",
      "**0.1**\n",
      "Accuracy:0.9414693149987267\n",
      "F1 Score:0.886954668822811\n",
      "ROC_AUC_Score:0.9160352796388425\n",
      "Recall:0.8614273548627468\n",
      "Precision:0.9178568666427122\n",
      "\n",
      "**0.15**\n",
      "Accuracy:0.9316993464052288\n",
      "F1 Score:0.8668719561018399\n",
      "ROC_AUC_Score:0.9013178004740656\n",
      "Recall:0.8363478503852143\n",
      "Precision:0.9026972516926766\n",
      "\n",
      "**0.2**\n",
      "Accuracy:0.9297597827009592\n",
      "F1 Score:0.8651653128356805\n",
      "ROC_AUC_Score:0.9008808332161118\n",
      "Recall:0.839095103132467\n",
      "Precision:0.8968309800081423\n",
      "\n",
      "**ANN Results**\n",
      "\n",
      "**0.05**\n",
      "Accuracy:0.9603386809269162\n",
      "F1 Score:0.9243741798113143\n",
      "ROC_AUC_Score:0.9465399985167702\n",
      "Recall:0.917053591625465\n",
      "Precision:0.9347497834852485\n",
      "\n",
      "**0.1**\n",
      "Accuracy:0.9570749511925982\n",
      "F1 Score:0.9192275761295837\n",
      "ROC_AUC_Score:0.9438526567183134\n",
      "Recall:0.9151671542434385\n",
      "Precision:0.9276166293923034\n",
      "\n",
      "**0.15**\n",
      "Accuracy:0.9479840421016892\n",
      "F1 Score:0.9010796296748556\n",
      "ROC_AUC_Score:0.9304969271152904\n",
      "Recall:0.8927799669626344\n",
      "Precision:0.9163825276489277\n",
      "\n",
      "**0.2**\n",
      "Accuracy:0.9479967744673627\n",
      "F1 Score:0.901741937000067\n",
      "ROC_AUC_Score:0.9324859661982444\n",
      "Recall:0.8986407728234402\n",
      "Precision:0.9089079499491947\n",
      "\n",
      "**DeepLearn Results**\n",
      "\n",
      "**0.05**\n",
      "Accuracy:0.9564510652745947\n",
      "F1 Score:0.9203518933828535\n",
      "ROC_AUC_Score:0.949102111984472\n",
      "Recall:0.9328076438351477\n",
      "Precision:0.9103057056554349\n",
      "\n",
      "**0.1**\n",
      "Accuracy:0.9531915796621678\n",
      "F1 Score:0.9120869518268817\n",
      "ROC_AUC_Score:0.9381712186945066\n",
      "Recall:0.9056554153336718\n",
      "Precision:0.9223021898561587\n",
      "\n",
      "**0.15**\n",
      "Accuracy:0.9473516679399033\n",
      "F1 Score:0.9008059057851678\n",
      "ROC_AUC_Score:0.9327052485750649\n",
      "Recall:0.9008265044071999\n",
      "Precision:0.9050794633248049\n",
      "\n",
      "**0.2**\n",
      "Accuracy:0.9512350394703336\n",
      "F1 Score:0.9084319694967548\n",
      "ROC_AUC_Score:0.9373060800685824\n",
      "Recall:0.9065283013129406\n",
      "Precision:0.9121477657302808\n"
     ]
    }
   ],
   "source": [
    "print('*RandomForest Results**')\n",
    "for c, i in enumerate(variance): \n",
    "    print(f'\\n**{i}**')\n",
    "    for metric, score in RandomForestVar[c][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "\n",
    "print('\\n**LMT Results**')\n",
    "for c, i in enumerate(variance): \n",
    "    print(f'\\n**{i}**')\n",
    "    for metric, score in LogisticModelVar[c][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "\n",
    "print('\\n**LogitBoost Results**')\n",
    "for c, i in enumerate(variance): \n",
    "    print(f'\\n**{i}**')\n",
    "    for metric, score in LogitBoostVar[c][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "        \n",
    "print('\\n**SGD Results**')\n",
    "for c, i in enumerate(variance): \n",
    "    print(f'**{i}**')\n",
    "    for metric, score in SGDVar[c][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "\n",
    "print('\\n**SVM Results**')\n",
    "for c, i in enumerate(variance): \n",
    "    print(f'\\n**{i}**')\n",
    "    for metric, score in SVMVar[c][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "        \n",
    "print('\\n**ANN Results**')\n",
    "for c, i in enumerate(variance): \n",
    "    print(f'\\n**{i}**')\n",
    "    for metric, score in ANNVar[c][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "\n",
    "print('\\n**DeepLearn Results**')\n",
    "for c, i in enumerate(variance): \n",
    "    print(f'\\n**{i}**')\n",
    "    for metric, score in DeepLearnVar[c][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi2  Info Gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.feature_selection import chi2, mutual_info_classif\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# fschi2 = SelectKBest(chi2, k='all')\n",
    "# fschi2.fit(X, y)\n",
    "# fschi2.transform(X)\n",
    "# fs_info_gain = SelectKBest(mutual_info_classif, k='all')\n",
    "# fs_info_gain.fit(X, y)\n",
    "# fs_info_gain.transform(X)\n",
    "# bestfeatschi2 = []\n",
    "# bestfeats_info_gain = []\n",
    "# bestFeatsThresholdChi2 = [50, 75, 100, 150]\n",
    "# for treshold in bestFeatsThreshold:\n",
    "#     bestfeatschi2.append([i for i in fschi2.scores_ if i > treshold])\n",
    "#     bestfeats_info_gain.append([i for i in fs_info_gain.scores_ if i > treshold])\n",
    "    \n",
    "# for index,value in enumerate(bestfeatschi2):\n",
    "#     pyplot.bar([i for i in range(len(bestfeatschi2[index]))], bestfeatschi2[index])\n",
    "#     pyplot.show()\n",
    "#     pyplot.bar([i for i in range(len(bestfeats_info_gain[index]))], bestfeats_info_gain[index])\n",
    "#     pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestPercent = [2, 5, 10, 25, 40, 50, 70]\n",
    "bestChiFeatures = []\n",
    "bestInfoGainFeatures = []\n",
    "def getChi2Features(X, y, k):\n",
    "    chi2fs = SelectPercentile(score_func=chi2, percentile=k).fit(X, y)\n",
    "    cols = chi2fs.get_support(indices=True)\n",
    "    new_X = X.iloc[:,cols]\n",
    "    return new_X\n",
    "\n",
    "def getInfoGainFeatures(X, y, k):\n",
    "    InfoGainfs = SelectPercentile(score_func=mutual_info_classif, percentile=k).fit(X, y)\n",
    "    cols = InfoGainfs.get_support(indices=True)\n",
    "    new_X = X.iloc[:,cols]\n",
    "    return new_X\n",
    "\n",
    "for i in bestPercent:\n",
    "    bestChiFeatures.append(getChi2Features(X,y,i))\n",
    "    bestInfoGainFeatures.append(getInfoGainFeatures(X, y, i))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/jackp/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3319, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-82-b961f0f2d4d4>\", line 11, in <module>\n",
      "    DeepLearnChi.append(deepLearn(X, y))\n",
      "  File \"<ipython-input-31-ea0704e7184f>\", line 35, in deepLearn\n",
      "    deepLearn.fit(X_train, train_y_2)\n",
      "  File \"/home/jackp/anaconda3/lib/python3.6/site-packages/keras/wrappers/scikit_learn.py\", line 209, in fit\n",
      "    return super(KerasClassifier, self).fit(x, y, **kwargs)\n",
      "  File \"/home/jackp/anaconda3/lib/python3.6/site-packages/keras/wrappers/scikit_learn.py\", line 151, in fit\n",
      "    history = self.model.fit(x, y, **fit_args)\n",
      "  File \"/home/jackp/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\", line 1239, in fit\n",
      "    validation_freq=validation_freq)\n",
      "  File \"/home/jackp/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\", line 196, in fit_loop\n",
      "    outs = fit_function(ins_batch)\n",
      "  File \"/home/jackp/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py\", line 3727, in __call__\n",
      "    outputs = self._graph_fn(*converted_inputs)\n",
      "  File \"/home/jackp/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\", line 1551, in __call__\n",
      "    return self._call_impl(args, kwargs)\n",
      "  File \"/home/jackp/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\", line 1591, in _call_impl\n",
      "    return self._call_flat(args, self.captured_inputs, cancellation_manager)\n",
      "  File \"/home/jackp/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\", line 1692, in _call_flat\n",
      "    ctx, args, cancellation_manager=cancellation_manager))\n",
      "  File \"/home/jackp/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\", line 545, in call\n",
      "    ctx=ctx)\n",
      "  File \"/home/jackp/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py\", line 61, in quick_execute\n",
      "    num_outputs)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jackp/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2034, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jackp/.local/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/jackp/.local/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/jackp/.local/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/jackp/anaconda3/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/jackp/anaconda3/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/jackp/anaconda3/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/jackp/anaconda3/lib/python3.6/inspect.py\", line 725, in getmodule\n",
      "    file = getabsfile(object, _filename)\n",
      "  File \"/home/jackp/anaconda3/lib/python3.6/inspect.py\", line 709, in getabsfile\n",
      "    return os.path.normcase(os.path.abspath(_filename))\n",
      "  File \"/home/jackp/anaconda3/lib/python3.6/posixpath.py\", line 383, in abspath\n",
      "    cwd = os.getcwd()\n",
      "OSError: [Errno 5] Input/output error\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "RandomForestChi, LogisticModelChi, LogitBoostChi, SGDChi, SVMChi, ANNChi, DeepLearnChi = [], [], [], [], [], [], []\n",
    "\n",
    "\n",
    "for X in bestChiFeatures:\n",
    "    RandomForestChi.append(RandomForest(X, y))\n",
    "    LogisticModelChi.append(LogisticModelTree(X, y))\n",
    "    LogitBoostChi.append(LogitBoostClassifier(X, y))\n",
    "    SGDChi.append(SGD(X, y))\n",
    "    SVMChi.append(SVM(X, y))\n",
    "    ANNChi.append(ANN(X, y))\n",
    "    DeepLearnChi.append(deepLearn(X, y))\n",
    "\n",
    "    \n",
    "print('*RandomForest Results**')\n",
    "for c, i in enumerate(bestPercent): \n",
    "    print(f'\\n**{i}**')\n",
    "    for metric, score in RandomForestChi[c][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "\n",
    "print('\\n**LMT Results**')\n",
    "for c, i in enumerate(bestPercent): \n",
    "    print(f'\\n**{i}**')\n",
    "    for metric, score in LogisticModelChi[c][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "\n",
    "print('\\n**LogitBoost Results**')\n",
    "for c, i in enumerate(bestPercent): \n",
    "    print(f'\\n**{i}**')\n",
    "    for metric, score in LogitBoostChi[c][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "        \n",
    "print('\\n**SGD Results**')\n",
    "for c, i in enumerate(bestPercent): \n",
    "    print(f'**{i}**')\n",
    "    for metric, score in SGDChi[c][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "\n",
    "print('\\n**SVM Results**')\n",
    "for c, i in enumerate(bestPercent): \n",
    "    print(f'\\n**{i}**')\n",
    "    for metric, score in SVMChi[c][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "        \n",
    "print('\\n**ANN Results**')\n",
    "for c, i in enumerate(bestPercent): \n",
    "    print(f'\\n**{i}**')\n",
    "    for metric, score in ANNChi[c][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "\n",
    "print('\\n**DeepLearn Results**')\n",
    "for c, i in enumerate(bestPercent): \n",
    "    print(f'\\n**{i}**')\n",
    "    for metric, score in DeepLearnChi[c][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*RandomForest Results**\n",
      "\n",
      "**2**\n",
      "Accuracy:0.8705373058314235\n",
      "F1 Score:0.7621593958575527\n",
      "ROC_AUC_Score:0.8406069162789453\n",
      "Recall:0.7762952149044521\n",
      "Precision:0.7535160357095488\n",
      "\n",
      "**5**\n",
      "Accuracy:0.8822553263729734\n",
      "F1 Score:0.7829363754662297\n",
      "ROC_AUC_Score:0.8542269089864668\n",
      "Recall:0.7938776324868696\n",
      "Precision:0.7748460722596573\n",
      "\n",
      "**10**\n",
      "Accuracy:0.884848484848485\n",
      "F1 Score:0.7752905849310086\n",
      "ROC_AUC_Score:0.8410709301137477\n",
      "Recall:0.7469572548192164\n",
      "Precision:0.8122401388255047\n",
      "\n",
      "**25**\n",
      "Accuracy:0.9121848739495798\n",
      "F1 Score:0.8314396241251275\n",
      "ROC_AUC_Score:0.8784995559040156\n",
      "Recall:0.8059382668879296\n",
      "Precision:0.8625827889980278\n",
      "\n",
      "**40**\n",
      "Accuracy:0.9238986503692386\n",
      "F1 Score:0.8544522022150453\n",
      "ROC_AUC_Score:0.8958481719328816\n",
      "Recall:0.8352029478910643\n",
      "Precision:0.8791145824646687\n",
      "\n",
      "**50**\n",
      "Accuracy:0.9297512944571767\n",
      "F1 Score:0.8650770685513519\n",
      "ROC_AUC_Score:0.9011336054652169\n",
      "Recall:0.8395985522866687\n",
      "Precision:0.8963484730596724\n",
      "\n",
      "**70**\n",
      "Accuracy:0.9232450555979967\n",
      "F1 Score:0.8528743991863648\n",
      "ROC_AUC_Score:0.8942692478878591\n",
      "Recall:0.8310298419795048\n",
      "Precision:0.8815722663594429\n",
      "\n",
      "**LMT Results**\n",
      "\n",
      "**2**\n",
      "Accuracy:0.8607546048722519\n",
      "F1 Score:0.7545617150627921\n",
      "ROC_AUC_Score:0.8410555872165665\n",
      "Recall:0.7984992520021061\n",
      "Precision:0.7192777271170165\n",
      "\n",
      "**5**\n",
      "Accuracy:0.8640565317035905\n",
      "F1 Score:0.7657964561869801\n",
      "ROC_AUC_Score:0.8529645078842465\n",
      "Recall:0.8286520260573192\n",
      "Precision:0.7143405987759575\n",
      "\n",
      "**10**\n",
      "Accuracy:0.867965367965368\n",
      "F1 Score:0.7720940450325166\n",
      "ROC_AUC_Score:0.8562289670837021\n",
      "Recall:0.8307765491730205\n",
      "Precision:0.7249350093929667\n",
      "\n",
      "**25**\n",
      "Accuracy:0.8660258042610984\n",
      "F1 Score:0.7588661380668351\n",
      "ROC_AUC_Score:0.8402961477104152\n",
      "Recall:0.7856787391815934\n",
      "Precision:0.7361238839602626\n",
      "\n",
      "**40**\n",
      "Accuracy:0.880973601561837\n",
      "F1 Score:0.7822071696402477\n",
      "ROC_AUC_Score:0.8560049828435667\n",
      "Recall:0.8037591883985241\n",
      "Precision:0.763886377055325\n",
      "\n",
      "**50**\n",
      "Accuracy:0.8770817417876241\n",
      "F1 Score:0.7868341834847004\n",
      "ROC_AUC_Score:0.8675485935239993\n",
      "Recall:0.8482405416759337\n",
      "Precision:0.7363841240134545\n",
      "\n",
      "**70**\n",
      "Accuracy:0.9024318818436466\n",
      "F1 Score:0.8286158696908658\n",
      "ROC_AUC_Score:0.8953457889998434\n",
      "Recall:0.8805178388468479\n",
      "Precision:0.7846751981324679\n",
      "\n",
      "**LogitBoost Results**\n",
      "\n",
      "**2**\n",
      "Accuracy:0.8666412019353196\n",
      "F1 Score:0.7523356647127811\n",
      "ROC_AUC_Score:0.8325779679525788\n",
      "Recall:0.7593444611088618\n",
      "Precision:0.7518666076897598\n",
      "\n",
      "**5**\n",
      "Accuracy:0.886164162634751\n",
      "F1 Score:0.790597657452038\n",
      "ROC_AUC_Score:0.8591995283550213\n",
      "Recall:0.8011334971895427\n",
      "Precision:0.7830877645657282\n",
      "\n",
      "**10**\n",
      "Accuracy:0.8913844325609033\n",
      "F1 Score:0.7895699394456996\n",
      "ROC_AUC_Score:0.8487604505721114\n",
      "Recall:0.7581481396997743\n",
      "Precision:0.8274932631161382\n",
      "\n",
      "**25**\n",
      "Accuracy:0.894622697563874\n",
      "F1 Score:0.791412548420168\n",
      "ROC_AUC_Score:0.8475395525423981\n",
      "Recall:0.7465788838388734\n",
      "Precision:0.8455999587986884\n",
      "\n",
      "**40**\n",
      "Accuracy:0.8978991596638656\n",
      "F1 Score:0.7979205774233129\n",
      "ROC_AUC_Score:0.8534068810021074\n",
      "Recall:0.7581481396997743\n",
      "Precision:0.8438948196740131\n",
      "\n",
      "**50**\n",
      "Accuracy:0.9017910194380783\n",
      "F1 Score:0.8057270414074764\n",
      "ROC_AUC_Score:0.8583622710719638\n",
      "Recall:0.7655353554938401\n",
      "Precision:0.85499141999142\n",
      "\n",
      "**70**\n",
      "Accuracy:0.9011374246668364\n",
      "F1 Score:0.8050135323711369\n",
      "ROC_AUC_Score:0.8581441417287017\n",
      "Recall:0.7659686620247076\n",
      "Precision:0.8507060151406106\n",
      "\n",
      "**SGD Results**\n",
      "**2**\n",
      "Accuracy:0.8516764281470165\n",
      "F1 Score:0.7413198589289529\n",
      "ROC_AUC_Score:0.8331111491631921\n",
      "Recall:0.793371046873901\n",
      "Precision:0.6986896467790826\n",
      "**5**\n",
      "Accuracy:0.866017316017316\n",
      "F1 Score:0.7486548177647048\n",
      "ROC_AUC_Score:0.8266070375466839\n",
      "Recall:0.7430257512769189\n",
      "Precision:0.7639320930510263\n",
      "**10**\n",
      "Accuracy:0.8829046770223241\n",
      "F1 Score:0.7715926629331432\n",
      "ROC_AUC_Score:0.8383883348599417\n",
      "Recall:0.7423235646899374\n",
      "Precision:0.8105046028364491\n",
      "**25**\n",
      "Accuracy:0.868623206858501\n",
      "F1 Score:0.7546408388826441\n",
      "ROC_AUC_Score:0.8303441636110278\n",
      "Recall:0.7460075731222592\n",
      "Precision:0.784381103901885\n",
      "**40**\n",
      "Accuracy:0.9011374246668364\n",
      "F1 Score:0.800202049521965\n",
      "ROC_AUC_Score:0.853533585679456\n",
      "Recall:0.75471466779199\n",
      "Precision:0.8588268503365978\n",
      "**50**\n",
      "Accuracy:0.8783464901111959\n",
      "F1 Score:0.7841986649865926\n",
      "ROC_AUC_Score:0.8560575913882434\n",
      "Recall:0.8077027625548643\n",
      "Precision:0.7854397619818827\n",
      "**70**\n",
      "Accuracy:0.8894915541974365\n",
      "F1 Score:0.7981901350676207\n",
      "ROC_AUC_Score:0.86051272915463\n",
      "Recall:0.7999929667288256\n",
      "Precision:0.8204080395151824\n",
      "\n",
      "**SVM Results**\n",
      "\n",
      "**2**\n",
      "Accuracy:0.8692386045327222\n",
      "F1 Score:0.7587636790912012\n",
      "ROC_AUC_Score:0.8380428137148428\n",
      "Recall:0.771167009776247\n",
      "Precision:0.7525969180624902\n",
      "\n",
      "**5**\n",
      "Accuracy:0.8861514302690774\n",
      "F1 Score:0.7880111127896756\n",
      "ROC_AUC_Score:0.8558767175652557\n",
      "Recall:0.7908069443097985\n",
      "Precision:0.7876006989220874\n",
      "\n",
      "**10**\n",
      "Accuracy:0.892670401493931\n",
      "F1 Score:0.7821067840887302\n",
      "ROC_AUC_Score:0.839277617883929\n",
      "Recall:0.7248050168133198\n",
      "Precision:0.8521243328383056\n",
      "\n",
      "**25**\n",
      "Accuracy:0.9037390713861303\n",
      "F1 Score:0.8068087074492591\n",
      "ROC_AUC_Score:0.8552454811404665\n",
      "Recall:0.7513287179867356\n",
      "Precision:0.874197295948657\n",
      "\n",
      "**40**\n",
      "Accuracy:0.9063492063492063\n",
      "F1 Score:0.8075316415747222\n",
      "ROC_AUC_Score:0.8536390094406385\n",
      "Recall:0.7409440930976997\n",
      "Precision:0.890407698661968\n",
      "\n",
      "**50**\n",
      "Accuracy:0.9069943128766658\n",
      "F1 Score:0.8112037538338909\n",
      "ROC_AUC_Score:0.8577706047956382\n",
      "Recall:0.7527787123791275\n",
      "Precision:0.8838417878758109\n",
      "\n",
      "**70**\n",
      "Accuracy:0.9043884220354809\n",
      "F1 Score:0.8057507766786378\n",
      "ROC_AUC_Score:0.8543675160815264\n",
      "Recall:0.7478336574340725\n",
      "Precision:0.8760238229432826\n",
      "\n",
      "**ANN Results**\n",
      "\n",
      "**2**\n",
      "Accuracy:0.8692386045327222\n",
      "F1 Score:0.7587636790912012\n",
      "ROC_AUC_Score:0.8380428137148428\n",
      "Recall:0.771167009776247\n",
      "Precision:0.7525969180624902\n",
      "\n",
      "**5**\n",
      "Accuracy:0.8842245989304812\n",
      "F1 Score:0.7874412183501636\n",
      "ROC_AUC_Score:0.8575888255813171\n",
      "Recall:0.7995552881645253\n",
      "Precision:0.7785484111923873\n",
      "\n",
      "**10**\n",
      "Accuracy:0.8822510822510823\n",
      "F1 Score:0.7747474988886577\n",
      "ROC_AUC_Score:0.8423144096625823\n",
      "Recall:0.7555805205000846\n",
      "Precision:0.7970237662036928\n",
      "\n",
      "**25**\n",
      "Accuracy:0.9102325778796369\n",
      "F1 Score:0.8264502670576039\n",
      "ROC_AUC_Score:0.8776711461949247\n",
      "Recall:0.8076786213267789\n",
      "Precision:0.8535322183413381\n",
      "\n",
      "**40**\n",
      "Accuracy:0.9219421101774042\n",
      "F1 Score:0.85149473381582\n",
      "ROC_AUC_Score:0.897648777323873\n",
      "Recall:0.8447727588101227\n",
      "Precision:0.8649237419675091\n",
      "\n",
      "**50**\n",
      "Accuracy:0.9284483490365844\n",
      "F1 Score:0.8629305015034676\n",
      "ROC_AUC_Score:0.9053626058080588\n",
      "Recall:0.8559207787541986\n",
      "Precision:0.873665199844236\n",
      "\n",
      "**70**\n",
      "Accuracy:0.9388719124013243\n",
      "F1 Score:0.8840741592343505\n",
      "ROC_AUC_Score:0.9184680599455136\n",
      "Recall:0.8751944129214498\n",
      "Precision:0.8963711801677142\n",
      "\n",
      "**DeepLearn Results**\n",
      "\n",
      "**2**\n",
      "Accuracy:0.8705373058314235\n",
      "F1 Score:0.7621593958575527\n",
      "ROC_AUC_Score:0.8406069162789453\n",
      "Recall:0.7762952149044521\n",
      "Precision:0.7535160357095488\n",
      "\n",
      "**5**\n",
      "Accuracy:0.8829131652661065\n",
      "F1 Score:0.7850031771154466\n",
      "ROC_AUC_Score:0.855692110451668\n",
      "Recall:0.7968080354172725\n",
      "Precision:0.7760409417370162\n",
      "\n",
      "**10**\n",
      "Accuracy:0.8829046770223241\n",
      "F1 Score:0.7714448904136122\n",
      "ROC_AUC_Score:0.83770289719596\n",
      "Recall:0.7402629112800363\n",
      "Precision:0.8108125932908413\n",
      "\n",
      "**25**\n",
      "Accuracy:0.9102283337577456\n",
      "F1 Score:0.8305371321546418\n",
      "ROC_AUC_Score:0.8816753579668886\n",
      "Recall:0.8192014956156107\n",
      "Precision:0.8463127359676481\n",
      "\n",
      "**40**\n",
      "Accuracy:0.9219590866649691\n",
      "F1 Score:0.8535773278577048\n",
      "ROC_AUC_Score:0.900651533707421\n",
      "Recall:0.8544676479030399\n",
      "Precision:0.8568191796313906\n",
      "\n",
      "**50**\n",
      "Accuracy:0.9291061879297173\n",
      "F1 Score:0.8672187197837372\n",
      "ROC_AUC_Score:0.9084593209734597\n",
      "Recall:0.8639365218763247\n",
      "Precision:0.8746570497657453\n",
      "\n",
      "**70**\n",
      "Accuracy:0.925201595789831\n",
      "F1 Score:0.8599708504729968\n",
      "ROC_AUC_Score:0.9041177225520123\n",
      "Recall:0.858676965656727\n",
      "Precision:0.8670181744418268\n"
     ]
    }
   ],
   "source": [
    "print('*RandomForest Results**')\n",
    "for c, i in enumerate(bestPercent): \n",
    "    print(f'\\n**{i}**')\n",
    "    for metric, score in RandomForestChi[c][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "\n",
    "print('\\n**LMT Results**')\n",
    "for c, i in enumerate(bestPercent): \n",
    "    print(f'\\n**{i}**')\n",
    "    for metric, score in LogisticModelChi[c][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "\n",
    "print('\\n**LogitBoost Results**')\n",
    "for c, i in enumerate(bestPercent): \n",
    "    print(f'\\n**{i}**')\n",
    "    for metric, score in LogitBoostChi[c][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "        \n",
    "print('\\n**SGD Results**')\n",
    "for c, i in enumerate(bestPercent): \n",
    "    print(f'**{i}**')\n",
    "    for metric, score in SGDChi[c][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "\n",
    "print('\\n**SVM Results**')\n",
    "for c, i in enumerate(bestPercent): \n",
    "    print(f'\\n**{i}**')\n",
    "    for metric, score in SVMChi[c][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "        \n",
    "print('\\n**ANN Results**')\n",
    "for c, i in enumerate(bestPercent): \n",
    "    print(f'\\n**{i}**')\n",
    "    for metric, score in ANNChi[c][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "\n",
    "print('\\n**DeepLearn Results**')\n",
    "for c, i in enumerate(bestPercent): \n",
    "    print(f'\\n**{i}**')\n",
    "    for metric, score in DeepLearnChi[c][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*RandomForest Results**\n",
      "\n",
      "**2**\n",
      "Accuracy:0.8712036329683389\n",
      "F1 Score:0.7524845060223535\n",
      "ROC_AUC_Score:0.8285239221494953\n",
      "Recall:0.7382638465150141\n",
      "Precision:0.7771678801871811\n",
      "\n",
      "**5**\n",
      "Accuracy:0.8920719803072744\n",
      "F1 Score:0.7878469310000737\n",
      "ROC_AUC_Score:0.8479019407711268\n",
      "Recall:0.7527662615882648\n",
      "Precision:0.833952892936205\n",
      "\n",
      "**10**\n",
      "Accuracy:0.8881376793141499\n",
      "F1 Score:0.7834229971039419\n",
      "ROC_AUC_Score:0.8458625481081933\n",
      "Recall:0.7550650007318404\n",
      "Precision:0.8180167840399253\n",
      "\n",
      "**25**\n",
      "Accuracy:0.9043841779135897\n",
      "F1 Score:0.8157885156030558\n",
      "ROC_AUC_Score:0.8696613617028529\n",
      "Recall:0.7934684671840875\n",
      "Precision:0.8447107367973912\n",
      "\n",
      "**40**\n",
      "Accuracy:0.9239028944911298\n",
      "F1 Score:0.8545940783635141\n",
      "ROC_AUC_Score:0.894668395055587\n",
      "Recall:0.8311459859980876\n",
      "Precision:0.8847415838940023\n",
      "\n",
      "**50**\n",
      "Accuracy:0.9304006451065275\n",
      "F1 Score:0.8652959129518673\n",
      "ROC_AUC_Score:0.9009774586620163\n",
      "Recall:0.8374588220981579\n",
      "Precision:0.8992659140685456\n",
      "\n",
      "**70**\n",
      "Accuracy:0.9343052372464138\n",
      "F1 Score:0.8737125257980226\n",
      "ROC_AUC_Score:0.9074125891792887\n",
      "Recall:0.8493635840029199\n",
      "Precision:0.9041689850683404\n",
      "\n",
      "**LMT Results**\n",
      "\n",
      "**2**\n",
      "Accuracy:0.8419149477973008\n",
      "F1 Score:0.7429259983444544\n",
      "ROC_AUC_Score:0.8448796030921324\n",
      "Recall:0.8507309849811147\n",
      "Precision:0.6616104886434947\n",
      "\n",
      "**5**\n",
      "Accuracy:0.8458280281809694\n",
      "F1 Score:0.7330072438515514\n",
      "ROC_AUC_Score:0.8282941445161024\n",
      "Recall:0.7918115615572802\n",
      "Precision:0.6851550930832065\n",
      "\n",
      "**10**\n",
      "Accuracy:0.8464943553178849\n",
      "F1 Score:0.736404691188181\n",
      "ROC_AUC_Score:0.8324666835988124\n",
      "Recall:0.8027577076098094\n",
      "Precision:0.6844806030431813\n",
      "\n",
      "**25**\n",
      "Accuracy:0.882268058738647\n",
      "F1 Score:0.7872073570693162\n",
      "ROC_AUC_Score:0.8607167258757691\n",
      "Recall:0.8149554907987706\n",
      "Precision:0.7633833940044409\n",
      "\n",
      "**40**\n",
      "Accuracy:0.8822638146167557\n",
      "F1 Score:0.7877837708749894\n",
      "ROC_AUC_Score:0.8613964618633684\n",
      "Recall:0.8172082285470974\n",
      "Precision:0.7626842716215327\n",
      "\n",
      "**50**\n",
      "Accuracy:0.8926746456158222\n",
      "F1 Score:0.8014877480108012\n",
      "ROC_AUC_Score:0.8665622685100074\n",
      "Recall:0.8115765742646908\n",
      "Precision:0.7930649965918517\n",
      "\n",
      "**70**\n",
      "Accuracy:0.8939945675239793\n",
      "F1 Score:0.8203677455950498\n",
      "ROC_AUC_Score:0.8943315023663656\n",
      "Recall:0.8955821552604117\n",
      "Precision:0.7592502436743912\n",
      "\n",
      "**LogitBoost Results**\n",
      "\n",
      "**2**\n",
      "Accuracy:0.8699049316696377\n",
      "F1 Score:0.7500079970915354\n",
      "ROC_AUC_Score:0.8250308744053229\n",
      "Recall:0.7302633104656976\n",
      "Precision:0.7772677797862565\n",
      "\n",
      "**5**\n",
      "Accuracy:0.8731559290382821\n",
      "F1 Score:0.7478151381076312\n",
      "ROC_AUC_Score:0.8210028149849047\n",
      "Recall:0.7096616236211462\n",
      "Precision:0.7985472890297917\n",
      "\n",
      "**10**\n",
      "Accuracy:0.8939733469145233\n",
      "F1 Score:0.7928336047129764\n",
      "ROC_AUC_Score:0.850590266230838\n",
      "Recall:0.7582151458643415\n",
      "Precision:0.8341242022511371\n",
      "\n",
      "**25**\n",
      "Accuracy:0.9011331805449453\n",
      "F1 Score:0.8023851091908549\n",
      "ROC_AUC_Score:0.8543192580497339\n",
      "Recall:0.7548514364030711\n",
      "Precision:0.8618739833215872\n",
      "\n",
      "**40**\n",
      "Accuracy:0.9017867753161871\n",
      "F1 Score:0.802754955938567\n",
      "ROC_AUC_Score:0.8537861314213433\n",
      "Recall:0.7511455678035854\n",
      "Precision:0.8635265084789834\n",
      "\n",
      "**50**\n",
      "Accuracy:0.9030982089805619\n",
      "F1 Score:0.8050083895966248\n",
      "ROC_AUC_Score:0.8552074474754908\n",
      "Recall:0.7530199345715692\n",
      "Precision:0.8673210248532074\n",
      "\n",
      "**70**\n",
      "Accuracy:0.8991978609625668\n",
      "F1 Score:0.7992795250160979\n",
      "ROC_AUC_Score:0.8539923479549356\n",
      "Recall:0.7577148331689069\n",
      "Precision:0.8501824637350953\n",
      "\n",
      "**SGD Results**\n",
      "\n",
      "**2**\n",
      "Accuracy:0.851056786350904\n",
      "F1 Score:0.7263744147010597\n",
      "ROC_AUC_Score:0.8157800448741961\n",
      "Recall:0.7419634421969658\n",
      "Precision:0.7253666545767501\n",
      "\n",
      "**5**\n",
      "Accuracy:0.8607376283846871\n",
      "F1 Score:0.7395490492712261\n",
      "ROC_AUC_Score:0.8225614649863392\n",
      "Recall:0.7409650978670179\n",
      "Precision:0.764754561402109\n",
      "\n",
      "**10**\n",
      "Accuracy:0.8737840590781767\n",
      "F1 Score:0.7540430194373101\n",
      "ROC_AUC_Score:0.8262268885685031\n",
      "Recall:0.7234653687430024\n",
      "Precision:0.797706751677655\n",
      "\n",
      "**25**\n",
      "Accuracy:0.8913547237076649\n",
      "F1 Score:0.7820631181248434\n",
      "ROC_AUC_Score:0.8429316923587681\n",
      "Recall:0.7380834526138106\n",
      "Precision:0.842095574342985\n",
      "\n",
      "**40**\n",
      "Accuracy:0.8874543756896699\n",
      "F1 Score:0.7817099638458733\n",
      "ROC_AUC_Score:0.8466286303939666\n",
      "Recall:0.7613416249897826\n",
      "Precision:0.8163296459637923\n",
      "\n",
      "**50**\n",
      "Accuracy:0.8875010610304728\n",
      "F1 Score:0.7821749886467926\n",
      "ROC_AUC_Score:0.8471881200176595\n",
      "Recall:0.7608953924470272\n",
      "Precision:0.8122042498287165\n",
      "\n",
      "**70**\n",
      "Accuracy:0.896570749511926\n",
      "F1 Score:0.8005690901340488\n",
      "ROC_AUC_Score:0.8605873837816167\n",
      "Recall:0.7831727086267823\n",
      "Precision:0.8257523175546432\n",
      "\n",
      "**SVM Results**\n",
      "\n",
      "**2**\n",
      "Accuracy:0.8718572277395807\n",
      "F1 Score:0.7534311497400815\n",
      "ROC_AUC_Score:0.8289625186407233\n",
      "Recall:0.7382638465150141\n",
      "Precision:0.7788345468538478\n",
      "\n",
      "**5**\n",
      "Accuracy:0.882293523469994\n",
      "F1 Score:0.7549031686501666\n",
      "ROC_AUC_Score:0.8182513700598124\n",
      "Recall:0.6799909137739963\n",
      "Precision:0.8549514202964718\n",
      "\n",
      "**10**\n",
      "Accuracy:0.897228588405059\n",
      "F1 Score:0.7968696733207786\n",
      "ROC_AUC_Score:0.8513047580736028\n",
      "Recall:0.7534563775612038\n",
      "Precision:0.8483260491523976\n",
      "\n",
      "**25**\n",
      "Accuracy:0.9037433155080213\n",
      "F1 Score:0.8071551619743109\n",
      "ROC_AUC_Score:0.8557388001537664\n",
      "Recall:0.7532732273780536\n",
      "Precision:0.8714177516394839\n",
      "\n",
      "**40**\n",
      "Accuracy:0.905050505050505\n",
      "F1 Score:0.8076692653829938\n",
      "ROC_AUC_Score:0.855137113083592\n",
      "Recall:0.7485113226161488\n",
      "Precision:0.8791388521997783\n",
      "\n",
      "**50**\n",
      "Accuracy:0.9082930141753671\n",
      "F1 Score:0.813752389231255\n",
      "ROC_AUC_Score:0.8587908130852491\n",
      "Recall:0.7531450127454279\n",
      "Precision:0.8888738118281136\n",
      "\n",
      "**70**\n",
      "Accuracy:0.9076436635260166\n",
      "F1 Score:0.8120296204271094\n",
      "ROC_AUC_Score:0.8584639847485345\n",
      "Recall:0.7543448507901025\n",
      "Precision:0.8830195833111555\n",
      "\n",
      "**ANN Results**\n",
      "\n",
      "**2**\n",
      "Accuracy:0.8699049316696377\n",
      "F1 Score:0.7515727124429781\n",
      "ROC_AUC_Score:0.828469118494529\n",
      "Recall:0.7408279490791166\n",
      "Precision:0.7732805330805925\n",
      "\n",
      "**5**\n",
      "Accuracy:0.8862320685850097\n",
      "F1 Score:0.7789278610905023\n",
      "ROC_AUC_Score:0.8425938322794977\n",
      "Recall:0.7486270864579115\n",
      "Precision:0.8184996877306778\n",
      "\n",
      "**10**\n",
      "Accuracy:0.8900942195059842\n",
      "F1 Score:0.7844872735170463\n",
      "ROC_AUC_Score:0.8448009529554472\n",
      "Recall:0.7475558432226829\n",
      "Precision:0.82765565374883\n",
      "\n",
      "**25**\n",
      "Accuracy:0.9121806298276887\n",
      "F1 Score:0.8303748664234509\n",
      "ROC_AUC_Score:0.880110069016266\n",
      "Recall:0.8097446922563684\n",
      "Precision:0.8583262281236437\n",
      "\n",
      "**40**\n",
      "Accuracy:0.9245607333842628\n",
      "F1 Score:0.8569308215442255\n",
      "ROC_AUC_Score:0.8999311937995872\n",
      "Recall:0.8469736974666919\n",
      "Precision:0.8713268590087722\n",
      "\n",
      "**50**\n",
      "Accuracy:0.9336728630846277\n",
      "F1 Score:0.8757903812382273\n",
      "ROC_AUC_Score:0.914510056222029\n",
      "Recall:0.8733079755394234\n",
      "Precision:0.8816860504816726\n",
      "\n",
      "**70**\n",
      "Accuracy:0.9323868941516\n",
      "F1 Score:0.8749351646005532\n",
      "ROC_AUC_Score:0.9144461341468139\n",
      "Recall:0.8748125253055197\n",
      "Precision:0.8804002440291147\n",
      "\n",
      "**DeepLearn Results**\n",
      "\n",
      "**2**\n",
      "Accuracy:0.8712078770902301\n",
      "F1 Score:0.754516209564879\n",
      "ROC_AUC_Score:0.8318804897319874\n",
      "Recall:0.7485202567714244\n",
      "Precision:0.7696679917635318\n",
      "\n",
      "**5**\n",
      "Accuracy:0.88231474407945\n",
      "F1 Score:0.7732119906414503\n",
      "ROC_AUC_Score:0.8405172709600345\n",
      "Recall:0.7504433812166038\n",
      "Precision:0.8025903148264852\n",
      "\n",
      "**10**\n",
      "Accuracy:0.8868432221373398\n",
      "F1 Score:0.7772023183969401\n",
      "ROC_AUC_Score:0.8403248363065542\n",
      "Recall:0.7402387700519513\n",
      "Precision:0.8221245696766772\n",
      "\n",
      "**25**\n",
      "Accuracy:0.9004753416518122\n",
      "F1 Score:0.8122304364383552\n",
      "ROC_AUC_Score:0.8714484039050181\n",
      "Recall:0.8076719682324249\n",
      "Precision:0.8215159434061874\n",
      "\n",
      "**40**\n",
      "Accuracy:0.9206221882692471\n",
      "F1 Score:0.8465585500735854\n",
      "ROC_AUC_Score:0.8907775546078363\n",
      "Recall:0.8259016368512995\n",
      "Precision:0.8763383526814653\n",
      "\n",
      "**50**\n",
      "Accuracy:0.9277989983872337\n",
      "F1 Score:0.8646813344127866\n",
      "ROC_AUC_Score:0.9068837321506924\n",
      "Recall:0.8618057258430897\n",
      "Precision:0.8690030125363887\n",
      "\n",
      "**70**\n",
      "Accuracy:0.9284610814022578\n",
      "F1 Score:0.8644839242865558\n",
      "ROC_AUC_Score:0.905089505269926\n",
      "Recall:0.854534654067607\n",
      "Precision:0.8812319937402993\n"
     ]
    }
   ],
   "source": [
    "RandomForestInfoGain, LogisticModelInfoGain, LogitBoostInfoGain, SGDInfoGain, SVMInfoGain, ANNInfoGain, DeepLearnInfoGain = [], [], [], [], [], [], []\n",
    "\n",
    "for X in bestInfoGainFeatures:\n",
    "    RandomForestInfoGain.append(RandomForest(X, y))\n",
    "    LogisticModelInfoGain.append(LogisticModelTree(X, y))\n",
    "    LogitBoostInfoGain.append(LogitBoostClassifier(X, y))\n",
    "    SGDInfoGain.append(SGD(X, y))\n",
    "    SVMInfoGain.append(SVM(X, y))\n",
    "    ANNInfoGain.append(ANN(X, y))\n",
    "    DeepLearnInfoGain.append(deepLearn(X, y))\n",
    "\n",
    "\n",
    "print('*RandomForest Results**')\n",
    "for c, i in enumerate(bestPercent): \n",
    "    print(f'\\n**{i}**')\n",
    "    for metric, score in RandomForestInfoGain[c][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "\n",
    "print('\\n**LMT Results**')\n",
    "for c, i in enumerate(bestPercent): \n",
    "    print(f'\\n**{i}**')\n",
    "    for metric, score in LogisticModelInfoGain[c][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "\n",
    "print('\\n**LogitBoost Results**')\n",
    "for c, i in enumerate(bestPercent): \n",
    "    print(f'\\n**{i}**')\n",
    "    for metric, score in LogitBoostInfoGain[c][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "        \n",
    "print('\\n**SGD Results**')\n",
    "for c, i in enumerate(bestPercent): \n",
    "    print(f'\\n**{i}**')\n",
    "    for metric, score in SGDInfoGain[c][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "\n",
    "print('\\n**SVM Results**')\n",
    "for c, i in enumerate(bestPercent): \n",
    "    print(f'\\n**{i}**')\n",
    "    for metric, score in SVMInfoGain[c][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "        \n",
    "print('\\n**ANN Results**')\n",
    "for c, i in enumerate(bestPercent): \n",
    "    print(f'\\n**{i}**')\n",
    "    for metric, score in ANNInfoGain[c][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "\n",
    "print('\\n**DeepLearn Results**')\n",
    "for c, i in enumerate(bestPercent): \n",
    "    print(f'\\n**{i}**')\n",
    "    for metric, score in DeepLearnInfoGain[c][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*RandomForest Results**\n",
      "\n",
      "**2**\n",
      "Accuracy:0.8725108225108226\n",
      "F1 Score:0.7557233724191146\n",
      "ROC_AUC_Score:0.8309629465397391\n",
      "Recall:0.7431418952955019\n",
      "Precision:0.7782489612682623\n",
      "\n",
      "**5**\n",
      "Accuracy:0.8914226296579237\n",
      "F1 Score:0.7861165487063112\n",
      "ROC_AUC_Score:0.8466198894890755\n",
      "Recall:0.7502021590241622\n",
      "Precision:0.8335496671297532\n",
      "\n",
      "**10**\n",
      "Accuracy:0.8881419234360411\n",
      "F1 Score:0.7820738107246652\n",
      "ROC_AUC_Score:0.8442672136181221\n",
      "Recall:0.7501199457867854\n",
      "Precision:0.8213645138640263\n",
      "\n",
      "**25**\n",
      "Accuracy:0.9056913674560734\n",
      "F1 Score:0.8197853776425061\n",
      "ROC_AUC_Score:0.8739289358477833\n",
      "Recall:0.8046745591374549\n",
      "Precision:0.8411332247446468\n",
      "\n",
      "**40**\n",
      "Accuracy:0.925201595789831\n",
      "F1 Score:0.8563037566688599\n",
      "ROC_AUC_Score:0.89455621311618\n",
      "Recall:0.828328590627501\n",
      "Precision:0.8917855583304087\n",
      "\n",
      "**50**\n",
      "Accuracy:0.9310542398777694\n",
      "F1 Score:0.8668512002672125\n",
      "ROC_AUC_Score:0.9020125952208522\n",
      "Recall:0.839586481672626\n",
      "Precision:0.9005853004471323\n",
      "\n",
      "**70**\n",
      "Accuracy:0.9310542398777694\n",
      "F1 Score:0.8666105706795337\n",
      "ROC_AUC_Score:0.9013465223053391\n",
      "Recall:0.8373458145383419\n",
      "Precision:0.9026489385042016\n",
      "\n",
      "**LMT Results**\n",
      "\n",
      "**2**\n",
      "Accuracy:0.8419149477973008\n",
      "F1 Score:0.7429259983444544\n",
      "ROC_AUC_Score:0.8448796030921324\n",
      "Recall:0.8507309849811147\n",
      "Precision:0.6616104886434947\n",
      "\n",
      "**5**\n",
      "Accuracy:0.8458280281809694\n",
      "F1 Score:0.7330072438515514\n",
      "ROC_AUC_Score:0.8282941445161024\n",
      "Recall:0.7918115615572802\n",
      "Precision:0.6851550930832065\n",
      "\n",
      "**10**\n",
      "Accuracy:0.8464943553178849\n",
      "F1 Score:0.736404691188181\n",
      "ROC_AUC_Score:0.8324666835988124\n",
      "Recall:0.8027577076098094\n",
      "Precision:0.6844806030431813\n",
      "\n",
      "**25**\n",
      "Accuracy:0.882268058738647\n",
      "F1 Score:0.7872073570693162\n",
      "ROC_AUC_Score:0.8607167258757691\n",
      "Recall:0.8149554907987706\n",
      "Precision:0.7633833940044409\n",
      "\n",
      "**40**\n",
      "Accuracy:0.8822638146167557\n",
      "F1 Score:0.7877837708749894\n",
      "ROC_AUC_Score:0.8613964618633684\n",
      "Recall:0.8172082285470974\n",
      "Precision:0.7626842716215327\n",
      "\n",
      "**50**\n",
      "Accuracy:0.8926746456158222\n",
      "F1 Score:0.8014877480108012\n",
      "ROC_AUC_Score:0.8665622685100074\n",
      "Recall:0.8115765742646908\n",
      "Precision:0.7930649965918517\n",
      "\n",
      "**70**\n",
      "Accuracy:0.8939945675239793\n",
      "F1 Score:0.8203677455950498\n",
      "ROC_AUC_Score:0.8943315023663656\n",
      "Recall:0.8955821552604117\n",
      "Precision:0.7592502436743912\n",
      "\n",
      "**LogitBoost Results**\n",
      "\n",
      "**2**\n",
      "Accuracy:0.8699049316696377\n",
      "F1 Score:0.7500079970915354\n",
      "ROC_AUC_Score:0.8250308744053229\n",
      "Recall:0.7302633104656976\n",
      "Precision:0.7772677797862565\n",
      "\n",
      "**5**\n",
      "Accuracy:0.8731559290382821\n",
      "F1 Score:0.7478151381076312\n",
      "ROC_AUC_Score:0.8210028149849047\n",
      "Recall:0.7096616236211462\n",
      "Precision:0.7985472890297917\n",
      "\n",
      "**10**\n",
      "Accuracy:0.8939733469145233\n",
      "F1 Score:0.7928336047129764\n",
      "ROC_AUC_Score:0.850590266230838\n",
      "Recall:0.7582151458643415\n",
      "Precision:0.8341242022511371\n",
      "\n",
      "**25**\n",
      "Accuracy:0.9011331805449453\n",
      "F1 Score:0.8023851091908549\n",
      "ROC_AUC_Score:0.8543192580497339\n",
      "Recall:0.7548514364030711\n",
      "Precision:0.8618739833215872\n",
      "\n",
      "**40**\n",
      "Accuracy:0.9017867753161871\n",
      "F1 Score:0.802754955938567\n",
      "ROC_AUC_Score:0.8537861314213433\n",
      "Recall:0.7511455678035854\n",
      "Precision:0.8635265084789834\n",
      "\n",
      "**50**\n",
      "Accuracy:0.9030982089805619\n",
      "F1 Score:0.8050083895966248\n",
      "ROC_AUC_Score:0.8552074474754908\n",
      "Recall:0.7530199345715692\n",
      "Precision:0.8673210248532074\n",
      "\n",
      "**70**\n",
      "Accuracy:0.8991978609625668\n",
      "F1 Score:0.7992795250160979\n",
      "ROC_AUC_Score:0.8539923479549356\n",
      "Recall:0.7577148331689069\n",
      "Precision:0.8501824637350953\n",
      "\n",
      "**SGD Results**\n",
      "\n",
      "**2**\n",
      "Accuracy:0.8607885578473814\n",
      "F1 Score:0.7382964463154773\n",
      "ROC_AUC_Score:0.8203314118456377\n",
      "Recall:0.7339504553567864\n",
      "Precision:0.7499146824886823\n",
      "\n",
      "**5**\n",
      "Accuracy:0.8751124692301163\n",
      "F1 Score:0.7516927998410364\n",
      "ROC_AUC_Score:0.8243085625262058\n",
      "Recall:0.7160937401985663\n",
      "Precision:0.7996699213263605\n",
      "\n",
      "**10**\n",
      "Accuracy:0.8136151430269077\n",
      "F1 Score:0.7303688486891879\n",
      "ROC_AUC_Score:0.8040914686970687\n",
      "Recall:0.7823029591062803\n",
      "Precision:0.7325918845411694\n",
      "\n",
      "**25**\n",
      "Accuracy:0.8861768950004244\n",
      "F1 Score:0.7802602390725122\n",
      "ROC_AUC_Score:0.8454342022353254\n",
      "Recall:0.7570215807372008\n",
      "Precision:0.8145895135806924\n",
      "\n",
      "**40**\n",
      "Accuracy:0.8946311858076564\n",
      "F1 Score:0.7832605609931712\n",
      "ROC_AUC_Score:0.8396022376174367\n",
      "Recall:0.7216244575351995\n",
      "Precision:0.8649394766035206\n",
      "\n",
      "**50**\n",
      "Accuracy:0.8634708428826077\n",
      "F1 Score:0.7604195669313025\n",
      "ROC_AUC_Score:0.8395895063800319\n",
      "Recall:0.7898915735708678\n",
      "Precision:0.7552096142114798\n",
      "\n",
      "**70**\n",
      "Accuracy:0.8920634920634921\n",
      "F1 Score:0.8019195065017474\n",
      "ROC_AUC_Score:0.8626814731121295\n",
      "Recall:0.7975254290770638\n",
      "Precision:0.8275898671165918\n",
      "\n",
      "**SVM Results**\n",
      "\n",
      "**2**\n",
      "Accuracy:0.8718572277395807\n",
      "F1 Score:0.7534311497400815\n",
      "ROC_AUC_Score:0.8289625186407233\n",
      "Recall:0.7382638465150141\n",
      "Precision:0.7788345468538478\n",
      "\n",
      "**5**\n",
      "Accuracy:0.882293523469994\n",
      "F1 Score:0.7549031686501666\n",
      "ROC_AUC_Score:0.8182513700598124\n",
      "Recall:0.6799909137739963\n",
      "Precision:0.8549514202964718\n",
      "\n",
      "**10**\n",
      "Accuracy:0.897228588405059\n",
      "F1 Score:0.7968696733207786\n",
      "ROC_AUC_Score:0.8513047580736028\n",
      "Recall:0.7534563775612038\n",
      "Precision:0.8483260491523976\n",
      "\n",
      "**25**\n",
      "Accuracy:0.9037433155080213\n",
      "F1 Score:0.8071551619743109\n",
      "ROC_AUC_Score:0.8557388001537664\n",
      "Recall:0.7532732273780536\n",
      "Precision:0.8714177516394839\n",
      "\n",
      "**40**\n",
      "Accuracy:0.905050505050505\n",
      "F1 Score:0.8076692653829938\n",
      "ROC_AUC_Score:0.855137113083592\n",
      "Recall:0.7485113226161488\n",
      "Precision:0.8791388521997783\n",
      "\n",
      "**50**\n",
      "Accuracy:0.9082930141753671\n",
      "F1 Score:0.813752389231255\n",
      "ROC_AUC_Score:0.8587908130852491\n",
      "Recall:0.7531450127454279\n",
      "Precision:0.8888738118281136\n",
      "\n",
      "**70**\n",
      "Accuracy:0.9076436635260166\n",
      "F1 Score:0.8120296204271094\n",
      "ROC_AUC_Score:0.8584639847485345\n",
      "Recall:0.7543448507901025\n",
      "Precision:0.8830195833111555\n",
      "\n",
      "**ANN Results**\n",
      "\n",
      "**2**\n",
      "Accuracy:0.8725108225108226\n",
      "F1 Score:0.7572666240774333\n",
      "ROC_AUC_Score:0.833195089396882\n",
      "Recall:0.750284752438359\n",
      "Precision:0.7746682658868403\n",
      "\n",
      "**5**\n",
      "Accuracy:0.8855699855699856\n",
      "F1 Score:0.7746811970993572\n",
      "ROC_AUC_Score:0.8389325105320321\n",
      "Recall:0.7383706762015013\n",
      "Precision:0.8235507887365474\n",
      "\n",
      "**10**\n",
      "Accuracy:0.8939733469145235\n",
      "F1 Score:0.794515960932882\n",
      "ROC_AUC_Score:0.8534724730713265\n",
      "Recall:0.7665882551974923\n",
      "Precision:0.82631977720213\n",
      "\n",
      "**25**\n",
      "Accuracy:0.9017782870724048\n",
      "F1 Score:0.8141680739412669\n",
      "ROC_AUC_Score:0.8712801053196142\n",
      "Recall:0.8046745591374547\n",
      "Precision:0.8269507832743128\n",
      "\n",
      "**40**\n",
      "Accuracy:0.9226211696799933\n",
      "F1 Score:0.8533122382593957\n",
      "ROC_AUC_Score:0.8974698825166119\n",
      "Recall:0.8427183783177556\n",
      "Precision:0.8670357384270149\n",
      "\n",
      "**50**\n",
      "Accuracy:0.9330065359477124\n",
      "F1 Score:0.8720438498954384\n",
      "ROC_AUC_Score:0.9078624784635302\n",
      "Recall:0.8539150608948223\n",
      "Precision:0.8940105732034487\n",
      "\n",
      "**70**\n",
      "Accuracy:0.931045751633987\n",
      "F1 Score:0.8697868670846173\n",
      "ROC_AUC_Score:0.9096392703547973\n",
      "Recall:0.8637502352344075\n",
      "Precision:0.8804777538072848\n",
      "\n",
      "**DeepLearn Results**\n",
      "\n",
      "**2**\n",
      "Accuracy:0.8705542823189882\n",
      "F1 Score:0.7516608958644948\n",
      "ROC_AUC_Score:0.8280566324298692\n",
      "Recall:0.7382638465150141\n",
      "Precision:0.7755027553028148\n",
      "\n",
      "**5**\n",
      "Accuracy:0.8810075545369662\n",
      "F1 Score:0.7695133410838441\n",
      "ROC_AUC_Score:0.8387312661886466\n",
      "Recall:0.7478212066432096\n",
      "Precision:0.7996846899870155\n",
      "\n",
      "**10**\n",
      "Accuracy:0.8861853832442069\n",
      "F1 Score:0.7799660149803697\n",
      "ROC_AUC_Score:0.843081699306093\n",
      "Recall:0.7503701021345027\n",
      "Precision:0.8151803874068401\n",
      "\n",
      "**25**\n",
      "Accuracy:0.9050080638315933\n",
      "F1 Score:0.8158924527120707\n",
      "ROC_AUC_Score:0.869137341266325\n",
      "Recall:0.7906050704182517\n",
      "Precision:0.8473371311414051\n",
      "\n",
      "**40**\n",
      "Accuracy:0.9232535438417792\n",
      "F1 Score:0.8548407254591689\n",
      "ROC_AUC_Score:0.8979805710188378\n",
      "Recall:0.8429135991149485\n",
      "Precision:0.871572283758832\n",
      "\n",
      "**50**\n",
      "Accuracy:0.921301247771836\n",
      "F1 Score:0.8469638569884884\n",
      "ROC_AUC_Score:0.8890126490627672\n",
      "Recall:0.8196932543325902\n",
      "Precision:0.8802314701762105\n",
      "\n",
      "**70**\n",
      "Accuracy:0.9317078346490112\n",
      "F1 Score:0.8715773958880518\n",
      "ROC_AUC_Score:0.9099092327920951\n",
      "Recall:0.8625535336485\n",
      "Precision:0.8846285440813484\n"
     ]
    }
   ],
   "source": [
    "print('*RandomForest Results**')\n",
    "for c, i in enumerate(bestPercent): \n",
    "    print(f'\\n**{i}**')\n",
    "    for metric, score in RandomForestInfoGain[c][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "\n",
    "print('\\n**LMT Results**')\n",
    "for c, i in enumerate(bestPercent): \n",
    "    print(f'\\n**{i}**')\n",
    "    for metric, score in LogisticModelInfoGain[c][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "\n",
    "print('\\n**LogitBoost Results**')\n",
    "for c, i in enumerate(bestPercent): \n",
    "    print(f'\\n**{i}**')\n",
    "    for metric, score in LogitBoostInfoGain[c][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "        \n",
    "print('\\n**SGD Results**')\n",
    "for c, i in enumerate(bestPercent): \n",
    "    print(f'\\n**{i}**')\n",
    "    for metric, score in SGDInfoGain[c][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "\n",
    "print('\\n**SVM Results**')\n",
    "for c, i in enumerate(bestPercent): \n",
    "    print(f'\\n**{i}**')\n",
    "    for metric, score in SVMInfoGain[c][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "        \n",
    "print('\\n**ANN Results**')\n",
    "for c, i in enumerate(bestPercent): \n",
    "    print(f'\\n**{i}**')\n",
    "    for metric, score in ANNInfoGain[c][0].items():\n",
    "        print(f'{metric}:{score.mean()}')\n",
    "\n",
    "print('\\n**DeepLearn Results**')\n",
    "for c, i in enumerate(bestPercent): \n",
    "    print(f'\\n**{i}**')\n",
    "    for metric, score in DeepLearnInfoGain[c][0].items():\n",
    "        print(f'{metric}:{score.mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
